{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置文件夹路径和类别名称\n",
    "folders = [r'C:\\Users\\bugs_\\PycharmProjects\\eegProject\\data\\Test_EEG\\HC',\n",
    "           r'C:\\Users\\bugs_\\PycharmProjects\\eegProject\\data\\Test_EEG\\MDD',\n",
    "           r'C:\\Users\\bugs_\\PycharmProjects\\eegProject\\data\\Test_EEG\\BD']\n",
    "class_names = ['HC', 'MDD', 'BD']\n",
    "\n",
    "# 创建存储数据集的字典\n",
    "data_file = {'filename': []}\n",
    "\n",
    "# 遍历每个类别的文件夹\n",
    "for folder, class_name in zip(folders, class_names):\n",
    "    # 获取文件夹中的Clean.mat文件 列表\n",
    "    file_list = os.listdir(folder)\n",
    "    file_list = [os.path.join(folder, file) for file in file_list if file.endswith('Clean.mat')]\n",
    "\n",
    "    # 将数据加入到对应的数据集中\n",
    "    data_file['filename'].extend([(file, class_name) for file in file_list])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T08:42:23.189860500Z",
     "start_time": "2023-08-08T08:42:23.169844800Z"
    }
   },
   "id": "a51b904e6ba06388"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "label_dic = {'HC': 0, 'MDD': 1, \"BD\": 2}\n",
    "target_shape = (174, 16, 24000)\n",
    "X = np.empty(target_shape)\n",
    "y = {'label': np.empty(174, dtype=int)}\n",
    "\n",
    "num_merged = 0\n",
    "\n",
    "for sub, label in data_file['filename']:  # 被试循环\n",
    "    data = sio.loadmat(sub)\n",
    "    sample = data['EEG_ECClean']\n",
    "\n",
    "    # for i in range(120):  # 数据分段，增加数据量\n",
    "    eeg_data = sample[\"data\"][0][0][:, 0:24000]\n",
    "    X[num_merged] = eeg_data\n",
    "    y['label'][num_merged] = label_dic[label]\n",
    "    num_merged += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T08:42:33.457540800Z",
     "start_time": "2023-08-08T08:42:30.439059300Z"
    }
   },
   "id": "10dce38ca3d32481"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(174, 16, 24000)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T12:58:53.929134100Z",
     "start_time": "2023-08-08T12:58:53.903138800Z"
    }
   },
   "id": "e86f54a302c901c3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target folder already exists, if you need to regenerate the database IO, please delete the path C:\\Users\\bugs_\\PycharmProjects\\eegProject\\torcheegProj\\DGCNN\\origin\\features\\Avg\\All40.\n",
      "(tensor([[ 2.9057e+00,  2.8603e+00,  3.4777e+00,  3.0881e+00,  2.2180e+00,\n",
      "          2.6027e-03,  2.4013e-03,  2.3278e-02,  1.8424e-03,  1.4162e-04,\n",
      "          2.5646e+00,  2.4276e+00,  5.6848e+00,  3.3285e+00,  9.9541e-01,\n",
      "          3.4227e-01,  9.3510e-03, -4.8345e-03, -1.0467e-02, -7.3028e-03,\n",
      "          5.4197e-03,  2.8127e-02,  6.6780e-02,  2.7457e-01,  9.1318e-01,\n",
      "          8.0407e-04,  2.0541e-03,  3.1735e-03,  5.1031e-03,  8.1085e-03,\n",
      "          2.0777e+02,  1.5942e+02,  1.6375e+02,  1.6714e+02,  1.5673e+02,\n",
      "          1.1924e-01,  1.2518e-01,  3.2446e-01,  3.3793e-01,  9.3196e-02],\n",
      "        [ 2.8965e+00,  2.8442e+00,  3.4501e+00,  3.0541e+00,  2.1811e+00,\n",
      "          1.1818e-03,  2.0285e-03,  1.5872e-02,  2.0302e-03,  1.5030e-04,\n",
      "          2.5260e+00,  2.3654e+00,  5.4599e+00,  3.1839e+00,  9.3934e-01,\n",
      "          3.3746e-01,  8.5854e-03, -4.8169e-03, -9.4658e-03, -7.5584e-03,\n",
      "          5.2089e-03,  2.7906e-02,  6.7526e-02,  2.7117e-01,  9.0749e-01,\n",
      "          8.0509e-04,  2.0637e-03,  3.1610e-03,  5.0922e-03,  8.0593e-03,\n",
      "          2.0628e+02,  1.5945e+02,  1.6426e+02,  1.6744e+02,  1.5627e+02,\n",
      "          1.2069e-01,  1.2699e-01,  3.2544e-01,  3.3476e-01,  9.2128e-02],\n",
      "        [ 2.3382e+00,  2.5054e+00,  3.1922e+00,  2.6953e+00,  1.8641e+00,\n",
      "          3.0612e-04,  6.7213e-04,  1.3730e-02,  1.2119e-03,  7.2736e-05,\n",
      "          1.1828e+00,  1.4745e+00,  3.8812e+00,  1.9258e+00,  6.0984e-01,\n",
      "          2.9321e-01,  8.3943e-03, -8.8442e-03, -9.9981e-03, -5.0047e-03,\n",
      "          6.1761e-03,  2.9068e-02,  6.5609e-02,  2.6689e-01,  8.9076e-01,\n",
      "          8.8487e-04,  2.0580e-03,  3.1563e-03,  5.1617e-03,  8.1402e-03,\n",
      "          1.9711e+02,  1.5879e+02,  1.6368e+02,  1.6720e+02,  1.5715e+02,\n",
      "          9.1769e-02,  1.2753e-01,  3.5725e-01,  3.2943e-01,  9.4020e-02],\n",
      "        [ 2.8658e+00,  2.9850e+00,  3.5454e+00,  3.2281e+00,  2.3164e+00,\n",
      "          5.2183e-03,  2.5400e-03,  1.8402e-02,  2.4889e-03,  2.2296e-04,\n",
      "          2.4243e+00,  2.8502e+00,  6.2604e+00,  3.9898e+00,  1.1429e+00,\n",
      "          3.0501e-01,  9.4368e-03, -7.3758e-03, -1.1434e-02, -7.9435e-03,\n",
      "          5.5982e-03,  2.7876e-02,  6.7571e-02,  2.7067e-01,  8.8952e-01,\n",
      "          8.6913e-04,  2.0570e-03,  3.1855e-03,  5.0661e-03,  8.1912e-03,\n",
      "          1.9749e+02,  1.5996e+02,  1.6320e+02,  1.6655e+02,  1.5765e+02,\n",
      "          9.8779e-02,  1.3084e-01,  3.1232e-01,  3.6628e-01,  9.1776e-02],\n",
      "        [ 2.5680e+00,  2.7614e+00,  3.3969e+00,  3.1390e+00,  2.2835e+00,\n",
      "          4.4079e-03,  1.6594e-03,  1.5374e-02,  2.8304e-03,  3.5108e-04,\n",
      "          1.6421e+00,  2.0924e+00,  4.8997e+00,  3.5593e+00,  1.0973e+00,\n",
      "          2.9758e-01,  6.2140e-03, -1.5602e-02, -1.2149e-02, -8.1839e-03,\n",
      "          6.0275e-03,  2.8004e-02,  7.1294e-02,  2.7085e-01,  8.6953e-01,\n",
      "          9.0009e-04,  2.1138e-03,  3.1320e-03,  5.0616e-03,  8.0468e-03,\n",
      "          1.9325e+02,  1.5992e+02,  1.6453e+02,  1.6635e+02,  1.5643e+02,\n",
      "          7.9154e-02,  1.1643e-01,  3.1571e-01,  3.8499e-01,  1.0371e-01],\n",
      "        [ 2.7234e+00,  2.8571e+00,  3.4759e+00,  3.1047e+00,  2.2131e+00,\n",
      "          4.4296e-03,  5.6128e-03,  1.2836e-02,  6.7732e-04,  1.4212e-04,\n",
      "          1.9292e+00,  2.3152e+00,  5.5939e+00,  3.3923e+00,  9.8871e-01,\n",
      "          3.1378e-01,  1.0032e-02, -1.2134e-02, -1.0388e-02, -7.7879e-03,\n",
      "          6.1460e-03,  2.8575e-02,  6.8497e-02,  2.6205e-01,  8.7513e-01,\n",
      "          8.7515e-04,  2.0787e-03,  3.1440e-03,  5.0640e-03,  8.0384e-03,\n",
      "          1.9787e+02,  1.5973e+02,  1.6398e+02,  1.6663e+02,  1.5628e+02,\n",
      "          9.3352e-02,  1.2794e-01,  3.3582e-01,  3.5126e-01,  9.1629e-02],\n",
      "        [ 2.4525e+00,  2.6185e+00,  3.1628e+00,  2.8541e+00,  1.9214e+00,\n",
      "          2.1403e-03,  1.0061e-03,  2.8391e-03,  5.2964e-04,  1.0922e-04,\n",
      "          1.3872e+00,  1.7245e+00,  3.6272e+00,  2.4063e+00,  6.6187e-01,\n",
      "          3.0481e-01,  6.0146e-03, -7.3615e-03, -9.9624e-03, -9.9248e-03,\n",
      "          6.1996e-03,  2.7336e-02,  6.9574e-02,  2.6053e-01,  8.9841e-01,\n",
      "          8.9641e-04,  2.0805e-03,  3.1553e-03,  5.0229e-03,  8.0707e-03,\n",
      "          1.9093e+02,  1.6016e+02,  1.6391e+02,  1.6730e+02,  1.5632e+02,\n",
      "          9.6705e-02,  1.3491e-01,  3.1528e-01,  3.6180e-01,  9.1305e-02],\n",
      "        [ 2.7631e+00,  2.9104e+00,  3.6025e+00,  3.1897e+00,  2.2510e+00,\n",
      "          5.6552e-03,  6.8093e-03,  2.2548e-02,  3.4035e-03,  1.3442e-04,\n",
      "          2.1259e+00,  2.5024e+00,  6.5747e+00,  3.8266e+00,  1.0425e+00,\n",
      "          3.2764e-01,  5.9276e-03, -1.1141e-02, -8.0328e-03, -8.6533e-03,\n",
      "          5.9420e-03,  2.9013e-02,  7.0362e-02,  2.6181e-01,  8.7484e-01,\n",
      "          8.8976e-04,  2.1182e-03,  3.1324e-03,  4.9804e-03,  8.0010e-03,\n",
      "          1.9757e+02,  1.5895e+02,  1.6494e+02,  1.6647e+02,  1.5592e+02,\n",
      "          8.5089e-02,  1.2421e-01,  3.5019e-01,  3.5203e-01,  8.8478e-02],\n",
      "        [ 3.0500e+00,  3.3327e+00,  3.9986e+00,  3.4347e+00,  2.5753e+00,\n",
      "          6.0774e-03,  1.4630e-02,  1.0780e-01,  4.0419e-03,  2.2463e-04,\n",
      "          3.1645e+00,  4.7030e+00,  1.2153e+01,  5.4100e+00,  1.6314e+00,\n",
      "          2.7834e-01,  6.9657e-03, -8.5067e-03, -1.0518e-02, -9.0416e-03,\n",
      "          6.6234e-03,  2.8991e-02,  6.3549e-02,  2.5898e-01,  9.0846e-01,\n",
      "          9.3486e-04,  2.0349e-03,  3.2026e-03,  5.1435e-03,  8.2012e-03,\n",
      "          1.9016e+02,  1.5865e+02,  1.6327e+02,  1.6822e+02,  1.5753e+02,\n",
      "          8.4412e-02,  1.3959e-01,  3.7485e-01,  3.1234e-01,  8.8803e-02],\n",
      "        [ 2.9869e+00,  3.2554e+00,  4.0318e+00,  3.4237e+00,  2.5606e+00,\n",
      "          1.1982e-02,  1.1307e-02,  8.6130e-02,  9.2328e-03,  5.9804e-04,\n",
      "          2.8967e+00,  4.0797e+00,  1.2398e+01,  5.2387e+00,  1.5553e+00,\n",
      "          2.6229e-01,  5.7270e-03, -8.6630e-03, -8.7267e-03, -7.3395e-03,\n",
      "          6.6168e-03,  2.7350e-02,  6.9937e-02,  2.4766e-01,  9.3598e-01,\n",
      "          9.2090e-04,  2.1368e-03,  3.0522e-03,  5.2068e-03,  8.0528e-03,\n",
      "          1.8956e+02,  1.5777e+02,  1.6475e+02,  1.6936e+02,  1.5580e+02,\n",
      "          8.0582e-02,  1.3274e-01,  3.8605e-01,  3.0662e-01,  9.4008e-02],\n",
      "        [ 2.7824e+00,  2.9884e+00,  3.5072e+00,  3.1008e+00,  2.1368e+00,\n",
      "          1.8098e-03,  8.7495e-03,  1.8440e-02,  1.4672e-03,  1.4342e-04,\n",
      "          2.1826e+00,  2.8850e+00,  5.9685e+00,  3.4010e+00,  8.9778e-01,\n",
      "          2.8449e-01,  7.6772e-03, -9.9380e-03, -1.0587e-02, -1.0074e-02,\n",
      "          6.1797e-03,  2.8950e-02,  6.5297e-02,  2.4685e-01,  8.9217e-01,\n",
      "          8.9332e-04,  2.0246e-03,  3.1558e-03,  5.0509e-03,  8.2128e-03,\n",
      "          1.9495e+02,  1.6034e+02,  1.6285e+02,  1.6751e+02,  1.5788e+02,\n",
      "          9.7630e-02,  1.4864e-01,  3.3798e-01,  3.3475e-01,  8.1001e-02],\n",
      "        [ 2.7075e+00,  2.7572e+00,  3.3241e+00,  2.9828e+00,  2.1152e+00,\n",
      "          5.2891e-03,  1.9009e-03,  6.6825e-03,  8.6334e-04,  1.4082e-04,\n",
      "          1.9431e+00,  2.0716e+00,  4.5831e+00,  2.8814e+00,  8.5993e-01,\n",
      "          3.0899e-01,  9.6487e-03, -6.1765e-03, -9.5439e-03, -8.3191e-03,\n",
      "          5.7390e-03,  2.7209e-02,  6.9174e-02,  2.6063e-01,  9.0694e-01,\n",
      "          8.4281e-04,  2.0877e-03,  3.1422e-03,  5.1309e-03,  8.0250e-03,\n",
      "          1.9736e+02,  1.5965e+02,  1.6352e+02,  1.6773e+02,  1.5581e+02,\n",
      "          1.0720e-01,  1.3217e-01,  3.1602e-01,  3.4756e-01,  9.7049e-02],\n",
      "        [ 2.6711e+00,  2.7302e+00,  3.2586e+00,  2.9670e+00,  2.1014e+00,\n",
      "          1.3719e-03,  3.9886e-03,  8.2412e-03,  1.8902e-03,  1.7151e-04,\n",
      "          1.8756e+00,  2.0120e+00,  4.1139e+00,  2.8259e+00,  8.4571e-01,\n",
      "          3.2324e-01,  1.1444e-02, -7.0049e-03, -9.0492e-03, -6.7167e-03,\n",
      "          6.1677e-03,  2.7513e-02,  7.0378e-02,  2.5907e-01,  8.9967e-01,\n",
      "          8.5509e-04,  2.0825e-03,  3.1239e-03,  5.1788e-03,  8.0203e-03,\n",
      "          1.9607e+02,  1.6037e+02,  1.6315e+02,  1.6734e+02,  1.5587e+02,\n",
      "          1.0718e-01,  1.3231e-01,  3.0559e-01,  3.5735e-01,  9.7566e-02],\n",
      "        [ 2.6050e+00,  2.7646e+00,  3.2601e+00,  3.0332e+00,  2.1936e+00,\n",
      "          1.7637e-03,  1.6648e-03,  5.8903e-04,  7.8768e-04,  1.1815e-04,\n",
      "          1.7024e+00,  2.1060e+00,  4.1584e+00,  3.0934e+00,  9.6217e-01,\n",
      "          2.9227e-01,  9.8073e-03, -7.9138e-03, -8.8141e-03, -7.3776e-03,\n",
      "          6.1676e-03,  2.7574e-02,  7.0254e-02,  2.5872e-01,  8.8403e-01,\n",
      "          8.7945e-04,  2.0769e-03,  3.1630e-03,  5.1827e-03,  8.0314e-03,\n",
      "          1.9201e+02,  1.6091e+02,  1.6292e+02,  1.6717e+02,  1.5598e+02,\n",
      "          9.4390e-02,  1.3187e-01,  2.9392e-01,  3.7533e-01,  1.0449e-01],\n",
      "        [ 2.4718e+00,  2.6869e+00,  3.2730e+00,  2.8759e+00,  1.9352e+00,\n",
      "          1.4158e-03,  2.1838e-03,  1.0993e-02,  6.3724e-04,  6.6122e-05,\n",
      "          1.4202e+00,  1.9144e+00,  4.3304e+00,  2.4890e+00,  6.7660e-01,\n",
      "          3.0155e-01,  5.3414e-03, -9.5984e-03, -1.1166e-02, -1.0162e-02,\n",
      "          6.2843e-03,  2.8336e-02,  6.5735e-02,  2.5069e-01,  8.9624e-01,\n",
      "          9.1159e-04,  2.0484e-03,  3.1638e-03,  5.0600e-03,  8.1734e-03,\n",
      "          1.9163e+02,  1.5967e+02,  1.6312e+02,  1.6766e+02,  1.5744e+02,\n",
      "          9.1070e-02,  1.3735e-01,  3.4146e-01,  3.4374e-01,  8.6382e-02],\n",
      "        [ 2.9854e+00,  3.2086e+00,  3.7997e+00,  3.3025e+00,  2.4228e+00,\n",
      "          5.5397e-03,  1.1016e-02,  4.0862e-02,  5.2611e-03,  4.9338e-04,\n",
      "          2.7410e+00,  3.8736e+00,  9.0228e+00,  4.4711e+00,  1.3039e+00,\n",
      "          2.8190e-01,  6.6491e-03, -4.3623e-03, -8.2419e-03, -6.8997e-03,\n",
      "          6.2855e-03,  3.0017e-02,  6.3597e-02,  2.5514e-01,  9.1441e-01,\n",
      "          8.9071e-04,  2.0163e-03,  3.2038e-03,  5.1337e-03,  8.0347e-03,\n",
      "          1.9726e+02,  1.5948e+02,  1.6289e+02,  1.6873e+02,  1.5576e+02,\n",
      "          9.4956e-02,  1.4094e-01,  3.5429e-01,  3.2128e-01,  8.8524e-02]]), 0)\n"
     ]
    }
   ],
   "source": [
    "from torcheeg import transforms\n",
    "from torcheeg.datasets import NumpyDataset\n",
    "\n",
    "dataset = NumpyDataset(X=X,\n",
    "                       y=y,\n",
    "                       io_path=r'C:\\Users\\bugs_\\PycharmProjects\\eegProject\\torcheegProj\\DGCNN\\origin\\features\\Avg\\All40',\n",
    "                       online_transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]),\n",
    "                       offline_transform=transforms.Concatenate([\n",
    "                           transforms.BandDifferentialEntropy(sampling_rate=200,\n",
    "                                                              band_dict={\n",
    "                                                                  \"delta\": (1, 4),\n",
    "                                                                  \"theta\": (4, 8),\n",
    "                                                                  \"alpha\": (8, 13),\n",
    "                                                                  \"beta\": (13, 30),\n",
    "                                                                  \"gamma\": (30, 44)\n",
    "                                                              }),\n",
    "                           # transforms.BandKurtosis(sampling_rate=200,\n",
    "                           #                         band_dict={\n",
    "                           #                            \"delta\": (1, 4),\n",
    "                           #                            \"theta\": (4, 8),\n",
    "                           #                            \"alpha\": (8, 13),\n",
    "                           #                            \"beta\": (13, 30),\n",
    "                           #                            \"gamma\": (30, 44)\n",
    "                           #                         })\n",
    "                           # transforms.BandPowerSpectralDensity(sampling_rate=200,\n",
    "                           #                                     band_dict={\n",
    "                           #                                        \"delta\": (1, 4),\n",
    "                           #                                        \"theta\": (4, 8),\n",
    "                           #                                        \"alpha\": (8, 13),\n",
    "                           #                                        \"beta\": (13, 30),\n",
    "                           #                                        \"gamma\": (30, 44)\n",
    "                           #                                    }),\n",
    "                           # transforms.BandMeanAbsoluteDeviation(sampling_rate=200, \n",
    "                           #                                      band_dict={\n",
    "                           #                                        \"delta\": (1, 4),\n",
    "                           #                                        \"theta\": (4, 8),\n",
    "                           #                                        \"alpha\": (8, 13),\n",
    "                           #                                        \"beta\": (13, 30),\n",
    "                           #                                        \"gamma\": (30, 44)\n",
    "                           #                                    }),\n",
    "                           # transforms.BandDetrendedFluctuationAnalysis(sampling_rate=200, \n",
    "                           #                                             band_dict={\n",
    "                           #                                            \"delta\": (1, 4),\n",
    "                           #                                            \"theta\": (4, 8),\n",
    "                           #                                            \"alpha\": (8, 13),\n",
    "                           #                                            \"beta\": (13, 30),\n",
    "                           #                                            \"gamma\": (30, 44)\n",
    "                           #                                             }),\n",
    "                           # transforms.BandHiguchiFractalDimension(sampling_rate=200, \n",
    "                           #                                        band_dict={\n",
    "                           #                                        \"delta\": (1, 4),\n",
    "                           #                                        \"theta\": (4, 8),\n",
    "                           #                                        \"alpha\": (8, 13),\n",
    "                           #                                        \"beta\": (13, 30),\n",
    "                           #                                        \"gamma\": (30, 44)\n",
    "                           #                                        }),\n",
    "                           # transforms.BandHjorth(mode='mobility',\n",
    "                           #                       band_dict={\n",
    "                           #                            \"delta\": (1, 4),\n",
    "                           #                            \"theta\": (4, 8),\n",
    "                           #                            \"alpha\": (8, 13),\n",
    "                           #                            \"beta\": (13, 30),\n",
    "                           #                            \"gamma\": (30, 44)\n",
    "                           #                       }),\n",
    "                           # transforms.BandHjorth(mode='complexity',\n",
    "                           #                       band_dict={\n",
    "                           #                            \"delta\": (1, 4),\n",
    "                           #                            \"theta\": (4, 8),\n",
    "                           #                            \"alpha\": (8, 13),\n",
    "                           #                            \"beta\": (13, 30),\n",
    "                           #                            \"gamma\": (30, 44)\n",
    "                           #                       }),\n",
    "                           # transforms.BandBinPower(sampling_rate=200, \n",
    "                           #                         band_dict={\n",
    "                           #                                        \"delta\": (1, 4),\n",
    "                           #                                        \"theta\": (4, 8),\n",
    "                           #                                        \"alpha\": (8, 13),\n",
    "                           #                                        \"beta\": (13, 30),\n",
    "                           #                                        \"gamma\": (30, 44) \n",
    "                           #                         })\n",
    "                       ]), \n",
    "                       label_transform=transforms.Select('label'),\n",
    "                       num_worker=4\n",
    "                       )\n",
    "print(dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T09:00:22.255972200Z",
     "start_time": "2023-08-08T09:00:18.815619800Z"
    }
   },
   "id": "23083762c186052d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.90573907e+00,  2.86032891e+00,  3.47768044e+00,\n         3.08806610e+00,  2.21800566e+00,  2.60272273e-03,\n         2.40133749e-03,  2.32777726e-02,  1.84238493e-03,\n         1.41616838e-04,  2.56456113e+00,  2.42757130e+00,\n         5.68477678e+00,  3.32848835e+00,  9.95412350e-01,\n         3.42272431e-01,  9.35095642e-03, -4.83454857e-03,\n        -1.04669714e-02, -7.30280345e-03,  5.41967014e-03,\n         2.81269923e-02,  6.67802617e-02,  2.74565548e-01,\n         9.13177073e-01,  8.04065028e-04,  2.05407175e-03,\n         3.17353895e-03,  5.10306982e-03,  8.10850691e-03,\n         2.07768097e+02,  1.59420761e+02,  1.63754425e+02,\n         1.67144928e+02,  1.56732544e+02,  1.19241044e-01,\n         1.25178814e-01,  3.24458569e-01,  3.37925136e-01,\n         9.31964144e-02],\n       [ 2.89650464e+00,  2.84416437e+00,  3.45011640e+00,\n         3.05413675e+00,  2.18107462e+00,  1.18177535e-03,\n         2.02848902e-03,  1.58724468e-02,  2.03024852e-03,\n         1.50304870e-04,  2.52600288e+00,  2.36539984e+00,\n         5.45994473e+00,  3.18390989e+00,  9.39338863e-01,\n         3.37460667e-01,  8.58538225e-03, -4.81686741e-03,\n        -9.46576521e-03, -7.55840214e-03,  5.20888017e-03,\n         2.79055461e-02,  6.75255880e-02,  2.71167070e-01,\n         9.07485485e-01,  8.05085758e-04,  2.06368975e-03,\n         3.16097890e-03,  5.09220455e-03,  8.05931725e-03,\n         2.06275986e+02,  1.59448181e+02,  1.64256607e+02,\n         1.67436371e+02,  1.56273529e+02,  1.20688610e-01,\n         1.26987800e-01,  3.25440019e-01,  3.34755570e-01,\n         9.21280161e-02],\n       [ 2.33820033e+00,  2.50544834e+00,  3.19224310e+00,\n         2.69526672e+00,  1.86414897e+00,  3.06116912e-04,\n         6.72130787e-04,  1.37296962e-02,  1.21189433e-03,\n         7.27361767e-05,  1.18276548e+00,  1.47454512e+00,\n         3.88119030e+00,  1.92580628e+00,  6.09844327e-01,\n         2.93205738e-01,  8.39431025e-03, -8.84416141e-03,\n        -9.99807380e-03, -5.00473240e-03,  6.17606519e-03,\n         2.90680137e-02,  6.56087622e-02,  2.66893953e-01,\n         8.90756607e-01,  8.84874491e-04,  2.05797073e-03,\n         3.15632019e-03,  5.16165607e-03,  8.14018957e-03,\n         1.97108582e+02,  1.58789169e+02,  1.63679733e+02,\n         1.67196564e+02,  1.57147171e+02,  9.17687863e-02,\n         1.27530083e-01,  3.57249618e-01,  3.29431415e-01,\n         9.40200984e-02],\n       [ 2.86582685e+00,  2.98499346e+00,  3.54536676e+00,\n         3.22813797e+00,  2.31638145e+00,  5.21826884e-03,\n         2.53995298e-03,  1.84023939e-02,  2.48891534e-03,\n         2.22959105e-04,  2.42431688e+00,  2.85017586e+00,\n         6.26039362e+00,  3.98983192e+00,  1.14291477e+00,\n         3.05009931e-01,  9.43684950e-03, -7.37578608e-03,\n        -1.14344079e-02, -7.94350449e-03,  5.59817394e-03,\n         2.78763846e-02,  6.75712153e-02,  2.70666152e-01,\n         8.89518797e-01,  8.69129784e-04,  2.05702311e-03,\n         3.18547525e-03,  5.06611262e-03,  8.19117203e-03,\n         1.97493576e+02,  1.59958679e+02,  1.63198685e+02,\n         1.66545639e+02,  1.57648376e+02,  9.87791345e-02,\n         1.30842522e-01,  3.12318653e-01,  3.66283983e-01,\n         9.17756930e-02],\n       [ 2.56799173e+00,  2.76135635e+00,  3.39694571e+00,\n         3.13904500e+00,  2.28346896e+00,  4.40786080e-03,\n         1.65943650e-03,  1.53739136e-02,  2.83035985e-03,\n         3.51080700e-04,  1.64208674e+00,  2.09242439e+00,\n         4.89970541e+00,  3.55934978e+00,  1.09733403e+00,\n         2.97578037e-01,  6.21396443e-03, -1.56021798e-02,\n        -1.21493973e-02, -8.18394683e-03,  6.02753833e-03,\n         2.80042328e-02,  7.12942183e-02,  2.70846665e-01,\n         8.69528830e-01,  9.00091254e-04,  2.11380119e-03,\n         3.13201500e-03,  5.06164413e-03,  8.04684125e-03,\n         1.93250229e+02,  1.59922058e+02,  1.64528625e+02,\n         1.66354080e+02,  1.56428574e+02,  7.91543350e-02,\n         1.16432309e-01,  3.15707952e-01,  3.84993017e-01,\n         1.03712410e-01],\n       [ 2.72337890e+00,  2.85709977e+00,  3.47593522e+00,\n         3.10470247e+00,  2.21314216e+00,  4.42958670e-03,\n         5.61284460e-03,  1.28358416e-02,  6.77324424e-04,\n         1.42121455e-04,  1.92924118e+00,  2.31523156e+00,\n         5.59386969e+00,  3.39228773e+00,  9.88714397e-01,\n         3.13784003e-01,  1.00317588e-02, -1.21341022e-02,\n        -1.03884013e-02, -7.78785627e-03,  6.14602724e-03,\n         2.85749435e-02,  6.84973747e-02,  2.62053639e-01,\n         8.75130892e-01,  8.75154918e-04,  2.07873574e-03,\n         3.14395293e-03,  5.06397523e-03,  8.03836808e-03,\n         1.97871399e+02,  1.59731216e+02,  1.63983200e+02,\n         1.66633713e+02,  1.56282928e+02,  9.33522731e-02,\n         1.27944037e-01,  3.35819334e-01,  3.51255447e-01,\n         9.16289091e-02],\n       [ 2.45254517e+00,  2.61853361e+00,  3.16278005e+00,\n         2.85409141e+00,  1.92142224e+00,  2.14027055e-03,\n         1.00605888e-03,  2.83905142e-03,  5.29640645e-04,\n         1.09215223e-04,  1.38724005e+00,  1.72445321e+00,\n         3.62717295e+00,  2.40632248e+00,  6.61872983e-01,\n         3.04813415e-01,  6.01459481e-03, -7.36146094e-03,\n        -9.96239111e-03, -9.92479455e-03,  6.19960390e-03,\n         2.73358971e-02,  6.95742369e-02,  2.60529041e-01,\n         8.98413241e-01,  8.96414160e-04,  2.08045822e-03,\n         3.15531692e-03,  5.02288388e-03,  8.07074830e-03,\n         1.90929779e+02,  1.60157440e+02,  1.63911392e+02,\n         1.67302780e+02,  1.56323303e+02,  9.67051163e-02,\n         1.34912029e-01,  3.15281600e-01,  3.61795902e-01,\n         9.13053602e-02],\n       [ 2.76314211e+00,  2.91040659e+00,  3.60250330e+00,\n         3.18968225e+00,  2.25098610e+00,  5.65522956e-03,\n         6.80933287e-03,  2.25479472e-02,  3.40347877e-03,\n         1.34417220e-04,  2.12594390e+00,  2.50244808e+00,\n         6.57466602e+00,  3.82657504e+00,  1.04249954e+00,\n         3.27642143e-01,  5.92758507e-03, -1.11413170e-02,\n        -8.03280994e-03, -8.65329336e-03,  5.94204757e-03,\n         2.90129296e-02,  7.03622252e-02,  2.61811316e-01,\n         8.74839723e-01,  8.89763643e-04,  2.11822032e-03,\n         3.13237007e-03,  4.98043047e-03,  8.00096337e-03,\n         1.97565155e+02,  1.58951553e+02,  1.64935623e+02,\n         1.66472580e+02,  1.55922653e+02,  8.50886703e-02,\n         1.24211699e-01,  3.50192785e-01,  3.52028906e-01,\n         8.84779245e-02],\n       [ 3.04997182e+00,  3.33267355e+00,  3.99863935e+00,\n         3.43473554e+00,  2.57534838e+00,  6.07740739e-03,\n         1.46301156e-02,  1.07803971e-01,  4.04185615e-03,\n         2.24632604e-04,  3.16452217e+00,  4.70302773e+00,\n         1.21534319e+01,  5.40998459e+00,  1.63135767e+00,\n         2.78339684e-01,  6.96572941e-03, -8.50673951e-03,\n        -1.05183171e-02, -9.04157478e-03,  6.62340270e-03,\n         2.89912876e-02,  6.35486469e-02,  2.58977354e-01,\n         9.08459306e-01,  9.34862008e-04,  2.03493563e-03,\n         3.20261368e-03,  5.14351018e-03,  8.20124056e-03,\n         1.90164139e+02,  1.58653442e+02,  1.63274017e+02,\n         1.68218857e+02,  1.57525970e+02,  8.44121948e-02,\n         1.39592439e-01,  3.74850541e-01,  3.12341750e-01,\n         8.88030753e-02],\n       [ 2.98688602e+00,  3.25540876e+00,  4.03179407e+00,\n         3.42371297e+00,  2.56057048e+00,  1.19823879e-02,\n         1.13066919e-02,  8.61302763e-02,  9.23280604e-03,\n         5.98036626e-04,  2.89674187e+00,  4.07968426e+00,\n         1.23976870e+01,  5.23871803e+00,  1.55527115e+00,\n         2.62289703e-01,  5.72704803e-03, -8.66301358e-03,\n        -8.72672908e-03, -7.33949430e-03,  6.61682896e-03,\n         2.73504872e-02,  6.99367151e-02,  2.47661054e-01,\n         9.35979366e-01,  9.20898165e-04,  2.13681813e-03,\n         3.05223628e-03,  5.20684617e-03,  8.05281941e-03,\n         1.89562668e+02,  1.57772339e+02,  1.64745224e+02,\n         1.69355347e+02,  1.55801895e+02,  8.05822685e-02,\n         1.32739291e-01,  3.86048377e-01,  3.06621701e-01,\n         9.40083638e-02],\n       [ 2.78236103e+00,  2.98836613e+00,  3.50719810e+00,\n         3.10083699e+00,  2.13683319e+00,  1.80976780e-03,\n         8.74952972e-03,  1.84403118e-02,  1.46724435e-03,\n         1.43417536e-04,  2.18261027e+00,  2.88499188e+00,\n         5.96849108e+00,  3.40095782e+00,  8.97776425e-01,\n         2.84493238e-01,  7.67723564e-03, -9.93803423e-03,\n        -1.05870366e-02, -1.00743491e-02,  6.17967360e-03,\n         2.89500896e-02,  6.52967617e-02,  2.46851921e-01,\n         8.92167747e-01,  8.93322169e-04,  2.02457397e-03,\n         3.15581076e-03,  5.05089341e-03,  8.21284484e-03,\n         1.94947388e+02,  1.60342056e+02,  1.62850464e+02,\n         1.67507736e+02,  1.57878983e+02,  9.76300389e-02,\n         1.48642883e-01,  3.37978423e-01,  3.34747225e-01,\n         8.10014158e-02],\n       [ 2.70753884e+00,  2.75717092e+00,  3.32413793e+00,\n         2.98277950e+00,  2.11521339e+00,  5.28911361e-03,\n         1.90092623e-03,  6.68246904e-03,  8.63340567e-04,\n         1.40824661e-04,  1.94306839e+00,  2.07160020e+00,\n         4.58311510e+00,  2.88135791e+00,  8.59928191e-01,\n         3.08994234e-01,  9.64872912e-03, -6.17654528e-03,\n        -9.54394601e-03, -8.31905846e-03,  5.73896570e-03,\n         2.72091217e-02,  6.91743568e-02,  2.60628521e-01,\n         9.06938672e-01,  8.42810899e-04,  2.08769273e-03,\n         3.14223533e-03,  5.13092382e-03,  8.02503061e-03,\n         1.97355774e+02,  1.59649246e+02,  1.63518860e+02,\n         1.67733902e+02,  1.55813858e+02,  1.07204579e-01,\n         1.32166579e-01,  3.16016912e-01,  3.47562730e-01,\n         9.70492065e-02],\n       [ 2.67108464e+00,  2.73017287e+00,  3.25863695e+00,\n         2.96697235e+00,  2.10136867e+00,  1.37193676e-03,\n         3.98858963e-03,  8.24122317e-03,  1.89020275e-03,\n         1.71514694e-04,  1.87556660e+00,  2.01196337e+00,\n         4.11390162e+00,  2.82590628e+00,  8.45714152e-01,\n         3.23236495e-01,  1.14437323e-02, -7.00493762e-03,\n        -9.04917344e-03, -6.71666255e-03,  6.16770238e-03,\n         2.75134891e-02,  7.03781918e-02,  2.59074152e-01,\n         8.99673760e-01,  8.55094811e-04,  2.08246382e-03,\n         3.12391366e-03,  5.17879287e-03,  8.02025944e-03,\n         1.96065659e+02,  1.60366211e+02,  1.63154709e+02,\n         1.67339005e+02,  1.55870850e+02,  1.07180916e-01,\n         1.32314250e-01,  3.05586308e-01,  3.57352257e-01,\n         9.75662544e-02],\n       [ 2.60503626e+00,  2.76458526e+00,  3.26012945e+00,\n         3.03315949e+00,  2.19358015e+00,  1.76370388e-03,\n         1.66475191e-03,  5.89033996e-04,  7.87681318e-04,\n         1.18146942e-04,  1.70235491e+00,  2.10598254e+00,\n         4.15839672e+00,  3.09342909e+00,  9.62174237e-01,\n         2.92266756e-01,  9.80728213e-03, -7.91381579e-03,\n        -8.81414581e-03, -7.37764500e-03,  6.16755662e-03,\n         2.75741480e-02,  7.02540204e-02,  2.58715481e-01,\n         8.84025335e-01,  8.79452389e-04,  2.07691174e-03,\n         3.16297938e-03,  5.18274540e-03,  8.03141948e-03,\n         1.92005905e+02,  1.60911301e+02,  1.62918716e+02,\n         1.67171616e+02,  1.55982437e+02,  9.43902284e-02,\n         1.31869078e-01,  2.93923408e-01,  3.75329942e-01,\n         1.04487374e-01],\n       [ 2.47180367e+00,  2.68690157e+00,  3.27299142e+00,\n         2.87590599e+00,  1.93520558e+00,  1.41575385e-03,\n         2.18379544e-03,  1.09934602e-02,  6.37241057e-04,\n         6.61219310e-05,  1.42021966e+00,  1.91441560e+00,\n         4.33037710e+00,  2.48900008e+00,  6.76604092e-01,\n         3.01549971e-01,  5.34141762e-03, -9.59844422e-03,\n        -1.11656338e-02, -1.01622539e-02,  6.28428487e-03,\n         2.83364598e-02,  6.57349750e-02,  2.50694871e-01,\n         8.96237016e-01,  9.11587034e-04,  2.04844074e-03,\n         3.16376728e-03,  5.06004039e-03,  8.17335211e-03,\n         1.91634338e+02,  1.59665344e+02,  1.63119263e+02,\n         1.67661743e+02,  1.57443420e+02,  9.10700262e-02,\n         1.37349427e-01,  3.41461390e-01,  3.43737006e-01,\n         8.63821432e-02],\n       [ 2.98540187e+00,  3.20862651e+00,  3.79972053e+00,\n         3.30252838e+00,  2.42282033e+00,  5.53965941e-03,\n         1.10159647e-02,  4.08623293e-02,  5.26112784e-03,\n         4.93376807e-04,  2.74098992e+00,  3.87358713e+00,\n         9.02278423e+00,  4.47106314e+00,  1.30391538e+00,\n         2.81904519e-01,  6.64905878e-03, -4.36234148e-03,\n        -8.24187975e-03, -6.89967303e-03,  6.28550351e-03,\n         3.00171673e-02,  6.35969192e-02,  2.55141854e-01,\n         9.14408147e-01,  8.90714466e-04,  2.01627146e-03,\n         3.20377643e-03,  5.13368333e-03,  8.03465769e-03,\n         1.97261688e+02,  1.59480927e+02,  1.62892532e+02,\n         1.68732330e+02,  1.55756912e+02,  9.49562266e-02,\n         1.40942618e-01,  3.54293078e-01,  3.21283907e-01,\n         8.85241777e-02]], dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T09:01:00.248438700Z",
     "start_time": "2023-08-08T09:01:00.224915900Z"
    }
   },
   "id": "f31933df588281ea"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=5,\n",
    "               split_path=f'./tmp_out/split_5',\n",
    "               shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T05:38:17.144606600Z",
     "start_time": "2023-08-04T05:38:17.085606300Z"
    }
   },
   "id": "a8943e5d42b25d47"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T05:38:21.090243600Z",
     "start_time": "2023-08-04T05:38:21.071573300Z"
    }
   },
   "id": "1b210efef3596322"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import writer\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    global total_train_step\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "\n",
    "        # if batch_idx % 100 == 0:\n",
    "        loss, current = loss.item(), batch_idx * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        writer.add_scalar(\"train_loss\", loss, total_train_step)\n",
    "        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    train_correct /= size\n",
    "    writer.add_scalar(\"train_auc\", train_correct, total_train_step)\n",
    "    print(f\"Train Error: \\n Accuracy: {(100 * train_correct):>0.1f}% \")\n",
    "\n",
    "def valid(dataloader, model, loss_fn):\n",
    "    global total_val_step\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    writer.add_scalar(\"test_avg_loss\", val_loss, total_val_step)\n",
    "    writer.add_scalar(\"test_auc\", correct, total_val_step)\n",
    "    total_val_step += 1\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T05:38:23.751835100Z",
     "start_time": "2023-08-04T05:38:23.552754700Z"
    }
   },
   "id": "eb35148cf53531f2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.140611  [    0/13920]\n",
      "loss: 1.103626  [   64/13920]\n",
      "loss: 0.919332  [  128/13920]\n",
      "loss: 0.929460  [  192/13920]\n",
      "loss: 1.085753  [  256/13920]\n",
      "loss: 0.996086  [  320/13920]\n",
      "loss: 0.962318  [  384/13920]\n",
      "loss: 0.988241  [  448/13920]\n",
      "loss: 0.935223  [  512/13920]\n",
      "loss: 0.991930  [  576/13920]\n",
      "loss: 0.892168  [  640/13920]\n",
      "loss: 0.906935  [  704/13920]\n",
      "loss: 0.959001  [  768/13920]\n",
      "loss: 0.927891  [  832/13920]\n",
      "loss: 0.899170  [  896/13920]\n",
      "loss: 0.758602  [  960/13920]\n",
      "loss: 1.032525  [ 1024/13920]\n",
      "loss: 0.799099  [ 1088/13920]\n",
      "loss: 0.869301  [ 1152/13920]\n",
      "loss: 0.745384  [ 1216/13920]\n",
      "loss: 0.940887  [ 1280/13920]\n",
      "loss: 0.862875  [ 1344/13920]\n",
      "loss: 0.909645  [ 1408/13920]\n",
      "loss: 0.881026  [ 1472/13920]\n",
      "loss: 0.789544  [ 1536/13920]\n",
      "loss: 0.804044  [ 1600/13920]\n",
      "loss: 0.887467  [ 1664/13920]\n",
      "loss: 0.837257  [ 1728/13920]\n",
      "loss: 0.753794  [ 1792/13920]\n",
      "loss: 0.898825  [ 1856/13920]\n",
      "loss: 0.905080  [ 1920/13920]\n",
      "loss: 0.998252  [ 1984/13920]\n",
      "loss: 0.849637  [ 2048/13920]\n",
      "loss: 0.769875  [ 2112/13920]\n",
      "loss: 0.855480  [ 2176/13920]\n",
      "loss: 0.851545  [ 2240/13920]\n",
      "loss: 0.917942  [ 2304/13920]\n",
      "loss: 0.755101  [ 2368/13920]\n",
      "loss: 0.862833  [ 2432/13920]\n",
      "loss: 0.730279  [ 2496/13920]\n",
      "loss: 0.934473  [ 2560/13920]\n",
      "loss: 0.693952  [ 2624/13920]\n",
      "loss: 0.884853  [ 2688/13920]\n",
      "loss: 0.883919  [ 2752/13920]\n",
      "loss: 0.847360  [ 2816/13920]\n",
      "loss: 0.828579  [ 2880/13920]\n",
      "loss: 0.818740  [ 2944/13920]\n",
      "loss: 0.764804  [ 3008/13920]\n",
      "loss: 0.800582  [ 3072/13920]\n",
      "loss: 0.807440  [ 3136/13920]\n",
      "loss: 0.699654  [ 3200/13920]\n",
      "loss: 0.742029  [ 3264/13920]\n",
      "loss: 0.800906  [ 3328/13920]\n",
      "loss: 0.866037  [ 3392/13920]\n",
      "loss: 0.768499  [ 3456/13920]\n",
      "loss: 0.807343  [ 3520/13920]\n",
      "loss: 0.812332  [ 3584/13920]\n",
      "loss: 0.774594  [ 3648/13920]\n",
      "loss: 0.802848  [ 3712/13920]\n",
      "loss: 0.871997  [ 3776/13920]\n",
      "loss: 0.812119  [ 3840/13920]\n",
      "loss: 0.831157  [ 3904/13920]\n",
      "loss: 0.818973  [ 3968/13920]\n",
      "loss: 0.798355  [ 4032/13920]\n",
      "loss: 0.834727  [ 4096/13920]\n",
      "loss: 0.828202  [ 4160/13920]\n",
      "loss: 0.813853  [ 4224/13920]\n",
      "loss: 0.796688  [ 4288/13920]\n",
      "loss: 0.679226  [ 4352/13920]\n",
      "loss: 0.767420  [ 4416/13920]\n",
      "loss: 0.757149  [ 4480/13920]\n",
      "loss: 0.708371  [ 4544/13920]\n",
      "loss: 0.756737  [ 4608/13920]\n",
      "loss: 0.670571  [ 4672/13920]\n",
      "loss: 0.784269  [ 4736/13920]\n",
      "loss: 0.747889  [ 4800/13920]\n",
      "loss: 0.760781  [ 4864/13920]\n",
      "loss: 0.777688  [ 4928/13920]\n",
      "loss: 0.772748  [ 4992/13920]\n",
      "loss: 0.781178  [ 5056/13920]\n",
      "loss: 0.638852  [ 5120/13920]\n",
      "loss: 0.741565  [ 5184/13920]\n",
      "loss: 0.802055  [ 5248/13920]\n",
      "loss: 0.603084  [ 5312/13920]\n",
      "loss: 0.727805  [ 5376/13920]\n",
      "loss: 0.749444  [ 5440/13920]\n",
      "loss: 0.772386  [ 5504/13920]\n",
      "loss: 0.639951  [ 5568/13920]\n",
      "loss: 0.676691  [ 5632/13920]\n",
      "loss: 0.706369  [ 5696/13920]\n",
      "loss: 0.703209  [ 5760/13920]\n",
      "loss: 0.696670  [ 5824/13920]\n",
      "loss: 0.763091  [ 5888/13920]\n",
      "loss: 0.640925  [ 5952/13920]\n",
      "loss: 0.675751  [ 6016/13920]\n",
      "loss: 0.642789  [ 6080/13920]\n",
      "loss: 0.666531  [ 6144/13920]\n",
      "loss: 0.742479  [ 6208/13920]\n",
      "loss: 0.680223  [ 6272/13920]\n",
      "loss: 0.751635  [ 6336/13920]\n",
      "loss: 0.711386  [ 6400/13920]\n",
      "loss: 0.717332  [ 6464/13920]\n",
      "loss: 0.647199  [ 6528/13920]\n",
      "loss: 0.722445  [ 6592/13920]\n",
      "loss: 0.691164  [ 6656/13920]\n",
      "loss: 0.731141  [ 6720/13920]\n",
      "loss: 0.699050  [ 6784/13920]\n",
      "loss: 0.646874  [ 6848/13920]\n",
      "loss: 0.558910  [ 6912/13920]\n",
      "loss: 0.808735  [ 6976/13920]\n",
      "loss: 0.648843  [ 7040/13920]\n",
      "loss: 0.629634  [ 7104/13920]\n",
      "loss: 0.721791  [ 7168/13920]\n",
      "loss: 0.680248  [ 7232/13920]\n",
      "loss: 0.629818  [ 7296/13920]\n",
      "loss: 0.896055  [ 7360/13920]\n",
      "loss: 0.717245  [ 7424/13920]\n",
      "loss: 0.652395  [ 7488/13920]\n",
      "loss: 0.676198  [ 7552/13920]\n",
      "loss: 0.610368  [ 7616/13920]\n",
      "loss: 0.600972  [ 7680/13920]\n",
      "loss: 0.664567  [ 7744/13920]\n",
      "loss: 0.547755  [ 7808/13920]\n",
      "loss: 0.683023  [ 7872/13920]\n",
      "loss: 0.585566  [ 7936/13920]\n",
      "loss: 0.650303  [ 8000/13920]\n",
      "loss: 0.679890  [ 8064/13920]\n",
      "loss: 0.547642  [ 8128/13920]\n",
      "loss: 0.777638  [ 8192/13920]\n",
      "loss: 0.699411  [ 8256/13920]\n",
      "loss: 0.644172  [ 8320/13920]\n",
      "loss: 0.663286  [ 8384/13920]\n",
      "loss: 0.621365  [ 8448/13920]\n",
      "loss: 0.645839  [ 8512/13920]\n",
      "loss: 0.722946  [ 8576/13920]\n",
      "loss: 0.676085  [ 8640/13920]\n",
      "loss: 0.530205  [ 8704/13920]\n",
      "loss: 0.658267  [ 8768/13920]\n",
      "loss: 0.654326  [ 8832/13920]\n",
      "loss: 0.636973  [ 8896/13920]\n",
      "loss: 0.657043  [ 8960/13920]\n",
      "loss: 0.618615  [ 9024/13920]\n",
      "loss: 0.641993  [ 9088/13920]\n",
      "loss: 0.736662  [ 9152/13920]\n",
      "loss: 0.737465  [ 9216/13920]\n",
      "loss: 0.709787  [ 9280/13920]\n",
      "loss: 0.672121  [ 9344/13920]\n",
      "loss: 0.714315  [ 9408/13920]\n",
      "loss: 0.620156  [ 9472/13920]\n",
      "loss: 0.621743  [ 9536/13920]\n",
      "loss: 0.557730  [ 9600/13920]\n",
      "loss: 0.606615  [ 9664/13920]\n",
      "loss: 0.571349  [ 9728/13920]\n",
      "loss: 0.565374  [ 9792/13920]\n",
      "loss: 0.689571  [ 9856/13920]\n",
      "loss: 0.568845  [ 9920/13920]\n",
      "loss: 0.649667  [ 9984/13920]\n",
      "loss: 0.604061  [10048/13920]\n",
      "loss: 0.596846  [10112/13920]\n",
      "loss: 0.575886  [10176/13920]\n",
      "loss: 0.681667  [10240/13920]\n",
      "loss: 0.608403  [10304/13920]\n",
      "loss: 0.671332  [10368/13920]\n",
      "loss: 0.627104  [10432/13920]\n",
      "loss: 0.534870  [10496/13920]\n",
      "loss: 0.493695  [10560/13920]\n",
      "loss: 0.513398  [10624/13920]\n",
      "loss: 0.570420  [10688/13920]\n",
      "loss: 0.528621  [10752/13920]\n",
      "loss: 0.580972  [10816/13920]\n",
      "loss: 0.695838  [10880/13920]\n",
      "loss: 0.591237  [10944/13920]\n",
      "loss: 0.630920  [11008/13920]\n",
      "loss: 0.577270  [11072/13920]\n",
      "loss: 0.594653  [11136/13920]\n",
      "loss: 0.625947  [11200/13920]\n",
      "loss: 0.585922  [11264/13920]\n",
      "loss: 0.549634  [11328/13920]\n",
      "loss: 0.596209  [11392/13920]\n",
      "loss: 0.593769  [11456/13920]\n",
      "loss: 0.591960  [11520/13920]\n",
      "loss: 0.579185  [11584/13920]\n",
      "loss: 0.692939  [11648/13920]\n",
      "loss: 0.577767  [11712/13920]\n",
      "loss: 0.565872  [11776/13920]\n",
      "loss: 0.617526  [11840/13920]\n",
      "loss: 0.555671  [11904/13920]\n",
      "loss: 0.543360  [11968/13920]\n",
      "loss: 0.513732  [12032/13920]\n",
      "loss: 0.578833  [12096/13920]\n",
      "loss: 0.638806  [12160/13920]\n",
      "loss: 0.594219  [12224/13920]\n",
      "loss: 0.572158  [12288/13920]\n",
      "loss: 0.555668  [12352/13920]\n",
      "loss: 0.605815  [12416/13920]\n",
      "loss: 0.387745  [12480/13920]\n",
      "loss: 0.560111  [12544/13920]\n",
      "loss: 0.509411  [12608/13920]\n",
      "loss: 0.512426  [12672/13920]\n",
      "loss: 0.503435  [12736/13920]\n",
      "loss: 0.525027  [12800/13920]\n",
      "loss: 0.514585  [12864/13920]\n",
      "loss: 0.454934  [12928/13920]\n",
      "loss: 0.523453  [12992/13920]\n",
      "loss: 0.509347  [13056/13920]\n",
      "loss: 0.624015  [13120/13920]\n",
      "loss: 0.529155  [13184/13920]\n",
      "loss: 0.572693  [13248/13920]\n",
      "loss: 0.590152  [13312/13920]\n",
      "loss: 0.434390  [13376/13920]\n",
      "loss: 0.514570  [13440/13920]\n",
      "loss: 0.437895  [13504/13920]\n",
      "loss: 0.449543  [13568/13920]\n",
      "loss: 0.456740  [13632/13920]\n",
      "loss: 0.582239  [13696/13920]\n",
      "loss: 0.456742  [13760/13920]\n",
      "loss: 0.441008  [13824/13920]\n",
      "loss: 0.635774  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 69.2% \n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.519074 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.412080  [    0/13920]\n",
      "loss: 0.514885  [   64/13920]\n",
      "loss: 0.504648  [  128/13920]\n",
      "loss: 0.569997  [  192/13920]\n",
      "loss: 0.511035  [  256/13920]\n",
      "loss: 0.519044  [  320/13920]\n",
      "loss: 0.486734  [  384/13920]\n",
      "loss: 0.577035  [  448/13920]\n",
      "loss: 0.490840  [  512/13920]\n",
      "loss: 0.481594  [  576/13920]\n",
      "loss: 0.667202  [  640/13920]\n",
      "loss: 0.518595  [  704/13920]\n",
      "loss: 0.525774  [  768/13920]\n",
      "loss: 0.487569  [  832/13920]\n",
      "loss: 0.512775  [  896/13920]\n",
      "loss: 0.445593  [  960/13920]\n",
      "loss: 0.526190  [ 1024/13920]\n",
      "loss: 0.549789  [ 1088/13920]\n",
      "loss: 0.686435  [ 1152/13920]\n",
      "loss: 0.636264  [ 1216/13920]\n",
      "loss: 0.446550  [ 1280/13920]\n",
      "loss: 0.430227  [ 1344/13920]\n",
      "loss: 0.595199  [ 1408/13920]\n",
      "loss: 0.458520  [ 1472/13920]\n",
      "loss: 0.474050  [ 1536/13920]\n",
      "loss: 0.378173  [ 1600/13920]\n",
      "loss: 0.484317  [ 1664/13920]\n",
      "loss: 0.518858  [ 1728/13920]\n",
      "loss: 0.523285  [ 1792/13920]\n",
      "loss: 0.523328  [ 1856/13920]\n",
      "loss: 0.377775  [ 1920/13920]\n",
      "loss: 0.436329  [ 1984/13920]\n",
      "loss: 0.368638  [ 2048/13920]\n",
      "loss: 0.574740  [ 2112/13920]\n",
      "loss: 0.364428  [ 2176/13920]\n",
      "loss: 0.395858  [ 2240/13920]\n",
      "loss: 0.581971  [ 2304/13920]\n",
      "loss: 0.377429  [ 2368/13920]\n",
      "loss: 0.452653  [ 2432/13920]\n",
      "loss: 0.432776  [ 2496/13920]\n",
      "loss: 0.473993  [ 2560/13920]\n",
      "loss: 0.429523  [ 2624/13920]\n",
      "loss: 0.468906  [ 2688/13920]\n",
      "loss: 0.585679  [ 2752/13920]\n",
      "loss: 0.524501  [ 2816/13920]\n",
      "loss: 0.439431  [ 2880/13920]\n",
      "loss: 0.419640  [ 2944/13920]\n",
      "loss: 0.448298  [ 3008/13920]\n",
      "loss: 0.472363  [ 3072/13920]\n",
      "loss: 0.509394  [ 3136/13920]\n",
      "loss: 0.479887  [ 3200/13920]\n",
      "loss: 0.350692  [ 3264/13920]\n",
      "loss: 0.465113  [ 3328/13920]\n",
      "loss: 0.427216  [ 3392/13920]\n",
      "loss: 0.425321  [ 3456/13920]\n",
      "loss: 0.422832  [ 3520/13920]\n",
      "loss: 0.548393  [ 3584/13920]\n",
      "loss: 0.593148  [ 3648/13920]\n",
      "loss: 0.400422  [ 3712/13920]\n",
      "loss: 0.514116  [ 3776/13920]\n",
      "loss: 0.463369  [ 3840/13920]\n",
      "loss: 0.369230  [ 3904/13920]\n",
      "loss: 0.473140  [ 3968/13920]\n",
      "loss: 0.491504  [ 4032/13920]\n",
      "loss: 0.448314  [ 4096/13920]\n",
      "loss: 0.528901  [ 4160/13920]\n",
      "loss: 0.295146  [ 4224/13920]\n",
      "loss: 0.415587  [ 4288/13920]\n",
      "loss: 0.429314  [ 4352/13920]\n",
      "loss: 0.421417  [ 4416/13920]\n",
      "loss: 0.453086  [ 4480/13920]\n",
      "loss: 0.436000  [ 4544/13920]\n",
      "loss: 0.509355  [ 4608/13920]\n",
      "loss: 0.429875  [ 4672/13920]\n",
      "loss: 0.475501  [ 4736/13920]\n",
      "loss: 0.453518  [ 4800/13920]\n",
      "loss: 0.467952  [ 4864/13920]\n",
      "loss: 0.607767  [ 4928/13920]\n",
      "loss: 0.497516  [ 4992/13920]\n",
      "loss: 0.544338  [ 5056/13920]\n",
      "loss: 0.478267  [ 5120/13920]\n",
      "loss: 0.463765  [ 5184/13920]\n",
      "loss: 0.385315  [ 5248/13920]\n",
      "loss: 0.400943  [ 5312/13920]\n",
      "loss: 0.278005  [ 5376/13920]\n",
      "loss: 0.421368  [ 5440/13920]\n",
      "loss: 0.459600  [ 5504/13920]\n",
      "loss: 0.424603  [ 5568/13920]\n",
      "loss: 0.346770  [ 5632/13920]\n",
      "loss: 0.437002  [ 5696/13920]\n",
      "loss: 0.453897  [ 5760/13920]\n",
      "loss: 0.500222  [ 5824/13920]\n",
      "loss: 0.509891  [ 5888/13920]\n",
      "loss: 0.655388  [ 5952/13920]\n",
      "loss: 0.435672  [ 6016/13920]\n",
      "loss: 0.366748  [ 6080/13920]\n",
      "loss: 0.463605  [ 6144/13920]\n",
      "loss: 0.384440  [ 6208/13920]\n",
      "loss: 0.455191  [ 6272/13920]\n",
      "loss: 0.410632  [ 6336/13920]\n",
      "loss: 0.412873  [ 6400/13920]\n",
      "loss: 0.547254  [ 6464/13920]\n",
      "loss: 0.427821  [ 6528/13920]\n",
      "loss: 0.483540  [ 6592/13920]\n",
      "loss: 0.532301  [ 6656/13920]\n",
      "loss: 0.445203  [ 6720/13920]\n",
      "loss: 0.454966  [ 6784/13920]\n",
      "loss: 0.496458  [ 6848/13920]\n",
      "loss: 0.460980  [ 6912/13920]\n",
      "loss: 0.399494  [ 6976/13920]\n",
      "loss: 0.386347  [ 7040/13920]\n",
      "loss: 0.509630  [ 7104/13920]\n",
      "loss: 0.421907  [ 7168/13920]\n",
      "loss: 0.322635  [ 7232/13920]\n",
      "loss: 0.427057  [ 7296/13920]\n",
      "loss: 0.400830  [ 7360/13920]\n",
      "loss: 0.331198  [ 7424/13920]\n",
      "loss: 0.283869  [ 7488/13920]\n",
      "loss: 0.386853  [ 7552/13920]\n",
      "loss: 0.374854  [ 7616/13920]\n",
      "loss: 0.439202  [ 7680/13920]\n",
      "loss: 0.449915  [ 7744/13920]\n",
      "loss: 0.297914  [ 7808/13920]\n",
      "loss: 0.350497  [ 7872/13920]\n",
      "loss: 0.400391  [ 7936/13920]\n",
      "loss: 0.303681  [ 8000/13920]\n",
      "loss: 0.295219  [ 8064/13920]\n",
      "loss: 0.307372  [ 8128/13920]\n",
      "loss: 0.319466  [ 8192/13920]\n",
      "loss: 0.311389  [ 8256/13920]\n",
      "loss: 0.403783  [ 8320/13920]\n",
      "loss: 0.203227  [ 8384/13920]\n",
      "loss: 0.362686  [ 8448/13920]\n",
      "loss: 0.433585  [ 8512/13920]\n",
      "loss: 0.365491  [ 8576/13920]\n",
      "loss: 0.403995  [ 8640/13920]\n",
      "loss: 0.281222  [ 8704/13920]\n",
      "loss: 0.324484  [ 8768/13920]\n",
      "loss: 0.582335  [ 8832/13920]\n",
      "loss: 0.384053  [ 8896/13920]\n",
      "loss: 0.331891  [ 8960/13920]\n",
      "loss: 0.429907  [ 9024/13920]\n",
      "loss: 0.383600  [ 9088/13920]\n",
      "loss: 0.305214  [ 9152/13920]\n",
      "loss: 0.245867  [ 9216/13920]\n",
      "loss: 0.448653  [ 9280/13920]\n",
      "loss: 0.423240  [ 9344/13920]\n",
      "loss: 0.380187  [ 9408/13920]\n",
      "loss: 0.452204  [ 9472/13920]\n",
      "loss: 0.388922  [ 9536/13920]\n",
      "loss: 0.409740  [ 9600/13920]\n",
      "loss: 0.385978  [ 9664/13920]\n",
      "loss: 0.390140  [ 9728/13920]\n",
      "loss: 0.476430  [ 9792/13920]\n",
      "loss: 0.328654  [ 9856/13920]\n",
      "loss: 0.420936  [ 9920/13920]\n",
      "loss: 0.667907  [ 9984/13920]\n",
      "loss: 0.333107  [10048/13920]\n",
      "loss: 0.523327  [10112/13920]\n",
      "loss: 0.314470  [10176/13920]\n",
      "loss: 0.348406  [10240/13920]\n",
      "loss: 0.382765  [10304/13920]\n",
      "loss: 0.398199  [10368/13920]\n",
      "loss: 0.381562  [10432/13920]\n",
      "loss: 0.358989  [10496/13920]\n",
      "loss: 0.314954  [10560/13920]\n",
      "loss: 0.402235  [10624/13920]\n",
      "loss: 0.363335  [10688/13920]\n",
      "loss: 0.377728  [10752/13920]\n",
      "loss: 0.310471  [10816/13920]\n",
      "loss: 0.289420  [10880/13920]\n",
      "loss: 0.340218  [10944/13920]\n",
      "loss: 0.324737  [11008/13920]\n",
      "loss: 0.428489  [11072/13920]\n",
      "loss: 0.371298  [11136/13920]\n",
      "loss: 0.414718  [11200/13920]\n",
      "loss: 0.270913  [11264/13920]\n",
      "loss: 0.489696  [11328/13920]\n",
      "loss: 0.435802  [11392/13920]\n",
      "loss: 0.290423  [11456/13920]\n",
      "loss: 0.311103  [11520/13920]\n",
      "loss: 0.260034  [11584/13920]\n",
      "loss: 0.382411  [11648/13920]\n",
      "loss: 0.428962  [11712/13920]\n",
      "loss: 0.442837  [11776/13920]\n",
      "loss: 0.283090  [11840/13920]\n",
      "loss: 0.443220  [11904/13920]\n",
      "loss: 0.433177  [11968/13920]\n",
      "loss: 0.489770  [12032/13920]\n",
      "loss: 0.609896  [12096/13920]\n",
      "loss: 0.360976  [12160/13920]\n",
      "loss: 0.380910  [12224/13920]\n",
      "loss: 0.275277  [12288/13920]\n",
      "loss: 0.290845  [12352/13920]\n",
      "loss: 0.392911  [12416/13920]\n",
      "loss: 0.305987  [12480/13920]\n",
      "loss: 0.318114  [12544/13920]\n",
      "loss: 0.392388  [12608/13920]\n",
      "loss: 0.357574  [12672/13920]\n",
      "loss: 0.385870  [12736/13920]\n",
      "loss: 0.336649  [12800/13920]\n",
      "loss: 0.406022  [12864/13920]\n",
      "loss: 0.358300  [12928/13920]\n",
      "loss: 0.328638  [12992/13920]\n",
      "loss: 0.360888  [13056/13920]\n",
      "loss: 0.271194  [13120/13920]\n",
      "loss: 0.462010  [13184/13920]\n",
      "loss: 0.476324  [13248/13920]\n",
      "loss: 0.312503  [13312/13920]\n",
      "loss: 0.254768  [13376/13920]\n",
      "loss: 0.289722  [13440/13920]\n",
      "loss: 0.249573  [13504/13920]\n",
      "loss: 0.248743  [13568/13920]\n",
      "loss: 0.303837  [13632/13920]\n",
      "loss: 0.342096  [13696/13920]\n",
      "loss: 0.270889  [13760/13920]\n",
      "loss: 0.462277  [13824/13920]\n",
      "loss: 0.601026  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 84.2% \n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.328082 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.266376  [    0/13920]\n",
      "loss: 0.374325  [   64/13920]\n",
      "loss: 0.328060  [  128/13920]\n",
      "loss: 0.408886  [  192/13920]\n",
      "loss: 0.450619  [  256/13920]\n",
      "loss: 0.388743  [  320/13920]\n",
      "loss: 0.260721  [  384/13920]\n",
      "loss: 0.387009  [  448/13920]\n",
      "loss: 0.281878  [  512/13920]\n",
      "loss: 0.312465  [  576/13920]\n",
      "loss: 0.355093  [  640/13920]\n",
      "loss: 0.279727  [  704/13920]\n",
      "loss: 0.391869  [  768/13920]\n",
      "loss: 0.268719  [  832/13920]\n",
      "loss: 0.335259  [  896/13920]\n",
      "loss: 0.310628  [  960/13920]\n",
      "loss: 0.389225  [ 1024/13920]\n",
      "loss: 0.391302  [ 1088/13920]\n",
      "loss: 0.354155  [ 1152/13920]\n",
      "loss: 0.322648  [ 1216/13920]\n",
      "loss: 0.423310  [ 1280/13920]\n",
      "loss: 0.268798  [ 1344/13920]\n",
      "loss: 0.194959  [ 1408/13920]\n",
      "loss: 0.363792  [ 1472/13920]\n",
      "loss: 0.394699  [ 1536/13920]\n",
      "loss: 0.353740  [ 1600/13920]\n",
      "loss: 0.372156  [ 1664/13920]\n",
      "loss: 0.325363  [ 1728/13920]\n",
      "loss: 0.234988  [ 1792/13920]\n",
      "loss: 0.263976  [ 1856/13920]\n",
      "loss: 0.281936  [ 1920/13920]\n",
      "loss: 0.292911  [ 1984/13920]\n",
      "loss: 0.436231  [ 2048/13920]\n",
      "loss: 0.290878  [ 2112/13920]\n",
      "loss: 0.318210  [ 2176/13920]\n",
      "loss: 0.301518  [ 2240/13920]\n",
      "loss: 0.369198  [ 2304/13920]\n",
      "loss: 0.297423  [ 2368/13920]\n",
      "loss: 0.339238  [ 2432/13920]\n",
      "loss: 0.243868  [ 2496/13920]\n",
      "loss: 0.326630  [ 2560/13920]\n",
      "loss: 0.351491  [ 2624/13920]\n",
      "loss: 0.191224  [ 2688/13920]\n",
      "loss: 0.328110  [ 2752/13920]\n",
      "loss: 0.306877  [ 2816/13920]\n",
      "loss: 0.223229  [ 2880/13920]\n",
      "loss: 0.243327  [ 2944/13920]\n",
      "loss: 0.262321  [ 3008/13920]\n",
      "loss: 0.319371  [ 3072/13920]\n",
      "loss: 0.306482  [ 3136/13920]\n",
      "loss: 0.253373  [ 3200/13920]\n",
      "loss: 0.259126  [ 3264/13920]\n",
      "loss: 0.371585  [ 3328/13920]\n",
      "loss: 0.310346  [ 3392/13920]\n",
      "loss: 0.326164  [ 3456/13920]\n",
      "loss: 0.278343  [ 3520/13920]\n",
      "loss: 0.301660  [ 3584/13920]\n",
      "loss: 0.385650  [ 3648/13920]\n",
      "loss: 0.311711  [ 3712/13920]\n",
      "loss: 0.332608  [ 3776/13920]\n",
      "loss: 0.447341  [ 3840/13920]\n",
      "loss: 0.211842  [ 3904/13920]\n",
      "loss: 0.270187  [ 3968/13920]\n",
      "loss: 0.309208  [ 4032/13920]\n",
      "loss: 0.254674  [ 4096/13920]\n",
      "loss: 0.245941  [ 4160/13920]\n",
      "loss: 0.276041  [ 4224/13920]\n",
      "loss: 0.205378  [ 4288/13920]\n",
      "loss: 0.254732  [ 4352/13920]\n",
      "loss: 0.314916  [ 4416/13920]\n",
      "loss: 0.236028  [ 4480/13920]\n",
      "loss: 0.306409  [ 4544/13920]\n",
      "loss: 0.441851  [ 4608/13920]\n",
      "loss: 0.288456  [ 4672/13920]\n",
      "loss: 0.276090  [ 4736/13920]\n",
      "loss: 0.443257  [ 4800/13920]\n",
      "loss: 0.175914  [ 4864/13920]\n",
      "loss: 0.347024  [ 4928/13920]\n",
      "loss: 0.310724  [ 4992/13920]\n",
      "loss: 0.243120  [ 5056/13920]\n",
      "loss: 0.305961  [ 5120/13920]\n",
      "loss: 0.333916  [ 5184/13920]\n",
      "loss: 0.177071  [ 5248/13920]\n",
      "loss: 0.291235  [ 5312/13920]\n",
      "loss: 0.267650  [ 5376/13920]\n",
      "loss: 0.319476  [ 5440/13920]\n",
      "loss: 0.289213  [ 5504/13920]\n",
      "loss: 0.272690  [ 5568/13920]\n",
      "loss: 0.214219  [ 5632/13920]\n",
      "loss: 0.304845  [ 5696/13920]\n",
      "loss: 0.273857  [ 5760/13920]\n",
      "loss: 0.319258  [ 5824/13920]\n",
      "loss: 0.355084  [ 5888/13920]\n",
      "loss: 0.291327  [ 5952/13920]\n",
      "loss: 0.314138  [ 6016/13920]\n",
      "loss: 0.289048  [ 6080/13920]\n",
      "loss: 0.302272  [ 6144/13920]\n",
      "loss: 0.349835  [ 6208/13920]\n",
      "loss: 0.189667  [ 6272/13920]\n",
      "loss: 0.319766  [ 6336/13920]\n",
      "loss: 0.444616  [ 6400/13920]\n",
      "loss: 0.327642  [ 6464/13920]\n",
      "loss: 0.306774  [ 6528/13920]\n",
      "loss: 0.194934  [ 6592/13920]\n",
      "loss: 0.208360  [ 6656/13920]\n",
      "loss: 0.201261  [ 6720/13920]\n",
      "loss: 0.213306  [ 6784/13920]\n",
      "loss: 0.290502  [ 6848/13920]\n",
      "loss: 0.374185  [ 6912/13920]\n",
      "loss: 0.254387  [ 6976/13920]\n",
      "loss: 0.290058  [ 7040/13920]\n",
      "loss: 0.426424  [ 7104/13920]\n",
      "loss: 0.313305  [ 7168/13920]\n",
      "loss: 0.247156  [ 7232/13920]\n",
      "loss: 0.408344  [ 7296/13920]\n",
      "loss: 0.266754  [ 7360/13920]\n",
      "loss: 0.281791  [ 7424/13920]\n",
      "loss: 0.352487  [ 7488/13920]\n",
      "loss: 0.279593  [ 7552/13920]\n",
      "loss: 0.210415  [ 7616/13920]\n",
      "loss: 0.300922  [ 7680/13920]\n",
      "loss: 0.296636  [ 7744/13920]\n",
      "loss: 0.195952  [ 7808/13920]\n",
      "loss: 0.227737  [ 7872/13920]\n",
      "loss: 0.283291  [ 7936/13920]\n",
      "loss: 0.215476  [ 8000/13920]\n",
      "loss: 0.224914  [ 8064/13920]\n",
      "loss: 0.275514  [ 8128/13920]\n",
      "loss: 0.229895  [ 8192/13920]\n",
      "loss: 0.109704  [ 8256/13920]\n",
      "loss: 0.330023  [ 8320/13920]\n",
      "loss: 0.265180  [ 8384/13920]\n",
      "loss: 0.249741  [ 8448/13920]\n",
      "loss: 0.187692  [ 8512/13920]\n",
      "loss: 0.297182  [ 8576/13920]\n",
      "loss: 0.206490  [ 8640/13920]\n",
      "loss: 0.248481  [ 8704/13920]\n",
      "loss: 0.257704  [ 8768/13920]\n",
      "loss: 0.149236  [ 8832/13920]\n",
      "loss: 0.254823  [ 8896/13920]\n",
      "loss: 0.316354  [ 8960/13920]\n",
      "loss: 0.210914  [ 9024/13920]\n",
      "loss: 0.308957  [ 9088/13920]\n",
      "loss: 0.287753  [ 9152/13920]\n",
      "loss: 0.278219  [ 9216/13920]\n",
      "loss: 0.193773  [ 9280/13920]\n",
      "loss: 0.331804  [ 9344/13920]\n",
      "loss: 0.259070  [ 9408/13920]\n",
      "loss: 0.305962  [ 9472/13920]\n",
      "loss: 0.172304  [ 9536/13920]\n",
      "loss: 0.275423  [ 9600/13920]\n",
      "loss: 0.334285  [ 9664/13920]\n",
      "loss: 0.206955  [ 9728/13920]\n",
      "loss: 0.212952  [ 9792/13920]\n",
      "loss: 0.139336  [ 9856/13920]\n",
      "loss: 0.286399  [ 9920/13920]\n",
      "loss: 0.343933  [ 9984/13920]\n",
      "loss: 0.259507  [10048/13920]\n",
      "loss: 0.323777  [10112/13920]\n",
      "loss: 0.221861  [10176/13920]\n",
      "loss: 0.240083  [10240/13920]\n",
      "loss: 0.259715  [10304/13920]\n",
      "loss: 0.174469  [10368/13920]\n",
      "loss: 0.232841  [10432/13920]\n",
      "loss: 0.238117  [10496/13920]\n",
      "loss: 0.103742  [10560/13920]\n",
      "loss: 0.357461  [10624/13920]\n",
      "loss: 0.382137  [10688/13920]\n",
      "loss: 0.229428  [10752/13920]\n",
      "loss: 0.227944  [10816/13920]\n",
      "loss: 0.318181  [10880/13920]\n",
      "loss: 0.208491  [10944/13920]\n",
      "loss: 0.377657  [11008/13920]\n",
      "loss: 0.262954  [11072/13920]\n",
      "loss: 0.303233  [11136/13920]\n",
      "loss: 0.185595  [11200/13920]\n",
      "loss: 0.204057  [11264/13920]\n",
      "loss: 0.202293  [11328/13920]\n",
      "loss: 0.187740  [11392/13920]\n",
      "loss: 0.194838  [11456/13920]\n",
      "loss: 0.184447  [11520/13920]\n",
      "loss: 0.246250  [11584/13920]\n",
      "loss: 0.196466  [11648/13920]\n",
      "loss: 0.256011  [11712/13920]\n",
      "loss: 0.294801  [11776/13920]\n",
      "loss: 0.314568  [11840/13920]\n",
      "loss: 0.324140  [11904/13920]\n",
      "loss: 0.455057  [11968/13920]\n",
      "loss: 0.257338  [12032/13920]\n",
      "loss: 0.317603  [12096/13920]\n",
      "loss: 0.199962  [12160/13920]\n",
      "loss: 0.243737  [12224/13920]\n",
      "loss: 0.305238  [12288/13920]\n",
      "loss: 0.281002  [12352/13920]\n",
      "loss: 0.219447  [12416/13920]\n",
      "loss: 0.230208  [12480/13920]\n",
      "loss: 0.132501  [12544/13920]\n",
      "loss: 0.172320  [12608/13920]\n",
      "loss: 0.230234  [12672/13920]\n",
      "loss: 0.228866  [12736/13920]\n",
      "loss: 0.210167  [12800/13920]\n",
      "loss: 0.281646  [12864/13920]\n",
      "loss: 0.189614  [12928/13920]\n",
      "loss: 0.284257  [12992/13920]\n",
      "loss: 0.293602  [13056/13920]\n",
      "loss: 0.340888  [13120/13920]\n",
      "loss: 0.276709  [13184/13920]\n",
      "loss: 0.214179  [13248/13920]\n",
      "loss: 0.171072  [13312/13920]\n",
      "loss: 0.221036  [13376/13920]\n",
      "loss: 0.237366  [13440/13920]\n",
      "loss: 0.222183  [13504/13920]\n",
      "loss: 0.256814  [13568/13920]\n",
      "loss: 0.250062  [13632/13920]\n",
      "loss: 0.304057  [13696/13920]\n",
      "loss: 0.293191  [13760/13920]\n",
      "loss: 0.125001  [13824/13920]\n",
      "loss: 0.340984  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 90.2% \n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.241383 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.191908  [    0/13920]\n",
      "loss: 0.223255  [   64/13920]\n",
      "loss: 0.316486  [  128/13920]\n",
      "loss: 0.272118  [  192/13920]\n",
      "loss: 0.293471  [  256/13920]\n",
      "loss: 0.153156  [  320/13920]\n",
      "loss: 0.225560  [  384/13920]\n",
      "loss: 0.258025  [  448/13920]\n",
      "loss: 0.166494  [  512/13920]\n",
      "loss: 0.155473  [  576/13920]\n",
      "loss: 0.206892  [  640/13920]\n",
      "loss: 0.443929  [  704/13920]\n",
      "loss: 0.305275  [  768/13920]\n",
      "loss: 0.267990  [  832/13920]\n",
      "loss: 0.192681  [  896/13920]\n",
      "loss: 0.174905  [  960/13920]\n",
      "loss: 0.141103  [ 1024/13920]\n",
      "loss: 0.328032  [ 1088/13920]\n",
      "loss: 0.222689  [ 1152/13920]\n",
      "loss: 0.253556  [ 1216/13920]\n",
      "loss: 0.199169  [ 1280/13920]\n",
      "loss: 0.308223  [ 1344/13920]\n",
      "loss: 0.204008  [ 1408/13920]\n",
      "loss: 0.259019  [ 1472/13920]\n",
      "loss: 0.245600  [ 1536/13920]\n",
      "loss: 0.132941  [ 1600/13920]\n",
      "loss: 0.195580  [ 1664/13920]\n",
      "loss: 0.258646  [ 1728/13920]\n",
      "loss: 0.300739  [ 1792/13920]\n",
      "loss: 0.129425  [ 1856/13920]\n",
      "loss: 0.246784  [ 1920/13920]\n",
      "loss: 0.294985  [ 1984/13920]\n",
      "loss: 0.254975  [ 2048/13920]\n",
      "loss: 0.209969  [ 2112/13920]\n",
      "loss: 0.356363  [ 2176/13920]\n",
      "loss: 0.466883  [ 2240/13920]\n",
      "loss: 0.456105  [ 2304/13920]\n",
      "loss: 0.175199  [ 2368/13920]\n",
      "loss: 0.102115  [ 2432/13920]\n",
      "loss: 0.291057  [ 2496/13920]\n",
      "loss: 0.274178  [ 2560/13920]\n",
      "loss: 0.291176  [ 2624/13920]\n",
      "loss: 0.271192  [ 2688/13920]\n",
      "loss: 0.248167  [ 2752/13920]\n",
      "loss: 0.183640  [ 2816/13920]\n",
      "loss: 0.262537  [ 2880/13920]\n",
      "loss: 0.134017  [ 2944/13920]\n",
      "loss: 0.244562  [ 3008/13920]\n",
      "loss: 0.136409  [ 3072/13920]\n",
      "loss: 0.186646  [ 3136/13920]\n",
      "loss: 0.251688  [ 3200/13920]\n",
      "loss: 0.187332  [ 3264/13920]\n",
      "loss: 0.298061  [ 3328/13920]\n",
      "loss: 0.317219  [ 3392/13920]\n",
      "loss: 0.212016  [ 3456/13920]\n",
      "loss: 0.270367  [ 3520/13920]\n",
      "loss: 0.322646  [ 3584/13920]\n",
      "loss: 0.194343  [ 3648/13920]\n",
      "loss: 0.328808  [ 3712/13920]\n",
      "loss: 0.154842  [ 3776/13920]\n",
      "loss: 0.200640  [ 3840/13920]\n",
      "loss: 0.143213  [ 3904/13920]\n",
      "loss: 0.362546  [ 3968/13920]\n",
      "loss: 0.171717  [ 4032/13920]\n",
      "loss: 0.259271  [ 4096/13920]\n",
      "loss: 0.211084  [ 4160/13920]\n",
      "loss: 0.220159  [ 4224/13920]\n",
      "loss: 0.402283  [ 4288/13920]\n",
      "loss: 0.151627  [ 4352/13920]\n",
      "loss: 0.260044  [ 4416/13920]\n",
      "loss: 0.140198  [ 4480/13920]\n",
      "loss: 0.387635  [ 4544/13920]\n",
      "loss: 0.296914  [ 4608/13920]\n",
      "loss: 0.361935  [ 4672/13920]\n",
      "loss: 0.222671  [ 4736/13920]\n",
      "loss: 0.190842  [ 4800/13920]\n",
      "loss: 0.287753  [ 4864/13920]\n",
      "loss: 0.248034  [ 4928/13920]\n",
      "loss: 0.152296  [ 4992/13920]\n",
      "loss: 0.182567  [ 5056/13920]\n",
      "loss: 0.278884  [ 5120/13920]\n",
      "loss: 0.197475  [ 5184/13920]\n",
      "loss: 0.283826  [ 5248/13920]\n",
      "loss: 0.254783  [ 5312/13920]\n",
      "loss: 0.171521  [ 5376/13920]\n",
      "loss: 0.178589  [ 5440/13920]\n",
      "loss: 0.173806  [ 5504/13920]\n",
      "loss: 0.166817  [ 5568/13920]\n",
      "loss: 0.157691  [ 5632/13920]\n",
      "loss: 0.129638  [ 5696/13920]\n",
      "loss: 0.214502  [ 5760/13920]\n",
      "loss: 0.149920  [ 5824/13920]\n",
      "loss: 0.155607  [ 5888/13920]\n",
      "loss: 0.170287  [ 5952/13920]\n",
      "loss: 0.203115  [ 6016/13920]\n",
      "loss: 0.157080  [ 6080/13920]\n",
      "loss: 0.121937  [ 6144/13920]\n",
      "loss: 0.152685  [ 6208/13920]\n",
      "loss: 0.213817  [ 6272/13920]\n",
      "loss: 0.163266  [ 6336/13920]\n",
      "loss: 0.130297  [ 6400/13920]\n",
      "loss: 0.225905  [ 6464/13920]\n",
      "loss: 0.288250  [ 6528/13920]\n",
      "loss: 0.240935  [ 6592/13920]\n",
      "loss: 0.209210  [ 6656/13920]\n",
      "loss: 0.292408  [ 6720/13920]\n",
      "loss: 0.284208  [ 6784/13920]\n",
      "loss: 0.220050  [ 6848/13920]\n",
      "loss: 0.130992  [ 6912/13920]\n",
      "loss: 0.223693  [ 6976/13920]\n",
      "loss: 0.231421  [ 7040/13920]\n",
      "loss: 0.266947  [ 7104/13920]\n",
      "loss: 0.118415  [ 7168/13920]\n",
      "loss: 0.206545  [ 7232/13920]\n",
      "loss: 0.130186  [ 7296/13920]\n",
      "loss: 0.132690  [ 7360/13920]\n",
      "loss: 0.158274  [ 7424/13920]\n",
      "loss: 0.172522  [ 7488/13920]\n",
      "loss: 0.157002  [ 7552/13920]\n",
      "loss: 0.287464  [ 7616/13920]\n",
      "loss: 0.273552  [ 7680/13920]\n",
      "loss: 0.256991  [ 7744/13920]\n",
      "loss: 0.138036  [ 7808/13920]\n",
      "loss: 0.148702  [ 7872/13920]\n",
      "loss: 0.167240  [ 7936/13920]\n",
      "loss: 0.210526  [ 8000/13920]\n",
      "loss: 0.187396  [ 8064/13920]\n",
      "loss: 0.219202  [ 8128/13920]\n",
      "loss: 0.133439  [ 8192/13920]\n",
      "loss: 0.117857  [ 8256/13920]\n",
      "loss: 0.294312  [ 8320/13920]\n",
      "loss: 0.200682  [ 8384/13920]\n",
      "loss: 0.168343  [ 8448/13920]\n",
      "loss: 0.154272  [ 8512/13920]\n",
      "loss: 0.123933  [ 8576/13920]\n",
      "loss: 0.189881  [ 8640/13920]\n",
      "loss: 0.241780  [ 8704/13920]\n",
      "loss: 0.225913  [ 8768/13920]\n",
      "loss: 0.149713  [ 8832/13920]\n",
      "loss: 0.305879  [ 8896/13920]\n",
      "loss: 0.368378  [ 8960/13920]\n",
      "loss: 0.218526  [ 9024/13920]\n",
      "loss: 0.214173  [ 9088/13920]\n",
      "loss: 0.334408  [ 9152/13920]\n",
      "loss: 0.198416  [ 9216/13920]\n",
      "loss: 0.189565  [ 9280/13920]\n",
      "loss: 0.147505  [ 9344/13920]\n",
      "loss: 0.122279  [ 9408/13920]\n",
      "loss: 0.387666  [ 9472/13920]\n",
      "loss: 0.159377  [ 9536/13920]\n",
      "loss: 0.194919  [ 9600/13920]\n",
      "loss: 0.188204  [ 9664/13920]\n",
      "loss: 0.300492  [ 9728/13920]\n",
      "loss: 0.224245  [ 9792/13920]\n",
      "loss: 0.155239  [ 9856/13920]\n",
      "loss: 0.151115  [ 9920/13920]\n",
      "loss: 0.179129  [ 9984/13920]\n",
      "loss: 0.331055  [10048/13920]\n",
      "loss: 0.182409  [10112/13920]\n",
      "loss: 0.179566  [10176/13920]\n",
      "loss: 0.080791  [10240/13920]\n",
      "loss: 0.229125  [10304/13920]\n",
      "loss: 0.119035  [10368/13920]\n",
      "loss: 0.123257  [10432/13920]\n",
      "loss: 0.235858  [10496/13920]\n",
      "loss: 0.317645  [10560/13920]\n",
      "loss: 0.122068  [10624/13920]\n",
      "loss: 0.224460  [10688/13920]\n",
      "loss: 0.106334  [10752/13920]\n",
      "loss: 0.179199  [10816/13920]\n",
      "loss: 0.115904  [10880/13920]\n",
      "loss: 0.366558  [10944/13920]\n",
      "loss: 0.194447  [11008/13920]\n",
      "loss: 0.154920  [11072/13920]\n",
      "loss: 0.128051  [11136/13920]\n",
      "loss: 0.231841  [11200/13920]\n",
      "loss: 0.243708  [11264/13920]\n",
      "loss: 0.158018  [11328/13920]\n",
      "loss: 0.303682  [11392/13920]\n",
      "loss: 0.278013  [11456/13920]\n",
      "loss: 0.261280  [11520/13920]\n",
      "loss: 0.334317  [11584/13920]\n",
      "loss: 0.272217  [11648/13920]\n",
      "loss: 0.276703  [11712/13920]\n",
      "loss: 0.275055  [11776/13920]\n",
      "loss: 0.132564  [11840/13920]\n",
      "loss: 0.160255  [11904/13920]\n",
      "loss: 0.206582  [11968/13920]\n",
      "loss: 0.195843  [12032/13920]\n",
      "loss: 0.203748  [12096/13920]\n",
      "loss: 0.125111  [12160/13920]\n",
      "loss: 0.189683  [12224/13920]\n",
      "loss: 0.183963  [12288/13920]\n",
      "loss: 0.202716  [12352/13920]\n",
      "loss: 0.218026  [12416/13920]\n",
      "loss: 0.155274  [12480/13920]\n",
      "loss: 0.241039  [12544/13920]\n",
      "loss: 0.183823  [12608/13920]\n",
      "loss: 0.115209  [12672/13920]\n",
      "loss: 0.149368  [12736/13920]\n",
      "loss: 0.233805  [12800/13920]\n",
      "loss: 0.117688  [12864/13920]\n",
      "loss: 0.144635  [12928/13920]\n",
      "loss: 0.244461  [12992/13920]\n",
      "loss: 0.092532  [13056/13920]\n",
      "loss: 0.212187  [13120/13920]\n",
      "loss: 0.260677  [13184/13920]\n",
      "loss: 0.170460  [13248/13920]\n",
      "loss: 0.217654  [13312/13920]\n",
      "loss: 0.150825  [13376/13920]\n",
      "loss: 0.206683  [13440/13920]\n",
      "loss: 0.185653  [13504/13920]\n",
      "loss: 0.147726  [13568/13920]\n",
      "loss: 0.151563  [13632/13920]\n",
      "loss: 0.128528  [13696/13920]\n",
      "loss: 0.186138  [13760/13920]\n",
      "loss: 0.140861  [13824/13920]\n",
      "loss: 0.082372  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 92.6% \n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.183876 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.119581  [    0/13920]\n",
      "loss: 0.114417  [   64/13920]\n",
      "loss: 0.149275  [  128/13920]\n",
      "loss: 0.130898  [  192/13920]\n",
      "loss: 0.138403  [  256/13920]\n",
      "loss: 0.205649  [  320/13920]\n",
      "loss: 0.116013  [  384/13920]\n",
      "loss: 0.133231  [  448/13920]\n",
      "loss: 0.080049  [  512/13920]\n",
      "loss: 0.175554  [  576/13920]\n",
      "loss: 0.215477  [  640/13920]\n",
      "loss: 0.119039  [  704/13920]\n",
      "loss: 0.125714  [  768/13920]\n",
      "loss: 0.177392  [  832/13920]\n",
      "loss: 0.171254  [  896/13920]\n",
      "loss: 0.198210  [  960/13920]\n",
      "loss: 0.157025  [ 1024/13920]\n",
      "loss: 0.165444  [ 1088/13920]\n",
      "loss: 0.226826  [ 1152/13920]\n",
      "loss: 0.075470  [ 1216/13920]\n",
      "loss: 0.101103  [ 1280/13920]\n",
      "loss: 0.108148  [ 1344/13920]\n",
      "loss: 0.192556  [ 1408/13920]\n",
      "loss: 0.105775  [ 1472/13920]\n",
      "loss: 0.179630  [ 1536/13920]\n",
      "loss: 0.225674  [ 1600/13920]\n",
      "loss: 0.187658  [ 1664/13920]\n",
      "loss: 0.191279  [ 1728/13920]\n",
      "loss: 0.190116  [ 1792/13920]\n",
      "loss: 0.256146  [ 1856/13920]\n",
      "loss: 0.237800  [ 1920/13920]\n",
      "loss: 0.124296  [ 1984/13920]\n",
      "loss: 0.130970  [ 2048/13920]\n",
      "loss: 0.164200  [ 2112/13920]\n",
      "loss: 0.157994  [ 2176/13920]\n",
      "loss: 0.077022  [ 2240/13920]\n",
      "loss: 0.168936  [ 2304/13920]\n",
      "loss: 0.187782  [ 2368/13920]\n",
      "loss: 0.136712  [ 2432/13920]\n",
      "loss: 0.079864  [ 2496/13920]\n",
      "loss: 0.156023  [ 2560/13920]\n",
      "loss: 0.131498  [ 2624/13920]\n",
      "loss: 0.122491  [ 2688/13920]\n",
      "loss: 0.170065  [ 2752/13920]\n",
      "loss: 0.129021  [ 2816/13920]\n",
      "loss: 0.127204  [ 2880/13920]\n",
      "loss: 0.176393  [ 2944/13920]\n",
      "loss: 0.120070  [ 3008/13920]\n",
      "loss: 0.293739  [ 3072/13920]\n",
      "loss: 0.248145  [ 3136/13920]\n",
      "loss: 0.256711  [ 3200/13920]\n",
      "loss: 0.142106  [ 3264/13920]\n",
      "loss: 0.199373  [ 3328/13920]\n",
      "loss: 0.161255  [ 3392/13920]\n",
      "loss: 0.126682  [ 3456/13920]\n",
      "loss: 0.142849  [ 3520/13920]\n",
      "loss: 0.142023  [ 3584/13920]\n",
      "loss: 0.114051  [ 3648/13920]\n",
      "loss: 0.215681  [ 3712/13920]\n",
      "loss: 0.118599  [ 3776/13920]\n",
      "loss: 0.317872  [ 3840/13920]\n",
      "loss: 0.224198  [ 3904/13920]\n",
      "loss: 0.170833  [ 3968/13920]\n",
      "loss: 0.160263  [ 4032/13920]\n",
      "loss: 0.139539  [ 4096/13920]\n",
      "loss: 0.265475  [ 4160/13920]\n",
      "loss: 0.156230  [ 4224/13920]\n",
      "loss: 0.256289  [ 4288/13920]\n",
      "loss: 0.159699  [ 4352/13920]\n",
      "loss: 0.163290  [ 4416/13920]\n",
      "loss: 0.091449  [ 4480/13920]\n",
      "loss: 0.242279  [ 4544/13920]\n",
      "loss: 0.161619  [ 4608/13920]\n",
      "loss: 0.140447  [ 4672/13920]\n",
      "loss: 0.150969  [ 4736/13920]\n",
      "loss: 0.229425  [ 4800/13920]\n",
      "loss: 0.151912  [ 4864/13920]\n",
      "loss: 0.176236  [ 4928/13920]\n",
      "loss: 0.189947  [ 4992/13920]\n",
      "loss: 0.197777  [ 5056/13920]\n",
      "loss: 0.157163  [ 5120/13920]\n",
      "loss: 0.210387  [ 5184/13920]\n",
      "loss: 0.103189  [ 5248/13920]\n",
      "loss: 0.270883  [ 5312/13920]\n",
      "loss: 0.209520  [ 5376/13920]\n",
      "loss: 0.110286  [ 5440/13920]\n",
      "loss: 0.145304  [ 5504/13920]\n",
      "loss: 0.160601  [ 5568/13920]\n",
      "loss: 0.165324  [ 5632/13920]\n",
      "loss: 0.078048  [ 5696/13920]\n",
      "loss: 0.164055  [ 5760/13920]\n",
      "loss: 0.156742  [ 5824/13920]\n",
      "loss: 0.152281  [ 5888/13920]\n",
      "loss: 0.090955  [ 5952/13920]\n",
      "loss: 0.193778  [ 6016/13920]\n",
      "loss: 0.106791  [ 6080/13920]\n",
      "loss: 0.158885  [ 6144/13920]\n",
      "loss: 0.135612  [ 6208/13920]\n",
      "loss: 0.126579  [ 6272/13920]\n",
      "loss: 0.138000  [ 6336/13920]\n",
      "loss: 0.136013  [ 6400/13920]\n",
      "loss: 0.258611  [ 6464/13920]\n",
      "loss: 0.116750  [ 6528/13920]\n",
      "loss: 0.133245  [ 6592/13920]\n",
      "loss: 0.088459  [ 6656/13920]\n",
      "loss: 0.143576  [ 6720/13920]\n",
      "loss: 0.123321  [ 6784/13920]\n",
      "loss: 0.113240  [ 6848/13920]\n",
      "loss: 0.101420  [ 6912/13920]\n",
      "loss: 0.118728  [ 6976/13920]\n",
      "loss: 0.189420  [ 7040/13920]\n",
      "loss: 0.283583  [ 7104/13920]\n",
      "loss: 0.186149  [ 7168/13920]\n",
      "loss: 0.182301  [ 7232/13920]\n",
      "loss: 0.260434  [ 7296/13920]\n",
      "loss: 0.242065  [ 7360/13920]\n",
      "loss: 0.137618  [ 7424/13920]\n",
      "loss: 0.310034  [ 7488/13920]\n",
      "loss: 0.122386  [ 7552/13920]\n",
      "loss: 0.230567  [ 7616/13920]\n",
      "loss: 0.113965  [ 7680/13920]\n",
      "loss: 0.127034  [ 7744/13920]\n",
      "loss: 0.187893  [ 7808/13920]\n",
      "loss: 0.301998  [ 7872/13920]\n",
      "loss: 0.167492  [ 7936/13920]\n",
      "loss: 0.099404  [ 8000/13920]\n",
      "loss: 0.195210  [ 8064/13920]\n",
      "loss: 0.159721  [ 8128/13920]\n",
      "loss: 0.247064  [ 8192/13920]\n",
      "loss: 0.156110  [ 8256/13920]\n",
      "loss: 0.144839  [ 8320/13920]\n",
      "loss: 0.198444  [ 8384/13920]\n",
      "loss: 0.135533  [ 8448/13920]\n",
      "loss: 0.142846  [ 8512/13920]\n",
      "loss: 0.066812  [ 8576/13920]\n",
      "loss: 0.136957  [ 8640/13920]\n",
      "loss: 0.206774  [ 8704/13920]\n",
      "loss: 0.110647  [ 8768/13920]\n",
      "loss: 0.231340  [ 8832/13920]\n",
      "loss: 0.207353  [ 8896/13920]\n",
      "loss: 0.235692  [ 8960/13920]\n",
      "loss: 0.223822  [ 9024/13920]\n",
      "loss: 0.118991  [ 9088/13920]\n",
      "loss: 0.174344  [ 9152/13920]\n",
      "loss: 0.157480  [ 9216/13920]\n",
      "loss: 0.209507  [ 9280/13920]\n",
      "loss: 0.130107  [ 9344/13920]\n",
      "loss: 0.347774  [ 9408/13920]\n",
      "loss: 0.074175  [ 9472/13920]\n",
      "loss: 0.337056  [ 9536/13920]\n",
      "loss: 0.149715  [ 9600/13920]\n",
      "loss: 0.133972  [ 9664/13920]\n",
      "loss: 0.235071  [ 9728/13920]\n",
      "loss: 0.136135  [ 9792/13920]\n",
      "loss: 0.222238  [ 9856/13920]\n",
      "loss: 0.159008  [ 9920/13920]\n",
      "loss: 0.111176  [ 9984/13920]\n",
      "loss: 0.116634  [10048/13920]\n",
      "loss: 0.197901  [10112/13920]\n",
      "loss: 0.147119  [10176/13920]\n",
      "loss: 0.098436  [10240/13920]\n",
      "loss: 0.153801  [10304/13920]\n",
      "loss: 0.141486  [10368/13920]\n",
      "loss: 0.148256  [10432/13920]\n",
      "loss: 0.375164  [10496/13920]\n",
      "loss: 0.065411  [10560/13920]\n",
      "loss: 0.118613  [10624/13920]\n",
      "loss: 0.159309  [10688/13920]\n",
      "loss: 0.108288  [10752/13920]\n",
      "loss: 0.244560  [10816/13920]\n",
      "loss: 0.089174  [10880/13920]\n",
      "loss: 0.116701  [10944/13920]\n",
      "loss: 0.073274  [11008/13920]\n",
      "loss: 0.140111  [11072/13920]\n",
      "loss: 0.265200  [11136/13920]\n",
      "loss: 0.135058  [11200/13920]\n",
      "loss: 0.127623  [11264/13920]\n",
      "loss: 0.181335  [11328/13920]\n",
      "loss: 0.209439  [11392/13920]\n",
      "loss: 0.247684  [11456/13920]\n",
      "loss: 0.090470  [11520/13920]\n",
      "loss: 0.080409  [11584/13920]\n",
      "loss: 0.065829  [11648/13920]\n",
      "loss: 0.235209  [11712/13920]\n",
      "loss: 0.198303  [11776/13920]\n",
      "loss: 0.115168  [11840/13920]\n",
      "loss: 0.064437  [11904/13920]\n",
      "loss: 0.244347  [11968/13920]\n",
      "loss: 0.196332  [12032/13920]\n",
      "loss: 0.123642  [12096/13920]\n",
      "loss: 0.206624  [12160/13920]\n",
      "loss: 0.094758  [12224/13920]\n",
      "loss: 0.248353  [12288/13920]\n",
      "loss: 0.118509  [12352/13920]\n",
      "loss: 0.102173  [12416/13920]\n",
      "loss: 0.172591  [12480/13920]\n",
      "loss: 0.101865  [12544/13920]\n",
      "loss: 0.186118  [12608/13920]\n",
      "loss: 0.231368  [12672/13920]\n",
      "loss: 0.167750  [12736/13920]\n",
      "loss: 0.240742  [12800/13920]\n",
      "loss: 0.190363  [12864/13920]\n",
      "loss: 0.183702  [12928/13920]\n",
      "loss: 0.158619  [12992/13920]\n",
      "loss: 0.147626  [13056/13920]\n",
      "loss: 0.077517  [13120/13920]\n",
      "loss: 0.133503  [13184/13920]\n",
      "loss: 0.116320  [13248/13920]\n",
      "loss: 0.205728  [13312/13920]\n",
      "loss: 0.153870  [13376/13920]\n",
      "loss: 0.117980  [13440/13920]\n",
      "loss: 0.176592  [13504/13920]\n",
      "loss: 0.158877  [13568/13920]\n",
      "loss: 0.087793  [13632/13920]\n",
      "loss: 0.092369  [13696/13920]\n",
      "loss: 0.126185  [13760/13920]\n",
      "loss: 0.125623  [13824/13920]\n",
      "loss: 0.120379  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 94.5% \n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.162274 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.078816  [    0/13920]\n",
      "loss: 0.055921  [   64/13920]\n",
      "loss: 0.074283  [  128/13920]\n",
      "loss: 0.182020  [  192/13920]\n",
      "loss: 0.102560  [  256/13920]\n",
      "loss: 0.145519  [  320/13920]\n",
      "loss: 0.136920  [  384/13920]\n",
      "loss: 0.191915  [  448/13920]\n",
      "loss: 0.122686  [  512/13920]\n",
      "loss: 0.112445  [  576/13920]\n",
      "loss: 0.104843  [  640/13920]\n",
      "loss: 0.105795  [  704/13920]\n",
      "loss: 0.107530  [  768/13920]\n",
      "loss: 0.143719  [  832/13920]\n",
      "loss: 0.094832  [  896/13920]\n",
      "loss: 0.092872  [  960/13920]\n",
      "loss: 0.147253  [ 1024/13920]\n",
      "loss: 0.137351  [ 1088/13920]\n",
      "loss: 0.199207  [ 1152/13920]\n",
      "loss: 0.106450  [ 1216/13920]\n",
      "loss: 0.154631  [ 1280/13920]\n",
      "loss: 0.069026  [ 1344/13920]\n",
      "loss: 0.156179  [ 1408/13920]\n",
      "loss: 0.133651  [ 1472/13920]\n",
      "loss: 0.143166  [ 1536/13920]\n",
      "loss: 0.191192  [ 1600/13920]\n",
      "loss: 0.115867  [ 1664/13920]\n",
      "loss: 0.090688  [ 1728/13920]\n",
      "loss: 0.077935  [ 1792/13920]\n",
      "loss: 0.080740  [ 1856/13920]\n",
      "loss: 0.082503  [ 1920/13920]\n",
      "loss: 0.087457  [ 1984/13920]\n",
      "loss: 0.120517  [ 2048/13920]\n",
      "loss: 0.194851  [ 2112/13920]\n",
      "loss: 0.163823  [ 2176/13920]\n",
      "loss: 0.131348  [ 2240/13920]\n",
      "loss: 0.154262  [ 2304/13920]\n",
      "loss: 0.069588  [ 2368/13920]\n",
      "loss: 0.214718  [ 2432/13920]\n",
      "loss: 0.099869  [ 2496/13920]\n",
      "loss: 0.186031  [ 2560/13920]\n",
      "loss: 0.210207  [ 2624/13920]\n",
      "loss: 0.151976  [ 2688/13920]\n",
      "loss: 0.196033  [ 2752/13920]\n",
      "loss: 0.079369  [ 2816/13920]\n",
      "loss: 0.136222  [ 2880/13920]\n",
      "loss: 0.208254  [ 2944/13920]\n",
      "loss: 0.091385  [ 3008/13920]\n",
      "loss: 0.058759  [ 3072/13920]\n",
      "loss: 0.071959  [ 3136/13920]\n",
      "loss: 0.083345  [ 3200/13920]\n",
      "loss: 0.112175  [ 3264/13920]\n",
      "loss: 0.221866  [ 3328/13920]\n",
      "loss: 0.138991  [ 3392/13920]\n",
      "loss: 0.209352  [ 3456/13920]\n",
      "loss: 0.157727  [ 3520/13920]\n",
      "loss: 0.096445  [ 3584/13920]\n",
      "loss: 0.069933  [ 3648/13920]\n",
      "loss: 0.139788  [ 3712/13920]\n",
      "loss: 0.186281  [ 3776/13920]\n",
      "loss: 0.129946  [ 3840/13920]\n",
      "loss: 0.114267  [ 3904/13920]\n",
      "loss: 0.169215  [ 3968/13920]\n",
      "loss: 0.092302  [ 4032/13920]\n",
      "loss: 0.115797  [ 4096/13920]\n",
      "loss: 0.287210  [ 4160/13920]\n",
      "loss: 0.131348  [ 4224/13920]\n",
      "loss: 0.108070  [ 4288/13920]\n",
      "loss: 0.297458  [ 4352/13920]\n",
      "loss: 0.142928  [ 4416/13920]\n",
      "loss: 0.106991  [ 4480/13920]\n",
      "loss: 0.140477  [ 4544/13920]\n",
      "loss: 0.189042  [ 4608/13920]\n",
      "loss: 0.114476  [ 4672/13920]\n",
      "loss: 0.171756  [ 4736/13920]\n",
      "loss: 0.091163  [ 4800/13920]\n",
      "loss: 0.071987  [ 4864/13920]\n",
      "loss: 0.076737  [ 4928/13920]\n",
      "loss: 0.274653  [ 4992/13920]\n",
      "loss: 0.199664  [ 5056/13920]\n",
      "loss: 0.172429  [ 5120/13920]\n",
      "loss: 0.107040  [ 5184/13920]\n",
      "loss: 0.249347  [ 5248/13920]\n",
      "loss: 0.140089  [ 5312/13920]\n",
      "loss: 0.128106  [ 5376/13920]\n",
      "loss: 0.114692  [ 5440/13920]\n",
      "loss: 0.165134  [ 5504/13920]\n",
      "loss: 0.107457  [ 5568/13920]\n",
      "loss: 0.199170  [ 5632/13920]\n",
      "loss: 0.135217  [ 5696/13920]\n",
      "loss: 0.162002  [ 5760/13920]\n",
      "loss: 0.132899  [ 5824/13920]\n",
      "loss: 0.107569  [ 5888/13920]\n",
      "loss: 0.126959  [ 5952/13920]\n",
      "loss: 0.131682  [ 6016/13920]\n",
      "loss: 0.104086  [ 6080/13920]\n",
      "loss: 0.126740  [ 6144/13920]\n",
      "loss: 0.099646  [ 6208/13920]\n",
      "loss: 0.096795  [ 6272/13920]\n",
      "loss: 0.087488  [ 6336/13920]\n",
      "loss: 0.116194  [ 6400/13920]\n",
      "loss: 0.121272  [ 6464/13920]\n",
      "loss: 0.051938  [ 6528/13920]\n",
      "loss: 0.122315  [ 6592/13920]\n",
      "loss: 0.161122  [ 6656/13920]\n",
      "loss: 0.183188  [ 6720/13920]\n",
      "loss: 0.186674  [ 6784/13920]\n",
      "loss: 0.128433  [ 6848/13920]\n",
      "loss: 0.065676  [ 6912/13920]\n",
      "loss: 0.128595  [ 6976/13920]\n",
      "loss: 0.204800  [ 7040/13920]\n",
      "loss: 0.062171  [ 7104/13920]\n",
      "loss: 0.140997  [ 7168/13920]\n",
      "loss: 0.090200  [ 7232/13920]\n",
      "loss: 0.109872  [ 7296/13920]\n",
      "loss: 0.141612  [ 7360/13920]\n",
      "loss: 0.111666  [ 7424/13920]\n",
      "loss: 0.272598  [ 7488/13920]\n",
      "loss: 0.152011  [ 7552/13920]\n",
      "loss: 0.096638  [ 7616/13920]\n",
      "loss: 0.081862  [ 7680/13920]\n",
      "loss: 0.139163  [ 7744/13920]\n",
      "loss: 0.155860  [ 7808/13920]\n",
      "loss: 0.112136  [ 7872/13920]\n",
      "loss: 0.161802  [ 7936/13920]\n",
      "loss: 0.143269  [ 8000/13920]\n",
      "loss: 0.147258  [ 8064/13920]\n",
      "loss: 0.129160  [ 8128/13920]\n",
      "loss: 0.236448  [ 8192/13920]\n",
      "loss: 0.052662  [ 8256/13920]\n",
      "loss: 0.121051  [ 8320/13920]\n",
      "loss: 0.115613  [ 8384/13920]\n",
      "loss: 0.092580  [ 8448/13920]\n",
      "loss: 0.152677  [ 8512/13920]\n",
      "loss: 0.139441  [ 8576/13920]\n",
      "loss: 0.150823  [ 8640/13920]\n",
      "loss: 0.138109  [ 8704/13920]\n",
      "loss: 0.194125  [ 8768/13920]\n",
      "loss: 0.079054  [ 8832/13920]\n",
      "loss: 0.135329  [ 8896/13920]\n",
      "loss: 0.118775  [ 8960/13920]\n",
      "loss: 0.182008  [ 9024/13920]\n",
      "loss: 0.088651  [ 9088/13920]\n",
      "loss: 0.118131  [ 9152/13920]\n",
      "loss: 0.088550  [ 9216/13920]\n",
      "loss: 0.118907  [ 9280/13920]\n",
      "loss: 0.130520  [ 9344/13920]\n",
      "loss: 0.111427  [ 9408/13920]\n",
      "loss: 0.065891  [ 9472/13920]\n",
      "loss: 0.160759  [ 9536/13920]\n",
      "loss: 0.121613  [ 9600/13920]\n",
      "loss: 0.324741  [ 9664/13920]\n",
      "loss: 0.107391  [ 9728/13920]\n",
      "loss: 0.064173  [ 9792/13920]\n",
      "loss: 0.112414  [ 9856/13920]\n",
      "loss: 0.114853  [ 9920/13920]\n",
      "loss: 0.113300  [ 9984/13920]\n",
      "loss: 0.138356  [10048/13920]\n",
      "loss: 0.159788  [10112/13920]\n",
      "loss: 0.096048  [10176/13920]\n",
      "loss: 0.105778  [10240/13920]\n",
      "loss: 0.102270  [10304/13920]\n",
      "loss: 0.238312  [10368/13920]\n",
      "loss: 0.079894  [10432/13920]\n",
      "loss: 0.177285  [10496/13920]\n",
      "loss: 0.062997  [10560/13920]\n",
      "loss: 0.102041  [10624/13920]\n",
      "loss: 0.169569  [10688/13920]\n",
      "loss: 0.072067  [10752/13920]\n",
      "loss: 0.154872  [10816/13920]\n",
      "loss: 0.126640  [10880/13920]\n",
      "loss: 0.108912  [10944/13920]\n",
      "loss: 0.189457  [11008/13920]\n",
      "loss: 0.128530  [11072/13920]\n",
      "loss: 0.166963  [11136/13920]\n",
      "loss: 0.165182  [11200/13920]\n",
      "loss: 0.103952  [11264/13920]\n",
      "loss: 0.179098  [11328/13920]\n",
      "loss: 0.122044  [11392/13920]\n",
      "loss: 0.183345  [11456/13920]\n",
      "loss: 0.124257  [11520/13920]\n",
      "loss: 0.132020  [11584/13920]\n",
      "loss: 0.070439  [11648/13920]\n",
      "loss: 0.286402  [11712/13920]\n",
      "loss: 0.189077  [11776/13920]\n",
      "loss: 0.088516  [11840/13920]\n",
      "loss: 0.092951  [11904/13920]\n",
      "loss: 0.043376  [11968/13920]\n",
      "loss: 0.099917  [12032/13920]\n",
      "loss: 0.067037  [12096/13920]\n",
      "loss: 0.125405  [12160/13920]\n",
      "loss: 0.238942  [12224/13920]\n",
      "loss: 0.091418  [12288/13920]\n",
      "loss: 0.066850  [12352/13920]\n",
      "loss: 0.103291  [12416/13920]\n",
      "loss: 0.143337  [12480/13920]\n",
      "loss: 0.073966  [12544/13920]\n",
      "loss: 0.179913  [12608/13920]\n",
      "loss: 0.067888  [12672/13920]\n",
      "loss: 0.141403  [12736/13920]\n",
      "loss: 0.151494  [12800/13920]\n",
      "loss: 0.094969  [12864/13920]\n",
      "loss: 0.061631  [12928/13920]\n",
      "loss: 0.069684  [12992/13920]\n",
      "loss: 0.116157  [13056/13920]\n",
      "loss: 0.187298  [13120/13920]\n",
      "loss: 0.145553  [13184/13920]\n",
      "loss: 0.107536  [13248/13920]\n",
      "loss: 0.132603  [13312/13920]\n",
      "loss: 0.157945  [13376/13920]\n",
      "loss: 0.220472  [13440/13920]\n",
      "loss: 0.154792  [13504/13920]\n",
      "loss: 0.163379  [13568/13920]\n",
      "loss: 0.136481  [13632/13920]\n",
      "loss: 0.094143  [13696/13920]\n",
      "loss: 0.090598  [13760/13920]\n",
      "loss: 0.133032  [13824/13920]\n",
      "loss: 0.144898  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.8% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.133384 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.097958  [    0/13920]\n",
      "loss: 0.087833  [   64/13920]\n",
      "loss: 0.074336  [  128/13920]\n",
      "loss: 0.126186  [  192/13920]\n",
      "loss: 0.048934  [  256/13920]\n",
      "loss: 0.090778  [  320/13920]\n",
      "loss: 0.053340  [  384/13920]\n",
      "loss: 0.092737  [  448/13920]\n",
      "loss: 0.096691  [  512/13920]\n",
      "loss: 0.039984  [  576/13920]\n",
      "loss: 0.144206  [  640/13920]\n",
      "loss: 0.104523  [  704/13920]\n",
      "loss: 0.100283  [  768/13920]\n",
      "loss: 0.065553  [  832/13920]\n",
      "loss: 0.103323  [  896/13920]\n",
      "loss: 0.066114  [  960/13920]\n",
      "loss: 0.070777  [ 1024/13920]\n",
      "loss: 0.070830  [ 1088/13920]\n",
      "loss: 0.176806  [ 1152/13920]\n",
      "loss: 0.089912  [ 1216/13920]\n",
      "loss: 0.075402  [ 1280/13920]\n",
      "loss: 0.108903  [ 1344/13920]\n",
      "loss: 0.158142  [ 1408/13920]\n",
      "loss: 0.096258  [ 1472/13920]\n",
      "loss: 0.084900  [ 1536/13920]\n",
      "loss: 0.157365  [ 1600/13920]\n",
      "loss: 0.053476  [ 1664/13920]\n",
      "loss: 0.172022  [ 1728/13920]\n",
      "loss: 0.086579  [ 1792/13920]\n",
      "loss: 0.157964  [ 1856/13920]\n",
      "loss: 0.137904  [ 1920/13920]\n",
      "loss: 0.044259  [ 1984/13920]\n",
      "loss: 0.145336  [ 2048/13920]\n",
      "loss: 0.117581  [ 2112/13920]\n",
      "loss: 0.096057  [ 2176/13920]\n",
      "loss: 0.080600  [ 2240/13920]\n",
      "loss: 0.152400  [ 2304/13920]\n",
      "loss: 0.064953  [ 2368/13920]\n",
      "loss: 0.080608  [ 2432/13920]\n",
      "loss: 0.094917  [ 2496/13920]\n",
      "loss: 0.051770  [ 2560/13920]\n",
      "loss: 0.077334  [ 2624/13920]\n",
      "loss: 0.084597  [ 2688/13920]\n",
      "loss: 0.161514  [ 2752/13920]\n",
      "loss: 0.140118  [ 2816/13920]\n",
      "loss: 0.164751  [ 2880/13920]\n",
      "loss: 0.100931  [ 2944/13920]\n",
      "loss: 0.043064  [ 3008/13920]\n",
      "loss: 0.092253  [ 3072/13920]\n",
      "loss: 0.110381  [ 3136/13920]\n",
      "loss: 0.058861  [ 3200/13920]\n",
      "loss: 0.035218  [ 3264/13920]\n",
      "loss: 0.233463  [ 3328/13920]\n",
      "loss: 0.042303  [ 3392/13920]\n",
      "loss: 0.102679  [ 3456/13920]\n",
      "loss: 0.063029  [ 3520/13920]\n",
      "loss: 0.082999  [ 3584/13920]\n",
      "loss: 0.162198  [ 3648/13920]\n",
      "loss: 0.135752  [ 3712/13920]\n",
      "loss: 0.153078  [ 3776/13920]\n",
      "loss: 0.145340  [ 3840/13920]\n",
      "loss: 0.074335  [ 3904/13920]\n",
      "loss: 0.055963  [ 3968/13920]\n",
      "loss: 0.038322  [ 4032/13920]\n",
      "loss: 0.156189  [ 4096/13920]\n",
      "loss: 0.105433  [ 4160/13920]\n",
      "loss: 0.149842  [ 4224/13920]\n",
      "loss: 0.093763  [ 4288/13920]\n",
      "loss: 0.151798  [ 4352/13920]\n",
      "loss: 0.066604  [ 4416/13920]\n",
      "loss: 0.117416  [ 4480/13920]\n",
      "loss: 0.063625  [ 4544/13920]\n",
      "loss: 0.092058  [ 4608/13920]\n",
      "loss: 0.072365  [ 4672/13920]\n",
      "loss: 0.065667  [ 4736/13920]\n",
      "loss: 0.060511  [ 4800/13920]\n",
      "loss: 0.127679  [ 4864/13920]\n",
      "loss: 0.098383  [ 4928/13920]\n",
      "loss: 0.143879  [ 4992/13920]\n",
      "loss: 0.058877  [ 5056/13920]\n",
      "loss: 0.200291  [ 5120/13920]\n",
      "loss: 0.051897  [ 5184/13920]\n",
      "loss: 0.161192  [ 5248/13920]\n",
      "loss: 0.090384  [ 5312/13920]\n",
      "loss: 0.163801  [ 5376/13920]\n",
      "loss: 0.058720  [ 5440/13920]\n",
      "loss: 0.075873  [ 5504/13920]\n",
      "loss: 0.099316  [ 5568/13920]\n",
      "loss: 0.066978  [ 5632/13920]\n",
      "loss: 0.193264  [ 5696/13920]\n",
      "loss: 0.120341  [ 5760/13920]\n",
      "loss: 0.167302  [ 5824/13920]\n",
      "loss: 0.073121  [ 5888/13920]\n",
      "loss: 0.140937  [ 5952/13920]\n",
      "loss: 0.112024  [ 6016/13920]\n",
      "loss: 0.109862  [ 6080/13920]\n",
      "loss: 0.059776  [ 6144/13920]\n",
      "loss: 0.142423  [ 6208/13920]\n",
      "loss: 0.075126  [ 6272/13920]\n",
      "loss: 0.056608  [ 6336/13920]\n",
      "loss: 0.141582  [ 6400/13920]\n",
      "loss: 0.162104  [ 6464/13920]\n",
      "loss: 0.126737  [ 6528/13920]\n",
      "loss: 0.140346  [ 6592/13920]\n",
      "loss: 0.161182  [ 6656/13920]\n",
      "loss: 0.132262  [ 6720/13920]\n",
      "loss: 0.029992  [ 6784/13920]\n",
      "loss: 0.077360  [ 6848/13920]\n",
      "loss: 0.111539  [ 6912/13920]\n",
      "loss: 0.048314  [ 6976/13920]\n",
      "loss: 0.102197  [ 7040/13920]\n",
      "loss: 0.135615  [ 7104/13920]\n",
      "loss: 0.057206  [ 7168/13920]\n",
      "loss: 0.081541  [ 7232/13920]\n",
      "loss: 0.113709  [ 7296/13920]\n",
      "loss: 0.185247  [ 7360/13920]\n",
      "loss: 0.138795  [ 7424/13920]\n",
      "loss: 0.100258  [ 7488/13920]\n",
      "loss: 0.074174  [ 7552/13920]\n",
      "loss: 0.073007  [ 7616/13920]\n",
      "loss: 0.199513  [ 7680/13920]\n",
      "loss: 0.039981  [ 7744/13920]\n",
      "loss: 0.081332  [ 7808/13920]\n",
      "loss: 0.113145  [ 7872/13920]\n",
      "loss: 0.072456  [ 7936/13920]\n",
      "loss: 0.250834  [ 8000/13920]\n",
      "loss: 0.138687  [ 8064/13920]\n",
      "loss: 0.103502  [ 8128/13920]\n",
      "loss: 0.071355  [ 8192/13920]\n",
      "loss: 0.149181  [ 8256/13920]\n",
      "loss: 0.123311  [ 8320/13920]\n",
      "loss: 0.128714  [ 8384/13920]\n",
      "loss: 0.131715  [ 8448/13920]\n",
      "loss: 0.092617  [ 8512/13920]\n",
      "loss: 0.053964  [ 8576/13920]\n",
      "loss: 0.158454  [ 8640/13920]\n",
      "loss: 0.242386  [ 8704/13920]\n",
      "loss: 0.038572  [ 8768/13920]\n",
      "loss: 0.156722  [ 8832/13920]\n",
      "loss: 0.057410  [ 8896/13920]\n",
      "loss: 0.123784  [ 8960/13920]\n",
      "loss: 0.088144  [ 9024/13920]\n",
      "loss: 0.078268  [ 9088/13920]\n",
      "loss: 0.072148  [ 9152/13920]\n",
      "loss: 0.133257  [ 9216/13920]\n",
      "loss: 0.067078  [ 9280/13920]\n",
      "loss: 0.119457  [ 9344/13920]\n",
      "loss: 0.146996  [ 9408/13920]\n",
      "loss: 0.070523  [ 9472/13920]\n",
      "loss: 0.067189  [ 9536/13920]\n",
      "loss: 0.079872  [ 9600/13920]\n",
      "loss: 0.234261  [ 9664/13920]\n",
      "loss: 0.049722  [ 9728/13920]\n",
      "loss: 0.039336  [ 9792/13920]\n",
      "loss: 0.114978  [ 9856/13920]\n",
      "loss: 0.053651  [ 9920/13920]\n",
      "loss: 0.103616  [ 9984/13920]\n",
      "loss: 0.056555  [10048/13920]\n",
      "loss: 0.136555  [10112/13920]\n",
      "loss: 0.062273  [10176/13920]\n",
      "loss: 0.066609  [10240/13920]\n",
      "loss: 0.114602  [10304/13920]\n",
      "loss: 0.060314  [10368/13920]\n",
      "loss: 0.077100  [10432/13920]\n",
      "loss: 0.107359  [10496/13920]\n",
      "loss: 0.119150  [10560/13920]\n",
      "loss: 0.092479  [10624/13920]\n",
      "loss: 0.239807  [10688/13920]\n",
      "loss: 0.092042  [10752/13920]\n",
      "loss: 0.055576  [10816/13920]\n",
      "loss: 0.051019  [10880/13920]\n",
      "loss: 0.037439  [10944/13920]\n",
      "loss: 0.231614  [11008/13920]\n",
      "loss: 0.042996  [11072/13920]\n",
      "loss: 0.073815  [11136/13920]\n",
      "loss: 0.119758  [11200/13920]\n",
      "loss: 0.070041  [11264/13920]\n",
      "loss: 0.056133  [11328/13920]\n",
      "loss: 0.060422  [11392/13920]\n",
      "loss: 0.078619  [11456/13920]\n",
      "loss: 0.105613  [11520/13920]\n",
      "loss: 0.053912  [11584/13920]\n",
      "loss: 0.054310  [11648/13920]\n",
      "loss: 0.134454  [11712/13920]\n",
      "loss: 0.131632  [11776/13920]\n",
      "loss: 0.169700  [11840/13920]\n",
      "loss: 0.052964  [11904/13920]\n",
      "loss: 0.137519  [11968/13920]\n",
      "loss: 0.085210  [12032/13920]\n",
      "loss: 0.066248  [12096/13920]\n",
      "loss: 0.072645  [12160/13920]\n",
      "loss: 0.086581  [12224/13920]\n",
      "loss: 0.120555  [12288/13920]\n",
      "loss: 0.075043  [12352/13920]\n",
      "loss: 0.080250  [12416/13920]\n",
      "loss: 0.151822  [12480/13920]\n",
      "loss: 0.133463  [12544/13920]\n",
      "loss: 0.072700  [12608/13920]\n",
      "loss: 0.109184  [12672/13920]\n",
      "loss: 0.090641  [12736/13920]\n",
      "loss: 0.054481  [12800/13920]\n",
      "loss: 0.033157  [12864/13920]\n",
      "loss: 0.105973  [12928/13920]\n",
      "loss: 0.068166  [12992/13920]\n",
      "loss: 0.082330  [13056/13920]\n",
      "loss: 0.037129  [13120/13920]\n",
      "loss: 0.062538  [13184/13920]\n",
      "loss: 0.176282  [13248/13920]\n",
      "loss: 0.059538  [13312/13920]\n",
      "loss: 0.111350  [13376/13920]\n",
      "loss: 0.094174  [13440/13920]\n",
      "loss: 0.079852  [13504/13920]\n",
      "loss: 0.087182  [13568/13920]\n",
      "loss: 0.054991  [13632/13920]\n",
      "loss: 0.054830  [13696/13920]\n",
      "loss: 0.188516  [13760/13920]\n",
      "loss: 0.113308  [13824/13920]\n",
      "loss: 0.097730  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 96.7% \n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.120394 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.120935  [    0/13920]\n",
      "loss: 0.080958  [   64/13920]\n",
      "loss: 0.033606  [  128/13920]\n",
      "loss: 0.052365  [  192/13920]\n",
      "loss: 0.103932  [  256/13920]\n",
      "loss: 0.119214  [  320/13920]\n",
      "loss: 0.173222  [  384/13920]\n",
      "loss: 0.069712  [  448/13920]\n",
      "loss: 0.096100  [  512/13920]\n",
      "loss: 0.053190  [  576/13920]\n",
      "loss: 0.057255  [  640/13920]\n",
      "loss: 0.065022  [  704/13920]\n",
      "loss: 0.158391  [  768/13920]\n",
      "loss: 0.086318  [  832/13920]\n",
      "loss: 0.102182  [  896/13920]\n",
      "loss: 0.032318  [  960/13920]\n",
      "loss: 0.140498  [ 1024/13920]\n",
      "loss: 0.065506  [ 1088/13920]\n",
      "loss: 0.091515  [ 1152/13920]\n",
      "loss: 0.075839  [ 1216/13920]\n",
      "loss: 0.112864  [ 1280/13920]\n",
      "loss: 0.059613  [ 1344/13920]\n",
      "loss: 0.053942  [ 1408/13920]\n",
      "loss: 0.053448  [ 1472/13920]\n",
      "loss: 0.120883  [ 1536/13920]\n",
      "loss: 0.087457  [ 1600/13920]\n",
      "loss: 0.040020  [ 1664/13920]\n",
      "loss: 0.093627  [ 1728/13920]\n",
      "loss: 0.139292  [ 1792/13920]\n",
      "loss: 0.057283  [ 1856/13920]\n",
      "loss: 0.070810  [ 1920/13920]\n",
      "loss: 0.109880  [ 1984/13920]\n",
      "loss: 0.088295  [ 2048/13920]\n",
      "loss: 0.069748  [ 2112/13920]\n",
      "loss: 0.061824  [ 2176/13920]\n",
      "loss: 0.077408  [ 2240/13920]\n",
      "loss: 0.056255  [ 2304/13920]\n",
      "loss: 0.071842  [ 2368/13920]\n",
      "loss: 0.106130  [ 2432/13920]\n",
      "loss: 0.079959  [ 2496/13920]\n",
      "loss: 0.052529  [ 2560/13920]\n",
      "loss: 0.057905  [ 2624/13920]\n",
      "loss: 0.096001  [ 2688/13920]\n",
      "loss: 0.076419  [ 2752/13920]\n",
      "loss: 0.047752  [ 2816/13920]\n",
      "loss: 0.197804  [ 2880/13920]\n",
      "loss: 0.138673  [ 2944/13920]\n",
      "loss: 0.022837  [ 3008/13920]\n",
      "loss: 0.043943  [ 3072/13920]\n",
      "loss: 0.047018  [ 3136/13920]\n",
      "loss: 0.050032  [ 3200/13920]\n",
      "loss: 0.046540  [ 3264/13920]\n",
      "loss: 0.100013  [ 3328/13920]\n",
      "loss: 0.179156  [ 3392/13920]\n",
      "loss: 0.134235  [ 3456/13920]\n",
      "loss: 0.069459  [ 3520/13920]\n",
      "loss: 0.104048  [ 3584/13920]\n",
      "loss: 0.054087  [ 3648/13920]\n",
      "loss: 0.033507  [ 3712/13920]\n",
      "loss: 0.106394  [ 3776/13920]\n",
      "loss: 0.048746  [ 3840/13920]\n",
      "loss: 0.114181  [ 3904/13920]\n",
      "loss: 0.117000  [ 3968/13920]\n",
      "loss: 0.056445  [ 4032/13920]\n",
      "loss: 0.109259  [ 4096/13920]\n",
      "loss: 0.159385  [ 4160/13920]\n",
      "loss: 0.151052  [ 4224/13920]\n",
      "loss: 0.075796  [ 4288/13920]\n",
      "loss: 0.078719  [ 4352/13920]\n",
      "loss: 0.156797  [ 4416/13920]\n",
      "loss: 0.054481  [ 4480/13920]\n",
      "loss: 0.065290  [ 4544/13920]\n",
      "loss: 0.073261  [ 4608/13920]\n",
      "loss: 0.029734  [ 4672/13920]\n",
      "loss: 0.075239  [ 4736/13920]\n",
      "loss: 0.075040  [ 4800/13920]\n",
      "loss: 0.074988  [ 4864/13920]\n",
      "loss: 0.139892  [ 4928/13920]\n",
      "loss: 0.070852  [ 4992/13920]\n",
      "loss: 0.050099  [ 5056/13920]\n",
      "loss: 0.133073  [ 5120/13920]\n",
      "loss: 0.142029  [ 5184/13920]\n",
      "loss: 0.106394  [ 5248/13920]\n",
      "loss: 0.125808  [ 5312/13920]\n",
      "loss: 0.104895  [ 5376/13920]\n",
      "loss: 0.066942  [ 5440/13920]\n",
      "loss: 0.113818  [ 5504/13920]\n",
      "loss: 0.064201  [ 5568/13920]\n",
      "loss: 0.071091  [ 5632/13920]\n",
      "loss: 0.117871  [ 5696/13920]\n",
      "loss: 0.146680  [ 5760/13920]\n",
      "loss: 0.177410  [ 5824/13920]\n",
      "loss: 0.097229  [ 5888/13920]\n",
      "loss: 0.059220  [ 5952/13920]\n",
      "loss: 0.040544  [ 6016/13920]\n",
      "loss: 0.050937  [ 6080/13920]\n",
      "loss: 0.067186  [ 6144/13920]\n",
      "loss: 0.066668  [ 6208/13920]\n",
      "loss: 0.185113  [ 6272/13920]\n",
      "loss: 0.117607  [ 6336/13920]\n",
      "loss: 0.064132  [ 6400/13920]\n",
      "loss: 0.063707  [ 6464/13920]\n",
      "loss: 0.205547  [ 6528/13920]\n",
      "loss: 0.053019  [ 6592/13920]\n",
      "loss: 0.059215  [ 6656/13920]\n",
      "loss: 0.046848  [ 6720/13920]\n",
      "loss: 0.053050  [ 6784/13920]\n",
      "loss: 0.067845  [ 6848/13920]\n",
      "loss: 0.092161  [ 6912/13920]\n",
      "loss: 0.074224  [ 6976/13920]\n",
      "loss: 0.025141  [ 7040/13920]\n",
      "loss: 0.117161  [ 7104/13920]\n",
      "loss: 0.104925  [ 7168/13920]\n",
      "loss: 0.091568  [ 7232/13920]\n",
      "loss: 0.233143  [ 7296/13920]\n",
      "loss: 0.023784  [ 7360/13920]\n",
      "loss: 0.046933  [ 7424/13920]\n",
      "loss: 0.038414  [ 7488/13920]\n",
      "loss: 0.084516  [ 7552/13920]\n",
      "loss: 0.066061  [ 7616/13920]\n",
      "loss: 0.062138  [ 7680/13920]\n",
      "loss: 0.087223  [ 7744/13920]\n",
      "loss: 0.081925  [ 7808/13920]\n",
      "loss: 0.038233  [ 7872/13920]\n",
      "loss: 0.063719  [ 7936/13920]\n",
      "loss: 0.164806  [ 8000/13920]\n",
      "loss: 0.060170  [ 8064/13920]\n",
      "loss: 0.082097  [ 8128/13920]\n",
      "loss: 0.146081  [ 8192/13920]\n",
      "loss: 0.050202  [ 8256/13920]\n",
      "loss: 0.065136  [ 8320/13920]\n",
      "loss: 0.061271  [ 8384/13920]\n",
      "loss: 0.051790  [ 8448/13920]\n",
      "loss: 0.085978  [ 8512/13920]\n",
      "loss: 0.048341  [ 8576/13920]\n",
      "loss: 0.153569  [ 8640/13920]\n",
      "loss: 0.181085  [ 8704/13920]\n",
      "loss: 0.058783  [ 8768/13920]\n",
      "loss: 0.144855  [ 8832/13920]\n",
      "loss: 0.066252  [ 8896/13920]\n",
      "loss: 0.129542  [ 8960/13920]\n",
      "loss: 0.124993  [ 9024/13920]\n",
      "loss: 0.206114  [ 9088/13920]\n",
      "loss: 0.065702  [ 9152/13920]\n",
      "loss: 0.045693  [ 9216/13920]\n",
      "loss: 0.064486  [ 9280/13920]\n",
      "loss: 0.051281  [ 9344/13920]\n",
      "loss: 0.059892  [ 9408/13920]\n",
      "loss: 0.083997  [ 9472/13920]\n",
      "loss: 0.081150  [ 9536/13920]\n",
      "loss: 0.181307  [ 9600/13920]\n",
      "loss: 0.049627  [ 9664/13920]\n",
      "loss: 0.138366  [ 9728/13920]\n",
      "loss: 0.168982  [ 9792/13920]\n",
      "loss: 0.029674  [ 9856/13920]\n",
      "loss: 0.069775  [ 9920/13920]\n",
      "loss: 0.027926  [ 9984/13920]\n",
      "loss: 0.092483  [10048/13920]\n",
      "loss: 0.076206  [10112/13920]\n",
      "loss: 0.139634  [10176/13920]\n",
      "loss: 0.058315  [10240/13920]\n",
      "loss: 0.075027  [10304/13920]\n",
      "loss: 0.078481  [10368/13920]\n",
      "loss: 0.060989  [10432/13920]\n",
      "loss: 0.100426  [10496/13920]\n",
      "loss: 0.072902  [10560/13920]\n",
      "loss: 0.025832  [10624/13920]\n",
      "loss: 0.054262  [10688/13920]\n",
      "loss: 0.103948  [10752/13920]\n",
      "loss: 0.156521  [10816/13920]\n",
      "loss: 0.044949  [10880/13920]\n",
      "loss: 0.101796  [10944/13920]\n",
      "loss: 0.123278  [11008/13920]\n",
      "loss: 0.059452  [11072/13920]\n",
      "loss: 0.087933  [11136/13920]\n",
      "loss: 0.031464  [11200/13920]\n",
      "loss: 0.029466  [11264/13920]\n",
      "loss: 0.083759  [11328/13920]\n",
      "loss: 0.079825  [11392/13920]\n",
      "loss: 0.084794  [11456/13920]\n",
      "loss: 0.178944  [11520/13920]\n",
      "loss: 0.081884  [11584/13920]\n",
      "loss: 0.057959  [11648/13920]\n",
      "loss: 0.064327  [11712/13920]\n",
      "loss: 0.111666  [11776/13920]\n",
      "loss: 0.027157  [11840/13920]\n",
      "loss: 0.139255  [11904/13920]\n",
      "loss: 0.136223  [11968/13920]\n",
      "loss: 0.090945  [12032/13920]\n",
      "loss: 0.103087  [12096/13920]\n",
      "loss: 0.081918  [12160/13920]\n",
      "loss: 0.092770  [12224/13920]\n",
      "loss: 0.070075  [12288/13920]\n",
      "loss: 0.076129  [12352/13920]\n",
      "loss: 0.093804  [12416/13920]\n",
      "loss: 0.191604  [12480/13920]\n",
      "loss: 0.052140  [12544/13920]\n",
      "loss: 0.072120  [12608/13920]\n",
      "loss: 0.077972  [12672/13920]\n",
      "loss: 0.138578  [12736/13920]\n",
      "loss: 0.112728  [12800/13920]\n",
      "loss: 0.076830  [12864/13920]\n",
      "loss: 0.119447  [12928/13920]\n",
      "loss: 0.077244  [12992/13920]\n",
      "loss: 0.067943  [13056/13920]\n",
      "loss: 0.074382  [13120/13920]\n",
      "loss: 0.203588  [13184/13920]\n",
      "loss: 0.065655  [13248/13920]\n",
      "loss: 0.049321  [13312/13920]\n",
      "loss: 0.113115  [13376/13920]\n",
      "loss: 0.049280  [13440/13920]\n",
      "loss: 0.098825  [13504/13920]\n",
      "loss: 0.109939  [13568/13920]\n",
      "loss: 0.101858  [13632/13920]\n",
      "loss: 0.117206  [13696/13920]\n",
      "loss: 0.104051  [13760/13920]\n",
      "loss: 0.039223  [13824/13920]\n",
      "loss: 0.176990  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.1% \n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.124394 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.036922  [    0/13920]\n",
      "loss: 0.041407  [   64/13920]\n",
      "loss: 0.103173  [  128/13920]\n",
      "loss: 0.083522  [  192/13920]\n",
      "loss: 0.156339  [  256/13920]\n",
      "loss: 0.081568  [  320/13920]\n",
      "loss: 0.046218  [  384/13920]\n",
      "loss: 0.134354  [  448/13920]\n",
      "loss: 0.088865  [  512/13920]\n",
      "loss: 0.065130  [  576/13920]\n",
      "loss: 0.047685  [  640/13920]\n",
      "loss: 0.068561  [  704/13920]\n",
      "loss: 0.068353  [  768/13920]\n",
      "loss: 0.075231  [  832/13920]\n",
      "loss: 0.119868  [  896/13920]\n",
      "loss: 0.079603  [  960/13920]\n",
      "loss: 0.046027  [ 1024/13920]\n",
      "loss: 0.073840  [ 1088/13920]\n",
      "loss: 0.035352  [ 1152/13920]\n",
      "loss: 0.071042  [ 1216/13920]\n",
      "loss: 0.096981  [ 1280/13920]\n",
      "loss: 0.057075  [ 1344/13920]\n",
      "loss: 0.056673  [ 1408/13920]\n",
      "loss: 0.036440  [ 1472/13920]\n",
      "loss: 0.069723  [ 1536/13920]\n",
      "loss: 0.079491  [ 1600/13920]\n",
      "loss: 0.016538  [ 1664/13920]\n",
      "loss: 0.085091  [ 1728/13920]\n",
      "loss: 0.026263  [ 1792/13920]\n",
      "loss: 0.084690  [ 1856/13920]\n",
      "loss: 0.020490  [ 1920/13920]\n",
      "loss: 0.041492  [ 1984/13920]\n",
      "loss: 0.124220  [ 2048/13920]\n",
      "loss: 0.067530  [ 2112/13920]\n",
      "loss: 0.031847  [ 2176/13920]\n",
      "loss: 0.039013  [ 2240/13920]\n",
      "loss: 0.046574  [ 2304/13920]\n",
      "loss: 0.092026  [ 2368/13920]\n",
      "loss: 0.031079  [ 2432/13920]\n",
      "loss: 0.086187  [ 2496/13920]\n",
      "loss: 0.109122  [ 2560/13920]\n",
      "loss: 0.055363  [ 2624/13920]\n",
      "loss: 0.038449  [ 2688/13920]\n",
      "loss: 0.055932  [ 2752/13920]\n",
      "loss: 0.052144  [ 2816/13920]\n",
      "loss: 0.047082  [ 2880/13920]\n",
      "loss: 0.122574  [ 2944/13920]\n",
      "loss: 0.073350  [ 3008/13920]\n",
      "loss: 0.154491  [ 3072/13920]\n",
      "loss: 0.087764  [ 3136/13920]\n",
      "loss: 0.072975  [ 3200/13920]\n",
      "loss: 0.122283  [ 3264/13920]\n",
      "loss: 0.112615  [ 3328/13920]\n",
      "loss: 0.071875  [ 3392/13920]\n",
      "loss: 0.042131  [ 3456/13920]\n",
      "loss: 0.061174  [ 3520/13920]\n",
      "loss: 0.060085  [ 3584/13920]\n",
      "loss: 0.063330  [ 3648/13920]\n",
      "loss: 0.066877  [ 3712/13920]\n",
      "loss: 0.063829  [ 3776/13920]\n",
      "loss: 0.091623  [ 3840/13920]\n",
      "loss: 0.026242  [ 3904/13920]\n",
      "loss: 0.102088  [ 3968/13920]\n",
      "loss: 0.098151  [ 4032/13920]\n",
      "loss: 0.048491  [ 4096/13920]\n",
      "loss: 0.083706  [ 4160/13920]\n",
      "loss: 0.089122  [ 4224/13920]\n",
      "loss: 0.069584  [ 4288/13920]\n",
      "loss: 0.240426  [ 4352/13920]\n",
      "loss: 0.098605  [ 4416/13920]\n",
      "loss: 0.066023  [ 4480/13920]\n",
      "loss: 0.074253  [ 4544/13920]\n",
      "loss: 0.034912  [ 4608/13920]\n",
      "loss: 0.101721  [ 4672/13920]\n",
      "loss: 0.081287  [ 4736/13920]\n",
      "loss: 0.097737  [ 4800/13920]\n",
      "loss: 0.044075  [ 4864/13920]\n",
      "loss: 0.086645  [ 4928/13920]\n",
      "loss: 0.092573  [ 4992/13920]\n",
      "loss: 0.043355  [ 5056/13920]\n",
      "loss: 0.084222  [ 5120/13920]\n",
      "loss: 0.108331  [ 5184/13920]\n",
      "loss: 0.102082  [ 5248/13920]\n",
      "loss: 0.093717  [ 5312/13920]\n",
      "loss: 0.150897  [ 5376/13920]\n",
      "loss: 0.055686  [ 5440/13920]\n",
      "loss: 0.074605  [ 5504/13920]\n",
      "loss: 0.070594  [ 5568/13920]\n",
      "loss: 0.066854  [ 5632/13920]\n",
      "loss: 0.022907  [ 5696/13920]\n",
      "loss: 0.032971  [ 5760/13920]\n",
      "loss: 0.075399  [ 5824/13920]\n",
      "loss: 0.126969  [ 5888/13920]\n",
      "loss: 0.140977  [ 5952/13920]\n",
      "loss: 0.059948  [ 6016/13920]\n",
      "loss: 0.028969  [ 6080/13920]\n",
      "loss: 0.036611  [ 6144/13920]\n",
      "loss: 0.040791  [ 6208/13920]\n",
      "loss: 0.082838  [ 6272/13920]\n",
      "loss: 0.078569  [ 6336/13920]\n",
      "loss: 0.034394  [ 6400/13920]\n",
      "loss: 0.148570  [ 6464/13920]\n",
      "loss: 0.090143  [ 6528/13920]\n",
      "loss: 0.116703  [ 6592/13920]\n",
      "loss: 0.039669  [ 6656/13920]\n",
      "loss: 0.099291  [ 6720/13920]\n",
      "loss: 0.050938  [ 6784/13920]\n",
      "loss: 0.050965  [ 6848/13920]\n",
      "loss: 0.062358  [ 6912/13920]\n",
      "loss: 0.056904  [ 6976/13920]\n",
      "loss: 0.117038  [ 7040/13920]\n",
      "loss: 0.045939  [ 7104/13920]\n",
      "loss: 0.123331  [ 7168/13920]\n",
      "loss: 0.109951  [ 7232/13920]\n",
      "loss: 0.067837  [ 7296/13920]\n",
      "loss: 0.021041  [ 7360/13920]\n",
      "loss: 0.063210  [ 7424/13920]\n",
      "loss: 0.040888  [ 7488/13920]\n",
      "loss: 0.097775  [ 7552/13920]\n",
      "loss: 0.053085  [ 7616/13920]\n",
      "loss: 0.025886  [ 7680/13920]\n",
      "loss: 0.065900  [ 7744/13920]\n",
      "loss: 0.133751  [ 7808/13920]\n",
      "loss: 0.032433  [ 7872/13920]\n",
      "loss: 0.035347  [ 7936/13920]\n",
      "loss: 0.040541  [ 8000/13920]\n",
      "loss: 0.067668  [ 8064/13920]\n",
      "loss: 0.138117  [ 8128/13920]\n",
      "loss: 0.041387  [ 8192/13920]\n",
      "loss: 0.030873  [ 8256/13920]\n",
      "loss: 0.045319  [ 8320/13920]\n",
      "loss: 0.116599  [ 8384/13920]\n",
      "loss: 0.024385  [ 8448/13920]\n",
      "loss: 0.062465  [ 8512/13920]\n",
      "loss: 0.025871  [ 8576/13920]\n",
      "loss: 0.066382  [ 8640/13920]\n",
      "loss: 0.021239  [ 8704/13920]\n",
      "loss: 0.080999  [ 8768/13920]\n",
      "loss: 0.156883  [ 8832/13920]\n",
      "loss: 0.053687  [ 8896/13920]\n",
      "loss: 0.086586  [ 8960/13920]\n",
      "loss: 0.035591  [ 9024/13920]\n",
      "loss: 0.078089  [ 9088/13920]\n",
      "loss: 0.030221  [ 9152/13920]\n",
      "loss: 0.060351  [ 9216/13920]\n",
      "loss: 0.047199  [ 9280/13920]\n",
      "loss: 0.043149  [ 9344/13920]\n",
      "loss: 0.129663  [ 9408/13920]\n",
      "loss: 0.071257  [ 9472/13920]\n",
      "loss: 0.120887  [ 9536/13920]\n",
      "loss: 0.051975  [ 9600/13920]\n",
      "loss: 0.036800  [ 9664/13920]\n",
      "loss: 0.025934  [ 9728/13920]\n",
      "loss: 0.050768  [ 9792/13920]\n",
      "loss: 0.043527  [ 9856/13920]\n",
      "loss: 0.140281  [ 9920/13920]\n",
      "loss: 0.089127  [ 9984/13920]\n",
      "loss: 0.062674  [10048/13920]\n",
      "loss: 0.029232  [10112/13920]\n",
      "loss: 0.039416  [10176/13920]\n",
      "loss: 0.028011  [10240/13920]\n",
      "loss: 0.039332  [10304/13920]\n",
      "loss: 0.029377  [10368/13920]\n",
      "loss: 0.087359  [10432/13920]\n",
      "loss: 0.021684  [10496/13920]\n",
      "loss: 0.094473  [10560/13920]\n",
      "loss: 0.029693  [10624/13920]\n",
      "loss: 0.028379  [10688/13920]\n",
      "loss: 0.097767  [10752/13920]\n",
      "loss: 0.032034  [10816/13920]\n",
      "loss: 0.065172  [10880/13920]\n",
      "loss: 0.038618  [10944/13920]\n",
      "loss: 0.055186  [11008/13920]\n",
      "loss: 0.044567  [11072/13920]\n",
      "loss: 0.064054  [11136/13920]\n",
      "loss: 0.040368  [11200/13920]\n",
      "loss: 0.044896  [11264/13920]\n",
      "loss: 0.046741  [11328/13920]\n",
      "loss: 0.072220  [11392/13920]\n",
      "loss: 0.039955  [11456/13920]\n",
      "loss: 0.086583  [11520/13920]\n",
      "loss: 0.051740  [11584/13920]\n",
      "loss: 0.069615  [11648/13920]\n",
      "loss: 0.056188  [11712/13920]\n",
      "loss: 0.089888  [11776/13920]\n",
      "loss: 0.097735  [11840/13920]\n",
      "loss: 0.132378  [11904/13920]\n",
      "loss: 0.123590  [11968/13920]\n",
      "loss: 0.046637  [12032/13920]\n",
      "loss: 0.097676  [12096/13920]\n",
      "loss: 0.116955  [12160/13920]\n",
      "loss: 0.050420  [12224/13920]\n",
      "loss: 0.071066  [12288/13920]\n",
      "loss: 0.143212  [12352/13920]\n",
      "loss: 0.046136  [12416/13920]\n",
      "loss: 0.062544  [12480/13920]\n",
      "loss: 0.060285  [12544/13920]\n",
      "loss: 0.044099  [12608/13920]\n",
      "loss: 0.057414  [12672/13920]\n",
      "loss: 0.103492  [12736/13920]\n",
      "loss: 0.110887  [12800/13920]\n",
      "loss: 0.099156  [12864/13920]\n",
      "loss: 0.124505  [12928/13920]\n",
      "loss: 0.059306  [12992/13920]\n",
      "loss: 0.095962  [13056/13920]\n",
      "loss: 0.066654  [13120/13920]\n",
      "loss: 0.058891  [13184/13920]\n",
      "loss: 0.049859  [13248/13920]\n",
      "loss: 0.031052  [13312/13920]\n",
      "loss: 0.068463  [13376/13920]\n",
      "loss: 0.063503  [13440/13920]\n",
      "loss: 0.101303  [13504/13920]\n",
      "loss: 0.107384  [13568/13920]\n",
      "loss: 0.107479  [13632/13920]\n",
      "loss: 0.101816  [13696/13920]\n",
      "loss: 0.043736  [13760/13920]\n",
      "loss: 0.068263  [13824/13920]\n",
      "loss: 0.039606  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.9% \n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.114622 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.069631  [    0/13920]\n",
      "loss: 0.041644  [   64/13920]\n",
      "loss: 0.023610  [  128/13920]\n",
      "loss: 0.069961  [  192/13920]\n",
      "loss: 0.066799  [  256/13920]\n",
      "loss: 0.019177  [  320/13920]\n",
      "loss: 0.098650  [  384/13920]\n",
      "loss: 0.033152  [  448/13920]\n",
      "loss: 0.098144  [  512/13920]\n",
      "loss: 0.034198  [  576/13920]\n",
      "loss: 0.026585  [  640/13920]\n",
      "loss: 0.109858  [  704/13920]\n",
      "loss: 0.039512  [  768/13920]\n",
      "loss: 0.023612  [  832/13920]\n",
      "loss: 0.032513  [  896/13920]\n",
      "loss: 0.166799  [  960/13920]\n",
      "loss: 0.045139  [ 1024/13920]\n",
      "loss: 0.104377  [ 1088/13920]\n",
      "loss: 0.056129  [ 1152/13920]\n",
      "loss: 0.032077  [ 1216/13920]\n",
      "loss: 0.036971  [ 1280/13920]\n",
      "loss: 0.047432  [ 1344/13920]\n",
      "loss: 0.072709  [ 1408/13920]\n",
      "loss: 0.044957  [ 1472/13920]\n",
      "loss: 0.120832  [ 1536/13920]\n",
      "loss: 0.088977  [ 1600/13920]\n",
      "loss: 0.039546  [ 1664/13920]\n",
      "loss: 0.092302  [ 1728/13920]\n",
      "loss: 0.058154  [ 1792/13920]\n",
      "loss: 0.129792  [ 1856/13920]\n",
      "loss: 0.175809  [ 1920/13920]\n",
      "loss: 0.041067  [ 1984/13920]\n",
      "loss: 0.037478  [ 2048/13920]\n",
      "loss: 0.039021  [ 2112/13920]\n",
      "loss: 0.037162  [ 2176/13920]\n",
      "loss: 0.175839  [ 2240/13920]\n",
      "loss: 0.185829  [ 2304/13920]\n",
      "loss: 0.031789  [ 2368/13920]\n",
      "loss: 0.065154  [ 2432/13920]\n",
      "loss: 0.046983  [ 2496/13920]\n",
      "loss: 0.056207  [ 2560/13920]\n",
      "loss: 0.063515  [ 2624/13920]\n",
      "loss: 0.039687  [ 2688/13920]\n",
      "loss: 0.095109  [ 2752/13920]\n",
      "loss: 0.082204  [ 2816/13920]\n",
      "loss: 0.079710  [ 2880/13920]\n",
      "loss: 0.065716  [ 2944/13920]\n",
      "loss: 0.083521  [ 3008/13920]\n",
      "loss: 0.063683  [ 3072/13920]\n",
      "loss: 0.011823  [ 3136/13920]\n",
      "loss: 0.027268  [ 3200/13920]\n",
      "loss: 0.083053  [ 3264/13920]\n",
      "loss: 0.084087  [ 3328/13920]\n",
      "loss: 0.067862  [ 3392/13920]\n",
      "loss: 0.080516  [ 3456/13920]\n",
      "loss: 0.053398  [ 3520/13920]\n",
      "loss: 0.028876  [ 3584/13920]\n",
      "loss: 0.037396  [ 3648/13920]\n",
      "loss: 0.099238  [ 3712/13920]\n",
      "loss: 0.027910  [ 3776/13920]\n",
      "loss: 0.055335  [ 3840/13920]\n",
      "loss: 0.078415  [ 3904/13920]\n",
      "loss: 0.016356  [ 3968/13920]\n",
      "loss: 0.078830  [ 4032/13920]\n",
      "loss: 0.016167  [ 4096/13920]\n",
      "loss: 0.030449  [ 4160/13920]\n",
      "loss: 0.043585  [ 4224/13920]\n",
      "loss: 0.206458  [ 4288/13920]\n",
      "loss: 0.032991  [ 4352/13920]\n",
      "loss: 0.030716  [ 4416/13920]\n",
      "loss: 0.064207  [ 4480/13920]\n",
      "loss: 0.105949  [ 4544/13920]\n",
      "loss: 0.034010  [ 4608/13920]\n",
      "loss: 0.139003  [ 4672/13920]\n",
      "loss: 0.102109  [ 4736/13920]\n",
      "loss: 0.025238  [ 4800/13920]\n",
      "loss: 0.091097  [ 4864/13920]\n",
      "loss: 0.056456  [ 4928/13920]\n",
      "loss: 0.053856  [ 4992/13920]\n",
      "loss: 0.078335  [ 5056/13920]\n",
      "loss: 0.196523  [ 5120/13920]\n",
      "loss: 0.050804  [ 5184/13920]\n",
      "loss: 0.042709  [ 5248/13920]\n",
      "loss: 0.047971  [ 5312/13920]\n",
      "loss: 0.044359  [ 5376/13920]\n",
      "loss: 0.042653  [ 5440/13920]\n",
      "loss: 0.063907  [ 5504/13920]\n",
      "loss: 0.083596  [ 5568/13920]\n",
      "loss: 0.024103  [ 5632/13920]\n",
      "loss: 0.076692  [ 5696/13920]\n",
      "loss: 0.135192  [ 5760/13920]\n",
      "loss: 0.062738  [ 5824/13920]\n",
      "loss: 0.098118  [ 5888/13920]\n",
      "loss: 0.052620  [ 5952/13920]\n",
      "loss: 0.019001  [ 6016/13920]\n",
      "loss: 0.031264  [ 6080/13920]\n",
      "loss: 0.039105  [ 6144/13920]\n",
      "loss: 0.040263  [ 6208/13920]\n",
      "loss: 0.041416  [ 6272/13920]\n",
      "loss: 0.056616  [ 6336/13920]\n",
      "loss: 0.070046  [ 6400/13920]\n",
      "loss: 0.063711  [ 6464/13920]\n",
      "loss: 0.069277  [ 6528/13920]\n",
      "loss: 0.027729  [ 6592/13920]\n",
      "loss: 0.083772  [ 6656/13920]\n",
      "loss: 0.041757  [ 6720/13920]\n",
      "loss: 0.019577  [ 6784/13920]\n",
      "loss: 0.026865  [ 6848/13920]\n",
      "loss: 0.063602  [ 6912/13920]\n",
      "loss: 0.067516  [ 6976/13920]\n",
      "loss: 0.066405  [ 7040/13920]\n",
      "loss: 0.090828  [ 7104/13920]\n",
      "loss: 0.049327  [ 7168/13920]\n",
      "loss: 0.054585  [ 7232/13920]\n",
      "loss: 0.032579  [ 7296/13920]\n",
      "loss: 0.031095  [ 7360/13920]\n",
      "loss: 0.029259  [ 7424/13920]\n",
      "loss: 0.108606  [ 7488/13920]\n",
      "loss: 0.028009  [ 7552/13920]\n",
      "loss: 0.041136  [ 7616/13920]\n",
      "loss: 0.033238  [ 7680/13920]\n",
      "loss: 0.053215  [ 7744/13920]\n",
      "loss: 0.076917  [ 7808/13920]\n",
      "loss: 0.073629  [ 7872/13920]\n",
      "loss: 0.059774  [ 7936/13920]\n",
      "loss: 0.068135  [ 8000/13920]\n",
      "loss: 0.057757  [ 8064/13920]\n",
      "loss: 0.055624  [ 8128/13920]\n",
      "loss: 0.094812  [ 8192/13920]\n",
      "loss: 0.099467  [ 8256/13920]\n",
      "loss: 0.072203  [ 8320/13920]\n",
      "loss: 0.033581  [ 8384/13920]\n",
      "loss: 0.049404  [ 8448/13920]\n",
      "loss: 0.117940  [ 8512/13920]\n",
      "loss: 0.113146  [ 8576/13920]\n",
      "loss: 0.131463  [ 8640/13920]\n",
      "loss: 0.083582  [ 8704/13920]\n",
      "loss: 0.034176  [ 8768/13920]\n",
      "loss: 0.083233  [ 8832/13920]\n",
      "loss: 0.059883  [ 8896/13920]\n",
      "loss: 0.046383  [ 8960/13920]\n",
      "loss: 0.074741  [ 9024/13920]\n",
      "loss: 0.073570  [ 9088/13920]\n",
      "loss: 0.045414  [ 9152/13920]\n",
      "loss: 0.087793  [ 9216/13920]\n",
      "loss: 0.066545  [ 9280/13920]\n",
      "loss: 0.059877  [ 9344/13920]\n",
      "loss: 0.079319  [ 9408/13920]\n",
      "loss: 0.078974  [ 9472/13920]\n",
      "loss: 0.056416  [ 9536/13920]\n",
      "loss: 0.028706  [ 9600/13920]\n",
      "loss: 0.053380  [ 9664/13920]\n",
      "loss: 0.019530  [ 9728/13920]\n",
      "loss: 0.077741  [ 9792/13920]\n",
      "loss: 0.074867  [ 9856/13920]\n",
      "loss: 0.062719  [ 9920/13920]\n",
      "loss: 0.052834  [ 9984/13920]\n",
      "loss: 0.113361  [10048/13920]\n",
      "loss: 0.080955  [10112/13920]\n",
      "loss: 0.069131  [10176/13920]\n",
      "loss: 0.022454  [10240/13920]\n",
      "loss: 0.029940  [10304/13920]\n",
      "loss: 0.051555  [10368/13920]\n",
      "loss: 0.059779  [10432/13920]\n",
      "loss: 0.101817  [10496/13920]\n",
      "loss: 0.062232  [10560/13920]\n",
      "loss: 0.063515  [10624/13920]\n",
      "loss: 0.038444  [10688/13920]\n",
      "loss: 0.016610  [10752/13920]\n",
      "loss: 0.023172  [10816/13920]\n",
      "loss: 0.151908  [10880/13920]\n",
      "loss: 0.047950  [10944/13920]\n",
      "loss: 0.123714  [11008/13920]\n",
      "loss: 0.063313  [11072/13920]\n",
      "loss: 0.077486  [11136/13920]\n",
      "loss: 0.055805  [11200/13920]\n",
      "loss: 0.070232  [11264/13920]\n",
      "loss: 0.060938  [11328/13920]\n",
      "loss: 0.074225  [11392/13920]\n",
      "loss: 0.126820  [11456/13920]\n",
      "loss: 0.066393  [11520/13920]\n",
      "loss: 0.052186  [11584/13920]\n",
      "loss: 0.055454  [11648/13920]\n",
      "loss: 0.103287  [11712/13920]\n",
      "loss: 0.050041  [11776/13920]\n",
      "loss: 0.054054  [11840/13920]\n",
      "loss: 0.055881  [11904/13920]\n",
      "loss: 0.055216  [11968/13920]\n",
      "loss: 0.109125  [12032/13920]\n",
      "loss: 0.099840  [12096/13920]\n",
      "loss: 0.035468  [12160/13920]\n",
      "loss: 0.019563  [12224/13920]\n",
      "loss: 0.148248  [12288/13920]\n",
      "loss: 0.011509  [12352/13920]\n",
      "loss: 0.089408  [12416/13920]\n",
      "loss: 0.070694  [12480/13920]\n",
      "loss: 0.038559  [12544/13920]\n",
      "loss: 0.029031  [12608/13920]\n",
      "loss: 0.095360  [12672/13920]\n",
      "loss: 0.039646  [12736/13920]\n",
      "loss: 0.023374  [12800/13920]\n",
      "loss: 0.055542  [12864/13920]\n",
      "loss: 0.028595  [12928/13920]\n",
      "loss: 0.018019  [12992/13920]\n",
      "loss: 0.163848  [13056/13920]\n",
      "loss: 0.072904  [13120/13920]\n",
      "loss: 0.122186  [13184/13920]\n",
      "loss: 0.030633  [13248/13920]\n",
      "loss: 0.049498  [13312/13920]\n",
      "loss: 0.022566  [13376/13920]\n",
      "loss: 0.021072  [13440/13920]\n",
      "loss: 0.169189  [13504/13920]\n",
      "loss: 0.044208  [13568/13920]\n",
      "loss: 0.065804  [13632/13920]\n",
      "loss: 0.071587  [13696/13920]\n",
      "loss: 0.077291  [13760/13920]\n",
      "loss: 0.044425  [13824/13920]\n",
      "loss: 0.059125  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 98.0% \n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.092733 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.083407  [    0/13920]\n",
      "loss: 1.091039  [   64/13920]\n",
      "loss: 1.114768  [  128/13920]\n",
      "loss: 1.045431  [  192/13920]\n",
      "loss: 0.978785  [  256/13920]\n",
      "loss: 1.072321  [  320/13920]\n",
      "loss: 1.023381  [  384/13920]\n",
      "loss: 0.784910  [  448/13920]\n",
      "loss: 0.954785  [  512/13920]\n",
      "loss: 0.973096  [  576/13920]\n",
      "loss: 0.972679  [  640/13920]\n",
      "loss: 0.925728  [  704/13920]\n",
      "loss: 0.979025  [  768/13920]\n",
      "loss: 0.851002  [  832/13920]\n",
      "loss: 0.937600  [  896/13920]\n",
      "loss: 0.983176  [  960/13920]\n",
      "loss: 0.898318  [ 1024/13920]\n",
      "loss: 0.985437  [ 1088/13920]\n",
      "loss: 0.797147  [ 1152/13920]\n",
      "loss: 0.811426  [ 1216/13920]\n",
      "loss: 0.887708  [ 1280/13920]\n",
      "loss: 0.985394  [ 1344/13920]\n",
      "loss: 0.981835  [ 1408/13920]\n",
      "loss: 0.796475  [ 1472/13920]\n",
      "loss: 0.932577  [ 1536/13920]\n",
      "loss: 0.808295  [ 1600/13920]\n",
      "loss: 0.941067  [ 1664/13920]\n",
      "loss: 0.937835  [ 1728/13920]\n",
      "loss: 0.882339  [ 1792/13920]\n",
      "loss: 0.816539  [ 1856/13920]\n",
      "loss: 0.902825  [ 1920/13920]\n",
      "loss: 0.844381  [ 1984/13920]\n",
      "loss: 0.842523  [ 2048/13920]\n",
      "loss: 0.891700  [ 2112/13920]\n",
      "loss: 0.948144  [ 2176/13920]\n",
      "loss: 0.870297  [ 2240/13920]\n",
      "loss: 0.835922  [ 2304/13920]\n",
      "loss: 0.770304  [ 2368/13920]\n",
      "loss: 0.846113  [ 2432/13920]\n",
      "loss: 0.877080  [ 2496/13920]\n",
      "loss: 0.852910  [ 2560/13920]\n",
      "loss: 0.835115  [ 2624/13920]\n",
      "loss: 0.775909  [ 2688/13920]\n",
      "loss: 0.899316  [ 2752/13920]\n",
      "loss: 0.784215  [ 2816/13920]\n",
      "loss: 0.730273  [ 2880/13920]\n",
      "loss: 0.780506  [ 2944/13920]\n",
      "loss: 0.815817  [ 3008/13920]\n",
      "loss: 0.912562  [ 3072/13920]\n",
      "loss: 0.731613  [ 3136/13920]\n",
      "loss: 0.728901  [ 3200/13920]\n",
      "loss: 0.754975  [ 3264/13920]\n",
      "loss: 0.724602  [ 3328/13920]\n",
      "loss: 0.734286  [ 3392/13920]\n",
      "loss: 0.846871  [ 3456/13920]\n",
      "loss: 0.727441  [ 3520/13920]\n",
      "loss: 0.708579  [ 3584/13920]\n",
      "loss: 0.773765  [ 3648/13920]\n",
      "loss: 0.850275  [ 3712/13920]\n",
      "loss: 0.804499  [ 3776/13920]\n",
      "loss: 0.691463  [ 3840/13920]\n",
      "loss: 0.769126  [ 3904/13920]\n",
      "loss: 0.759090  [ 3968/13920]\n",
      "loss: 0.828313  [ 4032/13920]\n",
      "loss: 0.956299  [ 4096/13920]\n",
      "loss: 0.708522  [ 4160/13920]\n",
      "loss: 0.797013  [ 4224/13920]\n",
      "loss: 0.617338  [ 4288/13920]\n",
      "loss: 0.811796  [ 4352/13920]\n",
      "loss: 0.740161  [ 4416/13920]\n",
      "loss: 0.749770  [ 4480/13920]\n",
      "loss: 0.830851  [ 4544/13920]\n",
      "loss: 0.804604  [ 4608/13920]\n",
      "loss: 0.782976  [ 4672/13920]\n",
      "loss: 0.645777  [ 4736/13920]\n",
      "loss: 0.679996  [ 4800/13920]\n",
      "loss: 0.732882  [ 4864/13920]\n",
      "loss: 0.739112  [ 4928/13920]\n",
      "loss: 0.648806  [ 4992/13920]\n",
      "loss: 0.797830  [ 5056/13920]\n",
      "loss: 0.739693  [ 5120/13920]\n",
      "loss: 0.763647  [ 5184/13920]\n",
      "loss: 0.714344  [ 5248/13920]\n",
      "loss: 0.704999  [ 5312/13920]\n",
      "loss: 0.789563  [ 5376/13920]\n",
      "loss: 0.693198  [ 5440/13920]\n",
      "loss: 0.718647  [ 5504/13920]\n",
      "loss: 0.814656  [ 5568/13920]\n",
      "loss: 0.775775  [ 5632/13920]\n",
      "loss: 0.760355  [ 5696/13920]\n",
      "loss: 0.800580  [ 5760/13920]\n",
      "loss: 0.686329  [ 5824/13920]\n",
      "loss: 0.655044  [ 5888/13920]\n",
      "loss: 0.739469  [ 5952/13920]\n",
      "loss: 0.797583  [ 6016/13920]\n",
      "loss: 0.741018  [ 6080/13920]\n",
      "loss: 0.839153  [ 6144/13920]\n",
      "loss: 0.725686  [ 6208/13920]\n",
      "loss: 0.726445  [ 6272/13920]\n",
      "loss: 0.684821  [ 6336/13920]\n",
      "loss: 0.730191  [ 6400/13920]\n",
      "loss: 0.729340  [ 6464/13920]\n",
      "loss: 0.706021  [ 6528/13920]\n",
      "loss: 0.674239  [ 6592/13920]\n",
      "loss: 0.819840  [ 6656/13920]\n",
      "loss: 0.647295  [ 6720/13920]\n",
      "loss: 0.663798  [ 6784/13920]\n",
      "loss: 0.647541  [ 6848/13920]\n",
      "loss: 0.808878  [ 6912/13920]\n",
      "loss: 0.681041  [ 6976/13920]\n",
      "loss: 0.592159  [ 7040/13920]\n",
      "loss: 0.666091  [ 7104/13920]\n",
      "loss: 0.712261  [ 7168/13920]\n",
      "loss: 0.728105  [ 7232/13920]\n",
      "loss: 0.653993  [ 7296/13920]\n",
      "loss: 0.727354  [ 7360/13920]\n",
      "loss: 0.614134  [ 7424/13920]\n",
      "loss: 0.630858  [ 7488/13920]\n",
      "loss: 0.710055  [ 7552/13920]\n",
      "loss: 0.716803  [ 7616/13920]\n",
      "loss: 0.632005  [ 7680/13920]\n",
      "loss: 0.591685  [ 7744/13920]\n",
      "loss: 0.709405  [ 7808/13920]\n",
      "loss: 0.691828  [ 7872/13920]\n",
      "loss: 0.567058  [ 7936/13920]\n",
      "loss: 0.729303  [ 8000/13920]\n",
      "loss: 0.556600  [ 8064/13920]\n",
      "loss: 0.760193  [ 8128/13920]\n",
      "loss: 0.661968  [ 8192/13920]\n",
      "loss: 0.658024  [ 8256/13920]\n",
      "loss: 0.600768  [ 8320/13920]\n",
      "loss: 0.663300  [ 8384/13920]\n",
      "loss: 0.545997  [ 8448/13920]\n",
      "loss: 0.690800  [ 8512/13920]\n",
      "loss: 0.767371  [ 8576/13920]\n",
      "loss: 0.637945  [ 8640/13920]\n",
      "loss: 0.727294  [ 8704/13920]\n",
      "loss: 0.606335  [ 8768/13920]\n",
      "loss: 0.684015  [ 8832/13920]\n",
      "loss: 0.621150  [ 8896/13920]\n",
      "loss: 0.656345  [ 8960/13920]\n",
      "loss: 0.598867  [ 9024/13920]\n",
      "loss: 0.677638  [ 9088/13920]\n",
      "loss: 0.671255  [ 9152/13920]\n",
      "loss: 0.527728  [ 9216/13920]\n",
      "loss: 0.566573  [ 9280/13920]\n",
      "loss: 0.672796  [ 9344/13920]\n",
      "loss: 0.699454  [ 9408/13920]\n",
      "loss: 0.720171  [ 9472/13920]\n",
      "loss: 0.597729  [ 9536/13920]\n",
      "loss: 0.638773  [ 9600/13920]\n",
      "loss: 0.737281  [ 9664/13920]\n",
      "loss: 0.735396  [ 9728/13920]\n",
      "loss: 0.609594  [ 9792/13920]\n",
      "loss: 0.600805  [ 9856/13920]\n",
      "loss: 0.534738  [ 9920/13920]\n",
      "loss: 0.639683  [ 9984/13920]\n",
      "loss: 0.662617  [10048/13920]\n",
      "loss: 0.533337  [10112/13920]\n",
      "loss: 0.638868  [10176/13920]\n",
      "loss: 0.535618  [10240/13920]\n",
      "loss: 0.622398  [10304/13920]\n",
      "loss: 0.535896  [10368/13920]\n",
      "loss: 0.778038  [10432/13920]\n",
      "loss: 0.427640  [10496/13920]\n",
      "loss: 0.582560  [10560/13920]\n",
      "loss: 0.679215  [10624/13920]\n",
      "loss: 0.617344  [10688/13920]\n",
      "loss: 0.434074  [10752/13920]\n",
      "loss: 0.572444  [10816/13920]\n",
      "loss: 0.550608  [10880/13920]\n",
      "loss: 0.634636  [10944/13920]\n",
      "loss: 0.622560  [11008/13920]\n",
      "loss: 0.643949  [11072/13920]\n",
      "loss: 0.485301  [11136/13920]\n",
      "loss: 0.525560  [11200/13920]\n",
      "loss: 0.472724  [11264/13920]\n",
      "loss: 0.582605  [11328/13920]\n",
      "loss: 0.704533  [11392/13920]\n",
      "loss: 0.766509  [11456/13920]\n",
      "loss: 0.764445  [11520/13920]\n",
      "loss: 0.673259  [11584/13920]\n",
      "loss: 0.579181  [11648/13920]\n",
      "loss: 0.614385  [11712/13920]\n",
      "loss: 0.552715  [11776/13920]\n",
      "loss: 0.544071  [11840/13920]\n",
      "loss: 0.571460  [11904/13920]\n",
      "loss: 0.492472  [11968/13920]\n",
      "loss: 0.443683  [12032/13920]\n",
      "loss: 0.519680  [12096/13920]\n",
      "loss: 0.689811  [12160/13920]\n",
      "loss: 0.514020  [12224/13920]\n",
      "loss: 0.523281  [12288/13920]\n",
      "loss: 0.606804  [12352/13920]\n",
      "loss: 0.563232  [12416/13920]\n",
      "loss: 0.642219  [12480/13920]\n",
      "loss: 0.511213  [12544/13920]\n",
      "loss: 0.659770  [12608/13920]\n",
      "loss: 0.440548  [12672/13920]\n",
      "loss: 0.516417  [12736/13920]\n",
      "loss: 0.548117  [12800/13920]\n",
      "loss: 0.541334  [12864/13920]\n",
      "loss: 0.493517  [12928/13920]\n",
      "loss: 0.527736  [12992/13920]\n",
      "loss: 0.527023  [13056/13920]\n",
      "loss: 0.582250  [13120/13920]\n",
      "loss: 0.581626  [13184/13920]\n",
      "loss: 0.628121  [13248/13920]\n",
      "loss: 0.523227  [13312/13920]\n",
      "loss: 0.446824  [13376/13920]\n",
      "loss: 0.439746  [13440/13920]\n",
      "loss: 0.507180  [13504/13920]\n",
      "loss: 0.498099  [13568/13920]\n",
      "loss: 0.442302  [13632/13920]\n",
      "loss: 0.512170  [13696/13920]\n",
      "loss: 0.510328  [13760/13920]\n",
      "loss: 0.419964  [13824/13920]\n",
      "loss: 0.655877  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 68.5% \n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.528549 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.571286  [    0/13920]\n",
      "loss: 0.500620  [   64/13920]\n",
      "loss: 0.648303  [  128/13920]\n",
      "loss: 0.429321  [  192/13920]\n",
      "loss: 0.458285  [  256/13920]\n",
      "loss: 0.572276  [  320/13920]\n",
      "loss: 0.523997  [  384/13920]\n",
      "loss: 0.502490  [  448/13920]\n",
      "loss: 0.502270  [  512/13920]\n",
      "loss: 0.357102  [  576/13920]\n",
      "loss: 0.524839  [  640/13920]\n",
      "loss: 0.464144  [  704/13920]\n",
      "loss: 0.446511  [  768/13920]\n",
      "loss: 0.417493  [  832/13920]\n",
      "loss: 0.522644  [  896/13920]\n",
      "loss: 0.479835  [  960/13920]\n",
      "loss: 0.313352  [ 1024/13920]\n",
      "loss: 0.563678  [ 1088/13920]\n",
      "loss: 0.532382  [ 1152/13920]\n",
      "loss: 0.453324  [ 1216/13920]\n",
      "loss: 0.440906  [ 1280/13920]\n",
      "loss: 0.462749  [ 1344/13920]\n",
      "loss: 0.422504  [ 1408/13920]\n",
      "loss: 0.418974  [ 1472/13920]\n",
      "loss: 0.399691  [ 1536/13920]\n",
      "loss: 0.562411  [ 1600/13920]\n",
      "loss: 0.496576  [ 1664/13920]\n",
      "loss: 0.559007  [ 1728/13920]\n",
      "loss: 0.516644  [ 1792/13920]\n",
      "loss: 0.570979  [ 1856/13920]\n",
      "loss: 0.600971  [ 1920/13920]\n",
      "loss: 0.553597  [ 1984/13920]\n",
      "loss: 0.534342  [ 2048/13920]\n",
      "loss: 0.568887  [ 2112/13920]\n",
      "loss: 0.461014  [ 2176/13920]\n",
      "loss: 0.501038  [ 2240/13920]\n",
      "loss: 0.431185  [ 2304/13920]\n",
      "loss: 0.409214  [ 2368/13920]\n",
      "loss: 0.549609  [ 2432/13920]\n",
      "loss: 0.508375  [ 2496/13920]\n",
      "loss: 0.454659  [ 2560/13920]\n",
      "loss: 0.352376  [ 2624/13920]\n",
      "loss: 0.436331  [ 2688/13920]\n",
      "loss: 0.570969  [ 2752/13920]\n",
      "loss: 0.380784  [ 2816/13920]\n",
      "loss: 0.379580  [ 2880/13920]\n",
      "loss: 0.475667  [ 2944/13920]\n",
      "loss: 0.406709  [ 3008/13920]\n",
      "loss: 0.498413  [ 3072/13920]\n",
      "loss: 0.488438  [ 3136/13920]\n",
      "loss: 0.437764  [ 3200/13920]\n",
      "loss: 0.515699  [ 3264/13920]\n",
      "loss: 0.406712  [ 3328/13920]\n",
      "loss: 0.502187  [ 3392/13920]\n",
      "loss: 0.356244  [ 3456/13920]\n",
      "loss: 0.477880  [ 3520/13920]\n",
      "loss: 0.573797  [ 3584/13920]\n",
      "loss: 0.491998  [ 3648/13920]\n",
      "loss: 0.413528  [ 3712/13920]\n",
      "loss: 0.341042  [ 3776/13920]\n",
      "loss: 0.535218  [ 3840/13920]\n",
      "loss: 0.638491  [ 3904/13920]\n",
      "loss: 0.467653  [ 3968/13920]\n",
      "loss: 0.508247  [ 4032/13920]\n",
      "loss: 0.436925  [ 4096/13920]\n",
      "loss: 0.496291  [ 4160/13920]\n",
      "loss: 0.433011  [ 4224/13920]\n",
      "loss: 0.499785  [ 4288/13920]\n",
      "loss: 0.436321  [ 4352/13920]\n",
      "loss: 0.447139  [ 4416/13920]\n",
      "loss: 0.506833  [ 4480/13920]\n",
      "loss: 0.430899  [ 4544/13920]\n",
      "loss: 0.369056  [ 4608/13920]\n",
      "loss: 0.466813  [ 4672/13920]\n",
      "loss: 0.399099  [ 4736/13920]\n",
      "loss: 0.498763  [ 4800/13920]\n",
      "loss: 0.397605  [ 4864/13920]\n",
      "loss: 0.640594  [ 4928/13920]\n",
      "loss: 0.407647  [ 4992/13920]\n",
      "loss: 0.388082  [ 5056/13920]\n",
      "loss: 0.419595  [ 5120/13920]\n",
      "loss: 0.411976  [ 5184/13920]\n",
      "loss: 0.550939  [ 5248/13920]\n",
      "loss: 0.408452  [ 5312/13920]\n",
      "loss: 0.530231  [ 5376/13920]\n",
      "loss: 0.478486  [ 5440/13920]\n",
      "loss: 0.343825  [ 5504/13920]\n",
      "loss: 0.489783  [ 5568/13920]\n",
      "loss: 0.451788  [ 5632/13920]\n",
      "loss: 0.383258  [ 5696/13920]\n",
      "loss: 0.492459  [ 5760/13920]\n",
      "loss: 0.575509  [ 5824/13920]\n",
      "loss: 0.422791  [ 5888/13920]\n",
      "loss: 0.317453  [ 5952/13920]\n",
      "loss: 0.383916  [ 6016/13920]\n",
      "loss: 0.395026  [ 6080/13920]\n",
      "loss: 0.468300  [ 6144/13920]\n",
      "loss: 0.353712  [ 6208/13920]\n",
      "loss: 0.329279  [ 6272/13920]\n",
      "loss: 0.427259  [ 6336/13920]\n",
      "loss: 0.415498  [ 6400/13920]\n",
      "loss: 0.356806  [ 6464/13920]\n",
      "loss: 0.482751  [ 6528/13920]\n",
      "loss: 0.494161  [ 6592/13920]\n",
      "loss: 0.338603  [ 6656/13920]\n",
      "loss: 0.361482  [ 6720/13920]\n",
      "loss: 0.462543  [ 6784/13920]\n",
      "loss: 0.375896  [ 6848/13920]\n",
      "loss: 0.464686  [ 6912/13920]\n",
      "loss: 0.336875  [ 6976/13920]\n",
      "loss: 0.489503  [ 7040/13920]\n",
      "loss: 0.531312  [ 7104/13920]\n",
      "loss: 0.446038  [ 7168/13920]\n",
      "loss: 0.356417  [ 7232/13920]\n",
      "loss: 0.475250  [ 7296/13920]\n",
      "loss: 0.337053  [ 7360/13920]\n",
      "loss: 0.452177  [ 7424/13920]\n",
      "loss: 0.512283  [ 7488/13920]\n",
      "loss: 0.425243  [ 7552/13920]\n",
      "loss: 0.405728  [ 7616/13920]\n",
      "loss: 0.427546  [ 7680/13920]\n",
      "loss: 0.393085  [ 7744/13920]\n",
      "loss: 0.415279  [ 7808/13920]\n",
      "loss: 0.373696  [ 7872/13920]\n",
      "loss: 0.370550  [ 7936/13920]\n",
      "loss: 0.417282  [ 8000/13920]\n",
      "loss: 0.437397  [ 8064/13920]\n",
      "loss: 0.405574  [ 8128/13920]\n",
      "loss: 0.476841  [ 8192/13920]\n",
      "loss: 0.332975  [ 8256/13920]\n",
      "loss: 0.321257  [ 8320/13920]\n",
      "loss: 0.467619  [ 8384/13920]\n",
      "loss: 0.487486  [ 8448/13920]\n",
      "loss: 0.435294  [ 8512/13920]\n",
      "loss: 0.404167  [ 8576/13920]\n",
      "loss: 0.357637  [ 8640/13920]\n",
      "loss: 0.351229  [ 8704/13920]\n",
      "loss: 0.374195  [ 8768/13920]\n",
      "loss: 0.452061  [ 8832/13920]\n",
      "loss: 0.412628  [ 8896/13920]\n",
      "loss: 0.364960  [ 8960/13920]\n",
      "loss: 0.326936  [ 9024/13920]\n",
      "loss: 0.296460  [ 9088/13920]\n",
      "loss: 0.461647  [ 9152/13920]\n",
      "loss: 0.369363  [ 9216/13920]\n",
      "loss: 0.387422  [ 9280/13920]\n",
      "loss: 0.512849  [ 9344/13920]\n",
      "loss: 0.443010  [ 9408/13920]\n",
      "loss: 0.384547  [ 9472/13920]\n",
      "loss: 0.426870  [ 9536/13920]\n",
      "loss: 0.438221  [ 9600/13920]\n",
      "loss: 0.353724  [ 9664/13920]\n",
      "loss: 0.302749  [ 9728/13920]\n",
      "loss: 0.303704  [ 9792/13920]\n",
      "loss: 0.297747  [ 9856/13920]\n",
      "loss: 0.349947  [ 9920/13920]\n",
      "loss: 0.335646  [ 9984/13920]\n",
      "loss: 0.364760  [10048/13920]\n",
      "loss: 0.314983  [10112/13920]\n",
      "loss: 0.327036  [10176/13920]\n",
      "loss: 0.360308  [10240/13920]\n",
      "loss: 0.361717  [10304/13920]\n",
      "loss: 0.351576  [10368/13920]\n",
      "loss: 0.516585  [10432/13920]\n",
      "loss: 0.356094  [10496/13920]\n",
      "loss: 0.428148  [10560/13920]\n",
      "loss: 0.252204  [10624/13920]\n",
      "loss: 0.305097  [10688/13920]\n",
      "loss: 0.393652  [10752/13920]\n",
      "loss: 0.302134  [10816/13920]\n",
      "loss: 0.303527  [10880/13920]\n",
      "loss: 0.409982  [10944/13920]\n",
      "loss: 0.280537  [11008/13920]\n",
      "loss: 0.299320  [11072/13920]\n",
      "loss: 0.350027  [11136/13920]\n",
      "loss: 0.357248  [11200/13920]\n",
      "loss: 0.290400  [11264/13920]\n",
      "loss: 0.300772  [11328/13920]\n",
      "loss: 0.315048  [11392/13920]\n",
      "loss: 0.485197  [11456/13920]\n",
      "loss: 0.329856  [11520/13920]\n",
      "loss: 0.378536  [11584/13920]\n",
      "loss: 0.364935  [11648/13920]\n",
      "loss: 0.386326  [11712/13920]\n",
      "loss: 0.480820  [11776/13920]\n",
      "loss: 0.233486  [11840/13920]\n",
      "loss: 0.392204  [11904/13920]\n",
      "loss: 0.424655  [11968/13920]\n",
      "loss: 0.434329  [12032/13920]\n",
      "loss: 0.356168  [12096/13920]\n",
      "loss: 0.324887  [12160/13920]\n",
      "loss: 0.342099  [12224/13920]\n",
      "loss: 0.344219  [12288/13920]\n",
      "loss: 0.431906  [12352/13920]\n",
      "loss: 0.322752  [12416/13920]\n",
      "loss: 0.389028  [12480/13920]\n",
      "loss: 0.305363  [12544/13920]\n",
      "loss: 0.478304  [12608/13920]\n",
      "loss: 0.288845  [12672/13920]\n",
      "loss: 0.283954  [12736/13920]\n",
      "loss: 0.306606  [12800/13920]\n",
      "loss: 0.342337  [12864/13920]\n",
      "loss: 0.306601  [12928/13920]\n",
      "loss: 0.499854  [12992/13920]\n",
      "loss: 0.309361  [13056/13920]\n",
      "loss: 0.259624  [13120/13920]\n",
      "loss: 0.359498  [13184/13920]\n",
      "loss: 0.485874  [13248/13920]\n",
      "loss: 0.327051  [13312/13920]\n",
      "loss: 0.377791  [13376/13920]\n",
      "loss: 0.491721  [13440/13920]\n",
      "loss: 0.295192  [13504/13920]\n",
      "loss: 0.428336  [13568/13920]\n",
      "loss: 0.290869  [13632/13920]\n",
      "loss: 0.316352  [13696/13920]\n",
      "loss: 0.258620  [13760/13920]\n",
      "loss: 0.413687  [13824/13920]\n",
      "loss: 0.437946  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 84.1% \n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.323952 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.416843  [    0/13920]\n",
      "loss: 0.386825  [   64/13920]\n",
      "loss: 0.296512  [  128/13920]\n",
      "loss: 0.255365  [  192/13920]\n",
      "loss: 0.326840  [  256/13920]\n",
      "loss: 0.309040  [  320/13920]\n",
      "loss: 0.377850  [  384/13920]\n",
      "loss: 0.349329  [  448/13920]\n",
      "loss: 0.319061  [  512/13920]\n",
      "loss: 0.310790  [  576/13920]\n",
      "loss: 0.335101  [  640/13920]\n",
      "loss: 0.319225  [  704/13920]\n",
      "loss: 0.312648  [  768/13920]\n",
      "loss: 0.345769  [  832/13920]\n",
      "loss: 0.335270  [  896/13920]\n",
      "loss: 0.349129  [  960/13920]\n",
      "loss: 0.329258  [ 1024/13920]\n",
      "loss: 0.324269  [ 1088/13920]\n",
      "loss: 0.308102  [ 1152/13920]\n",
      "loss: 0.244073  [ 1216/13920]\n",
      "loss: 0.203786  [ 1280/13920]\n",
      "loss: 0.340908  [ 1344/13920]\n",
      "loss: 0.319211  [ 1408/13920]\n",
      "loss: 0.334200  [ 1472/13920]\n",
      "loss: 0.367055  [ 1536/13920]\n",
      "loss: 0.252798  [ 1600/13920]\n",
      "loss: 0.221678  [ 1664/13920]\n",
      "loss: 0.341538  [ 1728/13920]\n",
      "loss: 0.438195  [ 1792/13920]\n",
      "loss: 0.334632  [ 1856/13920]\n",
      "loss: 0.311294  [ 1920/13920]\n",
      "loss: 0.330697  [ 1984/13920]\n",
      "loss: 0.337680  [ 2048/13920]\n",
      "loss: 0.312579  [ 2112/13920]\n",
      "loss: 0.240871  [ 2176/13920]\n",
      "loss: 0.326728  [ 2240/13920]\n",
      "loss: 0.301740  [ 2304/13920]\n",
      "loss: 0.229751  [ 2368/13920]\n",
      "loss: 0.161798  [ 2432/13920]\n",
      "loss: 0.330379  [ 2496/13920]\n",
      "loss: 0.251026  [ 2560/13920]\n",
      "loss: 0.297251  [ 2624/13920]\n",
      "loss: 0.202539  [ 2688/13920]\n",
      "loss: 0.267505  [ 2752/13920]\n",
      "loss: 0.189657  [ 2816/13920]\n",
      "loss: 0.352845  [ 2880/13920]\n",
      "loss: 0.406977  [ 2944/13920]\n",
      "loss: 0.280358  [ 3008/13920]\n",
      "loss: 0.322181  [ 3072/13920]\n",
      "loss: 0.267299  [ 3136/13920]\n",
      "loss: 0.253408  [ 3200/13920]\n",
      "loss: 0.320668  [ 3264/13920]\n",
      "loss: 0.341052  [ 3328/13920]\n",
      "loss: 0.298616  [ 3392/13920]\n",
      "loss: 0.283565  [ 3456/13920]\n",
      "loss: 0.432343  [ 3520/13920]\n",
      "loss: 0.238954  [ 3584/13920]\n",
      "loss: 0.293179  [ 3648/13920]\n",
      "loss: 0.335328  [ 3712/13920]\n",
      "loss: 0.321722  [ 3776/13920]\n",
      "loss: 0.339685  [ 3840/13920]\n",
      "loss: 0.250820  [ 3904/13920]\n",
      "loss: 0.334430  [ 3968/13920]\n",
      "loss: 0.273149  [ 4032/13920]\n",
      "loss: 0.346108  [ 4096/13920]\n",
      "loss: 0.357003  [ 4160/13920]\n",
      "loss: 0.205386  [ 4224/13920]\n",
      "loss: 0.335174  [ 4288/13920]\n",
      "loss: 0.140957  [ 4352/13920]\n",
      "loss: 0.224608  [ 4416/13920]\n",
      "loss: 0.380657  [ 4480/13920]\n",
      "loss: 0.267255  [ 4544/13920]\n",
      "loss: 0.235006  [ 4608/13920]\n",
      "loss: 0.308449  [ 4672/13920]\n",
      "loss: 0.301151  [ 4736/13920]\n",
      "loss: 0.252150  [ 4800/13920]\n",
      "loss: 0.197003  [ 4864/13920]\n",
      "loss: 0.250424  [ 4928/13920]\n",
      "loss: 0.338480  [ 4992/13920]\n",
      "loss: 0.353683  [ 5056/13920]\n",
      "loss: 0.263371  [ 5120/13920]\n",
      "loss: 0.300072  [ 5184/13920]\n",
      "loss: 0.265565  [ 5248/13920]\n",
      "loss: 0.174788  [ 5312/13920]\n",
      "loss: 0.251487  [ 5376/13920]\n",
      "loss: 0.246051  [ 5440/13920]\n",
      "loss: 0.125683  [ 5504/13920]\n",
      "loss: 0.225885  [ 5568/13920]\n",
      "loss: 0.254252  [ 5632/13920]\n",
      "loss: 0.307759  [ 5696/13920]\n",
      "loss: 0.432109  [ 5760/13920]\n",
      "loss: 0.236884  [ 5824/13920]\n",
      "loss: 0.289854  [ 5888/13920]\n",
      "loss: 0.284298  [ 5952/13920]\n",
      "loss: 0.258570  [ 6016/13920]\n",
      "loss: 0.263334  [ 6080/13920]\n",
      "loss: 0.301663  [ 6144/13920]\n",
      "loss: 0.292483  [ 6208/13920]\n",
      "loss: 0.280137  [ 6272/13920]\n",
      "loss: 0.289144  [ 6336/13920]\n",
      "loss: 0.200536  [ 6400/13920]\n",
      "loss: 0.223790  [ 6464/13920]\n",
      "loss: 0.359922  [ 6528/13920]\n",
      "loss: 0.247075  [ 6592/13920]\n",
      "loss: 0.228673  [ 6656/13920]\n",
      "loss: 0.199213  [ 6720/13920]\n",
      "loss: 0.355501  [ 6784/13920]\n",
      "loss: 0.257553  [ 6848/13920]\n",
      "loss: 0.242564  [ 6912/13920]\n",
      "loss: 0.265085  [ 6976/13920]\n",
      "loss: 0.405422  [ 7040/13920]\n",
      "loss: 0.278939  [ 7104/13920]\n",
      "loss: 0.216264  [ 7168/13920]\n",
      "loss: 0.440234  [ 7232/13920]\n",
      "loss: 0.351574  [ 7296/13920]\n",
      "loss: 0.296246  [ 7360/13920]\n",
      "loss: 0.245719  [ 7424/13920]\n",
      "loss: 0.467685  [ 7488/13920]\n",
      "loss: 0.206735  [ 7552/13920]\n",
      "loss: 0.274880  [ 7616/13920]\n",
      "loss: 0.226778  [ 7680/13920]\n",
      "loss: 0.365075  [ 7744/13920]\n",
      "loss: 0.190101  [ 7808/13920]\n",
      "loss: 0.207949  [ 7872/13920]\n",
      "loss: 0.243345  [ 7936/13920]\n",
      "loss: 0.286552  [ 8000/13920]\n",
      "loss: 0.225507  [ 8064/13920]\n",
      "loss: 0.183937  [ 8128/13920]\n",
      "loss: 0.268925  [ 8192/13920]\n",
      "loss: 0.212427  [ 8256/13920]\n",
      "loss: 0.363202  [ 8320/13920]\n",
      "loss: 0.326316  [ 8384/13920]\n",
      "loss: 0.273508  [ 8448/13920]\n",
      "loss: 0.208221  [ 8512/13920]\n",
      "loss: 0.184551  [ 8576/13920]\n",
      "loss: 0.309303  [ 8640/13920]\n",
      "loss: 0.237017  [ 8704/13920]\n",
      "loss: 0.266800  [ 8768/13920]\n",
      "loss: 0.205149  [ 8832/13920]\n",
      "loss: 0.238635  [ 8896/13920]\n",
      "loss: 0.278246  [ 8960/13920]\n",
      "loss: 0.372412  [ 9024/13920]\n",
      "loss: 0.220640  [ 9088/13920]\n",
      "loss: 0.218765  [ 9152/13920]\n",
      "loss: 0.212401  [ 9216/13920]\n",
      "loss: 0.225801  [ 9280/13920]\n",
      "loss: 0.257713  [ 9344/13920]\n",
      "loss: 0.195619  [ 9408/13920]\n",
      "loss: 0.258125  [ 9472/13920]\n",
      "loss: 0.238586  [ 9536/13920]\n",
      "loss: 0.309515  [ 9600/13920]\n",
      "loss: 0.178723  [ 9664/13920]\n",
      "loss: 0.234552  [ 9728/13920]\n",
      "loss: 0.259580  [ 9792/13920]\n",
      "loss: 0.399205  [ 9856/13920]\n",
      "loss: 0.249419  [ 9920/13920]\n",
      "loss: 0.271915  [ 9984/13920]\n",
      "loss: 0.128201  [10048/13920]\n",
      "loss: 0.251035  [10112/13920]\n",
      "loss: 0.162735  [10176/13920]\n",
      "loss: 0.261359  [10240/13920]\n",
      "loss: 0.289445  [10304/13920]\n",
      "loss: 0.275885  [10368/13920]\n",
      "loss: 0.239148  [10432/13920]\n",
      "loss: 0.198694  [10496/13920]\n",
      "loss: 0.323572  [10560/13920]\n",
      "loss: 0.212082  [10624/13920]\n",
      "loss: 0.292328  [10688/13920]\n",
      "loss: 0.331333  [10752/13920]\n",
      "loss: 0.152591  [10816/13920]\n",
      "loss: 0.252264  [10880/13920]\n",
      "loss: 0.169453  [10944/13920]\n",
      "loss: 0.211759  [11008/13920]\n",
      "loss: 0.189463  [11072/13920]\n",
      "loss: 0.264521  [11136/13920]\n",
      "loss: 0.308847  [11200/13920]\n",
      "loss: 0.470855  [11264/13920]\n",
      "loss: 0.188244  [11328/13920]\n",
      "loss: 0.294802  [11392/13920]\n",
      "loss: 0.217439  [11456/13920]\n",
      "loss: 0.406372  [11520/13920]\n",
      "loss: 0.164140  [11584/13920]\n",
      "loss: 0.229301  [11648/13920]\n",
      "loss: 0.298213  [11712/13920]\n",
      "loss: 0.345229  [11776/13920]\n",
      "loss: 0.302544  [11840/13920]\n",
      "loss: 0.200099  [11904/13920]\n",
      "loss: 0.227429  [11968/13920]\n",
      "loss: 0.278514  [12032/13920]\n",
      "loss: 0.318159  [12096/13920]\n",
      "loss: 0.205626  [12160/13920]\n",
      "loss: 0.180973  [12224/13920]\n",
      "loss: 0.206775  [12288/13920]\n",
      "loss: 0.252892  [12352/13920]\n",
      "loss: 0.243205  [12416/13920]\n",
      "loss: 0.280657  [12480/13920]\n",
      "loss: 0.252448  [12544/13920]\n",
      "loss: 0.225420  [12608/13920]\n",
      "loss: 0.288297  [12672/13920]\n",
      "loss: 0.179434  [12736/13920]\n",
      "loss: 0.338314  [12800/13920]\n",
      "loss: 0.204246  [12864/13920]\n",
      "loss: 0.261699  [12928/13920]\n",
      "loss: 0.289898  [12992/13920]\n",
      "loss: 0.211398  [13056/13920]\n",
      "loss: 0.312434  [13120/13920]\n",
      "loss: 0.377174  [13184/13920]\n",
      "loss: 0.186919  [13248/13920]\n",
      "loss: 0.198036  [13312/13920]\n",
      "loss: 0.178016  [13376/13920]\n",
      "loss: 0.375751  [13440/13920]\n",
      "loss: 0.320643  [13504/13920]\n",
      "loss: 0.202321  [13568/13920]\n",
      "loss: 0.234258  [13632/13920]\n",
      "loss: 0.210831  [13696/13920]\n",
      "loss: 0.170667  [13760/13920]\n",
      "loss: 0.316107  [13824/13920]\n",
      "loss: 0.163403  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 90.2% \n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.250327 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.215842  [    0/13920]\n",
      "loss: 0.235924  [   64/13920]\n",
      "loss: 0.281615  [  128/13920]\n",
      "loss: 0.269307  [  192/13920]\n",
      "loss: 0.171287  [  256/13920]\n",
      "loss: 0.250848  [  320/13920]\n",
      "loss: 0.157396  [  384/13920]\n",
      "loss: 0.193941  [  448/13920]\n",
      "loss: 0.307957  [  512/13920]\n",
      "loss: 0.194916  [  576/13920]\n",
      "loss: 0.188320  [  640/13920]\n",
      "loss: 0.266684  [  704/13920]\n",
      "loss: 0.261003  [  768/13920]\n",
      "loss: 0.270483  [  832/13920]\n",
      "loss: 0.164155  [  896/13920]\n",
      "loss: 0.266712  [  960/13920]\n",
      "loss: 0.249919  [ 1024/13920]\n",
      "loss: 0.162510  [ 1088/13920]\n",
      "loss: 0.170025  [ 1152/13920]\n",
      "loss: 0.300038  [ 1216/13920]\n",
      "loss: 0.224658  [ 1280/13920]\n",
      "loss: 0.197613  [ 1344/13920]\n",
      "loss: 0.212872  [ 1408/13920]\n",
      "loss: 0.313310  [ 1472/13920]\n",
      "loss: 0.146184  [ 1536/13920]\n",
      "loss: 0.266854  [ 1600/13920]\n",
      "loss: 0.219843  [ 1664/13920]\n",
      "loss: 0.187676  [ 1728/13920]\n",
      "loss: 0.170414  [ 1792/13920]\n",
      "loss: 0.191392  [ 1856/13920]\n",
      "loss: 0.332644  [ 1920/13920]\n",
      "loss: 0.222940  [ 1984/13920]\n",
      "loss: 0.193607  [ 2048/13920]\n",
      "loss: 0.157345  [ 2112/13920]\n",
      "loss: 0.201101  [ 2176/13920]\n",
      "loss: 0.162005  [ 2240/13920]\n",
      "loss: 0.296220  [ 2304/13920]\n",
      "loss: 0.151746  [ 2368/13920]\n",
      "loss: 0.286978  [ 2432/13920]\n",
      "loss: 0.122764  [ 2496/13920]\n",
      "loss: 0.153431  [ 2560/13920]\n",
      "loss: 0.229628  [ 2624/13920]\n",
      "loss: 0.158539  [ 2688/13920]\n",
      "loss: 0.357133  [ 2752/13920]\n",
      "loss: 0.253008  [ 2816/13920]\n",
      "loss: 0.226630  [ 2880/13920]\n",
      "loss: 0.206754  [ 2944/13920]\n",
      "loss: 0.275198  [ 3008/13920]\n",
      "loss: 0.157160  [ 3072/13920]\n",
      "loss: 0.155790  [ 3136/13920]\n",
      "loss: 0.131306  [ 3200/13920]\n",
      "loss: 0.225930  [ 3264/13920]\n",
      "loss: 0.212555  [ 3328/13920]\n",
      "loss: 0.127824  [ 3392/13920]\n",
      "loss: 0.262309  [ 3456/13920]\n",
      "loss: 0.354239  [ 3520/13920]\n",
      "loss: 0.218835  [ 3584/13920]\n",
      "loss: 0.227306  [ 3648/13920]\n",
      "loss: 0.129762  [ 3712/13920]\n",
      "loss: 0.228911  [ 3776/13920]\n",
      "loss: 0.163648  [ 3840/13920]\n",
      "loss: 0.121005  [ 3904/13920]\n",
      "loss: 0.187314  [ 3968/13920]\n",
      "loss: 0.168274  [ 4032/13920]\n",
      "loss: 0.208558  [ 4096/13920]\n",
      "loss: 0.280765  [ 4160/13920]\n",
      "loss: 0.381707  [ 4224/13920]\n",
      "loss: 0.330818  [ 4288/13920]\n",
      "loss: 0.142216  [ 4352/13920]\n",
      "loss: 0.202375  [ 4416/13920]\n",
      "loss: 0.298857  [ 4480/13920]\n",
      "loss: 0.213842  [ 4544/13920]\n",
      "loss: 0.283387  [ 4608/13920]\n",
      "loss: 0.089028  [ 4672/13920]\n",
      "loss: 0.253062  [ 4736/13920]\n",
      "loss: 0.150258  [ 4800/13920]\n",
      "loss: 0.184595  [ 4864/13920]\n",
      "loss: 0.092725  [ 4928/13920]\n",
      "loss: 0.211678  [ 4992/13920]\n",
      "loss: 0.195053  [ 5056/13920]\n",
      "loss: 0.257986  [ 5120/13920]\n",
      "loss: 0.264633  [ 5184/13920]\n",
      "loss: 0.131077  [ 5248/13920]\n",
      "loss: 0.227695  [ 5312/13920]\n",
      "loss: 0.298216  [ 5376/13920]\n",
      "loss: 0.204844  [ 5440/13920]\n",
      "loss: 0.212679  [ 5504/13920]\n",
      "loss: 0.209503  [ 5568/13920]\n",
      "loss: 0.143040  [ 5632/13920]\n",
      "loss: 0.178143  [ 5696/13920]\n",
      "loss: 0.131912  [ 5760/13920]\n",
      "loss: 0.186466  [ 5824/13920]\n",
      "loss: 0.119654  [ 5888/13920]\n",
      "loss: 0.171128  [ 5952/13920]\n",
      "loss: 0.378075  [ 6016/13920]\n",
      "loss: 0.141253  [ 6080/13920]\n",
      "loss: 0.197845  [ 6144/13920]\n",
      "loss: 0.125657  [ 6208/13920]\n",
      "loss: 0.225634  [ 6272/13920]\n",
      "loss: 0.136379  [ 6336/13920]\n",
      "loss: 0.191233  [ 6400/13920]\n",
      "loss: 0.247684  [ 6464/13920]\n",
      "loss: 0.253899  [ 6528/13920]\n",
      "loss: 0.264102  [ 6592/13920]\n",
      "loss: 0.268712  [ 6656/13920]\n",
      "loss: 0.134781  [ 6720/13920]\n",
      "loss: 0.185347  [ 6784/13920]\n",
      "loss: 0.515944  [ 6848/13920]\n",
      "loss: 0.224908  [ 6912/13920]\n",
      "loss: 0.131027  [ 6976/13920]\n",
      "loss: 0.238267  [ 7040/13920]\n",
      "loss: 0.203585  [ 7104/13920]\n",
      "loss: 0.240993  [ 7168/13920]\n",
      "loss: 0.159331  [ 7232/13920]\n",
      "loss: 0.193523  [ 7296/13920]\n",
      "loss: 0.291389  [ 7360/13920]\n",
      "loss: 0.296567  [ 7424/13920]\n",
      "loss: 0.098636  [ 7488/13920]\n",
      "loss: 0.181498  [ 7552/13920]\n",
      "loss: 0.205220  [ 7616/13920]\n",
      "loss: 0.106306  [ 7680/13920]\n",
      "loss: 0.235298  [ 7744/13920]\n",
      "loss: 0.162078  [ 7808/13920]\n",
      "loss: 0.133062  [ 7872/13920]\n",
      "loss: 0.147616  [ 7936/13920]\n",
      "loss: 0.188769  [ 8000/13920]\n",
      "loss: 0.176813  [ 8064/13920]\n",
      "loss: 0.239460  [ 8128/13920]\n",
      "loss: 0.203150  [ 8192/13920]\n",
      "loss: 0.228888  [ 8256/13920]\n",
      "loss: 0.222872  [ 8320/13920]\n",
      "loss: 0.198308  [ 8384/13920]\n",
      "loss: 0.306528  [ 8448/13920]\n",
      "loss: 0.185408  [ 8512/13920]\n",
      "loss: 0.206662  [ 8576/13920]\n",
      "loss: 0.075551  [ 8640/13920]\n",
      "loss: 0.206154  [ 8704/13920]\n",
      "loss: 0.146086  [ 8768/13920]\n",
      "loss: 0.196114  [ 8832/13920]\n",
      "loss: 0.359302  [ 8896/13920]\n",
      "loss: 0.170467  [ 8960/13920]\n",
      "loss: 0.280913  [ 9024/13920]\n",
      "loss: 0.137377  [ 9088/13920]\n",
      "loss: 0.115867  [ 9152/13920]\n",
      "loss: 0.218013  [ 9216/13920]\n",
      "loss: 0.129365  [ 9280/13920]\n",
      "loss: 0.189670  [ 9344/13920]\n",
      "loss: 0.198878  [ 9408/13920]\n",
      "loss: 0.121822  [ 9472/13920]\n",
      "loss: 0.111271  [ 9536/13920]\n",
      "loss: 0.147994  [ 9600/13920]\n",
      "loss: 0.098176  [ 9664/13920]\n",
      "loss: 0.174335  [ 9728/13920]\n",
      "loss: 0.250134  [ 9792/13920]\n",
      "loss: 0.147044  [ 9856/13920]\n",
      "loss: 0.196730  [ 9920/13920]\n",
      "loss: 0.214695  [ 9984/13920]\n",
      "loss: 0.221275  [10048/13920]\n",
      "loss: 0.144115  [10112/13920]\n",
      "loss: 0.218199  [10176/13920]\n",
      "loss: 0.216837  [10240/13920]\n",
      "loss: 0.246577  [10304/13920]\n",
      "loss: 0.210350  [10368/13920]\n",
      "loss: 0.134090  [10432/13920]\n",
      "loss: 0.217816  [10496/13920]\n",
      "loss: 0.124592  [10560/13920]\n",
      "loss: 0.172335  [10624/13920]\n",
      "loss: 0.339604  [10688/13920]\n",
      "loss: 0.317132  [10752/13920]\n",
      "loss: 0.197829  [10816/13920]\n",
      "loss: 0.091285  [10880/13920]\n",
      "loss: 0.189262  [10944/13920]\n",
      "loss: 0.187046  [11008/13920]\n",
      "loss: 0.150228  [11072/13920]\n",
      "loss: 0.129033  [11136/13920]\n",
      "loss: 0.154576  [11200/13920]\n",
      "loss: 0.142244  [11264/13920]\n",
      "loss: 0.216378  [11328/13920]\n",
      "loss: 0.120374  [11392/13920]\n",
      "loss: 0.158697  [11456/13920]\n",
      "loss: 0.175125  [11520/13920]\n",
      "loss: 0.155946  [11584/13920]\n",
      "loss: 0.149610  [11648/13920]\n",
      "loss: 0.153696  [11712/13920]\n",
      "loss: 0.165759  [11776/13920]\n",
      "loss: 0.163500  [11840/13920]\n",
      "loss: 0.326145  [11904/13920]\n",
      "loss: 0.171928  [11968/13920]\n",
      "loss: 0.155492  [12032/13920]\n",
      "loss: 0.107124  [12096/13920]\n",
      "loss: 0.070158  [12160/13920]\n",
      "loss: 0.145732  [12224/13920]\n",
      "loss: 0.125872  [12288/13920]\n",
      "loss: 0.122136  [12352/13920]\n",
      "loss: 0.185279  [12416/13920]\n",
      "loss: 0.140678  [12480/13920]\n",
      "loss: 0.234907  [12544/13920]\n",
      "loss: 0.257516  [12608/13920]\n",
      "loss: 0.159408  [12672/13920]\n",
      "loss: 0.325594  [12736/13920]\n",
      "loss: 0.111309  [12800/13920]\n",
      "loss: 0.262905  [12864/13920]\n",
      "loss: 0.160919  [12928/13920]\n",
      "loss: 0.223340  [12992/13920]\n",
      "loss: 0.144994  [13056/13920]\n",
      "loss: 0.223984  [13120/13920]\n",
      "loss: 0.130339  [13184/13920]\n",
      "loss: 0.266099  [13248/13920]\n",
      "loss: 0.219037  [13312/13920]\n",
      "loss: 0.360167  [13376/13920]\n",
      "loss: 0.157131  [13440/13920]\n",
      "loss: 0.328567  [13504/13920]\n",
      "loss: 0.180770  [13568/13920]\n",
      "loss: 0.220836  [13632/13920]\n",
      "loss: 0.211262  [13696/13920]\n",
      "loss: 0.200152  [13760/13920]\n",
      "loss: 0.217832  [13824/13920]\n",
      "loss: 0.156767  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 93.2% \n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.216972 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.171347  [    0/13920]\n",
      "loss: 0.150811  [   64/13920]\n",
      "loss: 0.102421  [  128/13920]\n",
      "loss: 0.172357  [  192/13920]\n",
      "loss: 0.155357  [  256/13920]\n",
      "loss: 0.142159  [  320/13920]\n",
      "loss: 0.168095  [  384/13920]\n",
      "loss: 0.135441  [  448/13920]\n",
      "loss: 0.114498  [  512/13920]\n",
      "loss: 0.132316  [  576/13920]\n",
      "loss: 0.210630  [  640/13920]\n",
      "loss: 0.234654  [  704/13920]\n",
      "loss: 0.111781  [  768/13920]\n",
      "loss: 0.205311  [  832/13920]\n",
      "loss: 0.244962  [  896/13920]\n",
      "loss: 0.164176  [  960/13920]\n",
      "loss: 0.079461  [ 1024/13920]\n",
      "loss: 0.128582  [ 1088/13920]\n",
      "loss: 0.193322  [ 1152/13920]\n",
      "loss: 0.164828  [ 1216/13920]\n",
      "loss: 0.129193  [ 1280/13920]\n",
      "loss: 0.218610  [ 1344/13920]\n",
      "loss: 0.123288  [ 1408/13920]\n",
      "loss: 0.117617  [ 1472/13920]\n",
      "loss: 0.281670  [ 1536/13920]\n",
      "loss: 0.151481  [ 1600/13920]\n",
      "loss: 0.146308  [ 1664/13920]\n",
      "loss: 0.230457  [ 1728/13920]\n",
      "loss: 0.188945  [ 1792/13920]\n",
      "loss: 0.184703  [ 1856/13920]\n",
      "loss: 0.108629  [ 1920/13920]\n",
      "loss: 0.148534  [ 1984/13920]\n",
      "loss: 0.195167  [ 2048/13920]\n",
      "loss: 0.217072  [ 2112/13920]\n",
      "loss: 0.200410  [ 2176/13920]\n",
      "loss: 0.120810  [ 2240/13920]\n",
      "loss: 0.086517  [ 2304/13920]\n",
      "loss: 0.140753  [ 2368/13920]\n",
      "loss: 0.121904  [ 2432/13920]\n",
      "loss: 0.113527  [ 2496/13920]\n",
      "loss: 0.263949  [ 2560/13920]\n",
      "loss: 0.109819  [ 2624/13920]\n",
      "loss: 0.173819  [ 2688/13920]\n",
      "loss: 0.190315  [ 2752/13920]\n",
      "loss: 0.128023  [ 2816/13920]\n",
      "loss: 0.166561  [ 2880/13920]\n",
      "loss: 0.143688  [ 2944/13920]\n",
      "loss: 0.173059  [ 3008/13920]\n",
      "loss: 0.168586  [ 3072/13920]\n",
      "loss: 0.105252  [ 3136/13920]\n",
      "loss: 0.071779  [ 3200/13920]\n",
      "loss: 0.102381  [ 3264/13920]\n",
      "loss: 0.266783  [ 3328/13920]\n",
      "loss: 0.208260  [ 3392/13920]\n",
      "loss: 0.140513  [ 3456/13920]\n",
      "loss: 0.232660  [ 3520/13920]\n",
      "loss: 0.106559  [ 3584/13920]\n",
      "loss: 0.176743  [ 3648/13920]\n",
      "loss: 0.233104  [ 3712/13920]\n",
      "loss: 0.083683  [ 3776/13920]\n",
      "loss: 0.123035  [ 3840/13920]\n",
      "loss: 0.181449  [ 3904/13920]\n",
      "loss: 0.060830  [ 3968/13920]\n",
      "loss: 0.150970  [ 4032/13920]\n",
      "loss: 0.175717  [ 4096/13920]\n",
      "loss: 0.158826  [ 4160/13920]\n",
      "loss: 0.267362  [ 4224/13920]\n",
      "loss: 0.284122  [ 4288/13920]\n",
      "loss: 0.127077  [ 4352/13920]\n",
      "loss: 0.144552  [ 4416/13920]\n",
      "loss: 0.084441  [ 4480/13920]\n",
      "loss: 0.149665  [ 4544/13920]\n",
      "loss: 0.239028  [ 4608/13920]\n",
      "loss: 0.201400  [ 4672/13920]\n",
      "loss: 0.251324  [ 4736/13920]\n",
      "loss: 0.066521  [ 4800/13920]\n",
      "loss: 0.180296  [ 4864/13920]\n",
      "loss: 0.115808  [ 4928/13920]\n",
      "loss: 0.188552  [ 4992/13920]\n",
      "loss: 0.207821  [ 5056/13920]\n",
      "loss: 0.170202  [ 5120/13920]\n",
      "loss: 0.242698  [ 5184/13920]\n",
      "loss: 0.094034  [ 5248/13920]\n",
      "loss: 0.229092  [ 5312/13920]\n",
      "loss: 0.178513  [ 5376/13920]\n",
      "loss: 0.084264  [ 5440/13920]\n",
      "loss: 0.223536  [ 5504/13920]\n",
      "loss: 0.187561  [ 5568/13920]\n",
      "loss: 0.159124  [ 5632/13920]\n",
      "loss: 0.175832  [ 5696/13920]\n",
      "loss: 0.144528  [ 5760/13920]\n",
      "loss: 0.085765  [ 5824/13920]\n",
      "loss: 0.108518  [ 5888/13920]\n",
      "loss: 0.109986  [ 5952/13920]\n",
      "loss: 0.132143  [ 6016/13920]\n",
      "loss: 0.103831  [ 6080/13920]\n",
      "loss: 0.095637  [ 6144/13920]\n",
      "loss: 0.184747  [ 6208/13920]\n",
      "loss: 0.116358  [ 6272/13920]\n",
      "loss: 0.164115  [ 6336/13920]\n",
      "loss: 0.208543  [ 6400/13920]\n",
      "loss: 0.146174  [ 6464/13920]\n",
      "loss: 0.142415  [ 6528/13920]\n",
      "loss: 0.093161  [ 6592/13920]\n",
      "loss: 0.158800  [ 6656/13920]\n",
      "loss: 0.102896  [ 6720/13920]\n",
      "loss: 0.086881  [ 6784/13920]\n",
      "loss: 0.252263  [ 6848/13920]\n",
      "loss: 0.258746  [ 6912/13920]\n",
      "loss: 0.148874  [ 6976/13920]\n",
      "loss: 0.216638  [ 7040/13920]\n",
      "loss: 0.147466  [ 7104/13920]\n",
      "loss: 0.159789  [ 7168/13920]\n",
      "loss: 0.275477  [ 7232/13920]\n",
      "loss: 0.072182  [ 7296/13920]\n",
      "loss: 0.148170  [ 7360/13920]\n",
      "loss: 0.159254  [ 7424/13920]\n",
      "loss: 0.198679  [ 7488/13920]\n",
      "loss: 0.117460  [ 7552/13920]\n",
      "loss: 0.081117  [ 7616/13920]\n",
      "loss: 0.084165  [ 7680/13920]\n",
      "loss: 0.126965  [ 7744/13920]\n",
      "loss: 0.115038  [ 7808/13920]\n",
      "loss: 0.189734  [ 7872/13920]\n",
      "loss: 0.202829  [ 7936/13920]\n",
      "loss: 0.063526  [ 8000/13920]\n",
      "loss: 0.133340  [ 8064/13920]\n",
      "loss: 0.128169  [ 8128/13920]\n",
      "loss: 0.104740  [ 8192/13920]\n",
      "loss: 0.155568  [ 8256/13920]\n",
      "loss: 0.121053  [ 8320/13920]\n",
      "loss: 0.142159  [ 8384/13920]\n",
      "loss: 0.137472  [ 8448/13920]\n",
      "loss: 0.155057  [ 8512/13920]\n",
      "loss: 0.161254  [ 8576/13920]\n",
      "loss: 0.122276  [ 8640/13920]\n",
      "loss: 0.110227  [ 8704/13920]\n",
      "loss: 0.110345  [ 8768/13920]\n",
      "loss: 0.232648  [ 8832/13920]\n",
      "loss: 0.210763  [ 8896/13920]\n",
      "loss: 0.100916  [ 8960/13920]\n",
      "loss: 0.108998  [ 9024/13920]\n",
      "loss: 0.152501  [ 9088/13920]\n",
      "loss: 0.157237  [ 9152/13920]\n",
      "loss: 0.137966  [ 9216/13920]\n",
      "loss: 0.292718  [ 9280/13920]\n",
      "loss: 0.169624  [ 9344/13920]\n",
      "loss: 0.245929  [ 9408/13920]\n",
      "loss: 0.061562  [ 9472/13920]\n",
      "loss: 0.159445  [ 9536/13920]\n",
      "loss: 0.275713  [ 9600/13920]\n",
      "loss: 0.172846  [ 9664/13920]\n",
      "loss: 0.103531  [ 9728/13920]\n",
      "loss: 0.200823  [ 9792/13920]\n",
      "loss: 0.119395  [ 9856/13920]\n",
      "loss: 0.052342  [ 9920/13920]\n",
      "loss: 0.177005  [ 9984/13920]\n",
      "loss: 0.082915  [10048/13920]\n",
      "loss: 0.082915  [10112/13920]\n",
      "loss: 0.157161  [10176/13920]\n",
      "loss: 0.292634  [10240/13920]\n",
      "loss: 0.116674  [10304/13920]\n",
      "loss: 0.210726  [10368/13920]\n",
      "loss: 0.130647  [10432/13920]\n",
      "loss: 0.170993  [10496/13920]\n",
      "loss: 0.064485  [10560/13920]\n",
      "loss: 0.139371  [10624/13920]\n",
      "loss: 0.086828  [10688/13920]\n",
      "loss: 0.119506  [10752/13920]\n",
      "loss: 0.106966  [10816/13920]\n",
      "loss: 0.138060  [10880/13920]\n",
      "loss: 0.243894  [10944/13920]\n",
      "loss: 0.163213  [11008/13920]\n",
      "loss: 0.056908  [11072/13920]\n",
      "loss: 0.133596  [11136/13920]\n",
      "loss: 0.152683  [11200/13920]\n",
      "loss: 0.164095  [11264/13920]\n",
      "loss: 0.158722  [11328/13920]\n",
      "loss: 0.273567  [11392/13920]\n",
      "loss: 0.258956  [11456/13920]\n",
      "loss: 0.143640  [11520/13920]\n",
      "loss: 0.150182  [11584/13920]\n",
      "loss: 0.107094  [11648/13920]\n",
      "loss: 0.109519  [11712/13920]\n",
      "loss: 0.142404  [11776/13920]\n",
      "loss: 0.128192  [11840/13920]\n",
      "loss: 0.107011  [11904/13920]\n",
      "loss: 0.131444  [11968/13920]\n",
      "loss: 0.088087  [12032/13920]\n",
      "loss: 0.115699  [12096/13920]\n",
      "loss: 0.193713  [12160/13920]\n",
      "loss: 0.137409  [12224/13920]\n",
      "loss: 0.165876  [12288/13920]\n",
      "loss: 0.213789  [12352/13920]\n",
      "loss: 0.045846  [12416/13920]\n",
      "loss: 0.160156  [12480/13920]\n",
      "loss: 0.234013  [12544/13920]\n",
      "loss: 0.153464  [12608/13920]\n",
      "loss: 0.251091  [12672/13920]\n",
      "loss: 0.182111  [12736/13920]\n",
      "loss: 0.090753  [12800/13920]\n",
      "loss: 0.133583  [12864/13920]\n",
      "loss: 0.132147  [12928/13920]\n",
      "loss: 0.104882  [12992/13920]\n",
      "loss: 0.200218  [13056/13920]\n",
      "loss: 0.166420  [13120/13920]\n",
      "loss: 0.154181  [13184/13920]\n",
      "loss: 0.137900  [13248/13920]\n",
      "loss: 0.220014  [13312/13920]\n",
      "loss: 0.175032  [13376/13920]\n",
      "loss: 0.158842  [13440/13920]\n",
      "loss: 0.138722  [13504/13920]\n",
      "loss: 0.065322  [13568/13920]\n",
      "loss: 0.180498  [13632/13920]\n",
      "loss: 0.253522  [13696/13920]\n",
      "loss: 0.153666  [13760/13920]\n",
      "loss: 0.111169  [13824/13920]\n",
      "loss: 0.219857  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 94.7% \n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.172353 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.136176  [    0/13920]\n",
      "loss: 0.137352  [   64/13920]\n",
      "loss: 0.097585  [  128/13920]\n",
      "loss: 0.058924  [  192/13920]\n",
      "loss: 0.082037  [  256/13920]\n",
      "loss: 0.104773  [  320/13920]\n",
      "loss: 0.174297  [  384/13920]\n",
      "loss: 0.180752  [  448/13920]\n",
      "loss: 0.078667  [  512/13920]\n",
      "loss: 0.198741  [  576/13920]\n",
      "loss: 0.119200  [  640/13920]\n",
      "loss: 0.098675  [  704/13920]\n",
      "loss: 0.098509  [  768/13920]\n",
      "loss: 0.137869  [  832/13920]\n",
      "loss: 0.078365  [  896/13920]\n",
      "loss: 0.107091  [  960/13920]\n",
      "loss: 0.091041  [ 1024/13920]\n",
      "loss: 0.108109  [ 1088/13920]\n",
      "loss: 0.161986  [ 1152/13920]\n",
      "loss: 0.156159  [ 1216/13920]\n",
      "loss: 0.243259  [ 1280/13920]\n",
      "loss: 0.122739  [ 1344/13920]\n",
      "loss: 0.109780  [ 1408/13920]\n",
      "loss: 0.117366  [ 1472/13920]\n",
      "loss: 0.112625  [ 1536/13920]\n",
      "loss: 0.086487  [ 1600/13920]\n",
      "loss: 0.067410  [ 1664/13920]\n",
      "loss: 0.158691  [ 1728/13920]\n",
      "loss: 0.147858  [ 1792/13920]\n",
      "loss: 0.089023  [ 1856/13920]\n",
      "loss: 0.087179  [ 1920/13920]\n",
      "loss: 0.116820  [ 1984/13920]\n",
      "loss: 0.172977  [ 2048/13920]\n",
      "loss: 0.090703  [ 2112/13920]\n",
      "loss: 0.097808  [ 2176/13920]\n",
      "loss: 0.117036  [ 2240/13920]\n",
      "loss: 0.108701  [ 2304/13920]\n",
      "loss: 0.098000  [ 2368/13920]\n",
      "loss: 0.122984  [ 2432/13920]\n",
      "loss: 0.103839  [ 2496/13920]\n",
      "loss: 0.106857  [ 2560/13920]\n",
      "loss: 0.094658  [ 2624/13920]\n",
      "loss: 0.100449  [ 2688/13920]\n",
      "loss: 0.102201  [ 2752/13920]\n",
      "loss: 0.084602  [ 2816/13920]\n",
      "loss: 0.136257  [ 2880/13920]\n",
      "loss: 0.187174  [ 2944/13920]\n",
      "loss: 0.178179  [ 3008/13920]\n",
      "loss: 0.100840  [ 3072/13920]\n",
      "loss: 0.144285  [ 3136/13920]\n",
      "loss: 0.120303  [ 3200/13920]\n",
      "loss: 0.121746  [ 3264/13920]\n",
      "loss: 0.067421  [ 3328/13920]\n",
      "loss: 0.289250  [ 3392/13920]\n",
      "loss: 0.145246  [ 3456/13920]\n",
      "loss: 0.215438  [ 3520/13920]\n",
      "loss: 0.119951  [ 3584/13920]\n",
      "loss: 0.115217  [ 3648/13920]\n",
      "loss: 0.057732  [ 3712/13920]\n",
      "loss: 0.167546  [ 3776/13920]\n",
      "loss: 0.134227  [ 3840/13920]\n",
      "loss: 0.099975  [ 3904/13920]\n",
      "loss: 0.130559  [ 3968/13920]\n",
      "loss: 0.136026  [ 4032/13920]\n",
      "loss: 0.145958  [ 4096/13920]\n",
      "loss: 0.068087  [ 4160/13920]\n",
      "loss: 0.195293  [ 4224/13920]\n",
      "loss: 0.176688  [ 4288/13920]\n",
      "loss: 0.162294  [ 4352/13920]\n",
      "loss: 0.126091  [ 4416/13920]\n",
      "loss: 0.081055  [ 4480/13920]\n",
      "loss: 0.110091  [ 4544/13920]\n",
      "loss: 0.169312  [ 4608/13920]\n",
      "loss: 0.177731  [ 4672/13920]\n",
      "loss: 0.081769  [ 4736/13920]\n",
      "loss: 0.089711  [ 4800/13920]\n",
      "loss: 0.145829  [ 4864/13920]\n",
      "loss: 0.100703  [ 4928/13920]\n",
      "loss: 0.199350  [ 4992/13920]\n",
      "loss: 0.039621  [ 5056/13920]\n",
      "loss: 0.109682  [ 5120/13920]\n",
      "loss: 0.142503  [ 5184/13920]\n",
      "loss: 0.104297  [ 5248/13920]\n",
      "loss: 0.130979  [ 5312/13920]\n",
      "loss: 0.068677  [ 5376/13920]\n",
      "loss: 0.159138  [ 5440/13920]\n",
      "loss: 0.136186  [ 5504/13920]\n",
      "loss: 0.233488  [ 5568/13920]\n",
      "loss: 0.074534  [ 5632/13920]\n",
      "loss: 0.068354  [ 5696/13920]\n",
      "loss: 0.156848  [ 5760/13920]\n",
      "loss: 0.092228  [ 5824/13920]\n",
      "loss: 0.144832  [ 5888/13920]\n",
      "loss: 0.106939  [ 5952/13920]\n",
      "loss: 0.157949  [ 6016/13920]\n",
      "loss: 0.244960  [ 6080/13920]\n",
      "loss: 0.120202  [ 6144/13920]\n",
      "loss: 0.185052  [ 6208/13920]\n",
      "loss: 0.183047  [ 6272/13920]\n",
      "loss: 0.167101  [ 6336/13920]\n",
      "loss: 0.121722  [ 6400/13920]\n",
      "loss: 0.080190  [ 6464/13920]\n",
      "loss: 0.222784  [ 6528/13920]\n",
      "loss: 0.167503  [ 6592/13920]\n",
      "loss: 0.188421  [ 6656/13920]\n",
      "loss: 0.162913  [ 6720/13920]\n",
      "loss: 0.120343  [ 6784/13920]\n",
      "loss: 0.083167  [ 6848/13920]\n",
      "loss: 0.065178  [ 6912/13920]\n",
      "loss: 0.187369  [ 6976/13920]\n",
      "loss: 0.066689  [ 7040/13920]\n",
      "loss: 0.205935  [ 7104/13920]\n",
      "loss: 0.096881  [ 7168/13920]\n",
      "loss: 0.223065  [ 7232/13920]\n",
      "loss: 0.099425  [ 7296/13920]\n",
      "loss: 0.087602  [ 7360/13920]\n",
      "loss: 0.175851  [ 7424/13920]\n",
      "loss: 0.122828  [ 7488/13920]\n",
      "loss: 0.086993  [ 7552/13920]\n",
      "loss: 0.158275  [ 7616/13920]\n",
      "loss: 0.054758  [ 7680/13920]\n",
      "loss: 0.107735  [ 7744/13920]\n",
      "loss: 0.167300  [ 7808/13920]\n",
      "loss: 0.125338  [ 7872/13920]\n",
      "loss: 0.129050  [ 7936/13920]\n",
      "loss: 0.178795  [ 8000/13920]\n",
      "loss: 0.165223  [ 8064/13920]\n",
      "loss: 0.123406  [ 8128/13920]\n",
      "loss: 0.120483  [ 8192/13920]\n",
      "loss: 0.074444  [ 8256/13920]\n",
      "loss: 0.138262  [ 8320/13920]\n",
      "loss: 0.126264  [ 8384/13920]\n",
      "loss: 0.061755  [ 8448/13920]\n",
      "loss: 0.076256  [ 8512/13920]\n",
      "loss: 0.067542  [ 8576/13920]\n",
      "loss: 0.209611  [ 8640/13920]\n",
      "loss: 0.208735  [ 8704/13920]\n",
      "loss: 0.032321  [ 8768/13920]\n",
      "loss: 0.023538  [ 8832/13920]\n",
      "loss: 0.154127  [ 8896/13920]\n",
      "loss: 0.211730  [ 8960/13920]\n",
      "loss: 0.206098  [ 9024/13920]\n",
      "loss: 0.143449  [ 9088/13920]\n",
      "loss: 0.072312  [ 9152/13920]\n",
      "loss: 0.038372  [ 9216/13920]\n",
      "loss: 0.086044  [ 9280/13920]\n",
      "loss: 0.119654  [ 9344/13920]\n",
      "loss: 0.072840  [ 9408/13920]\n",
      "loss: 0.324586  [ 9472/13920]\n",
      "loss: 0.229048  [ 9536/13920]\n",
      "loss: 0.097757  [ 9600/13920]\n",
      "loss: 0.130985  [ 9664/13920]\n",
      "loss: 0.088389  [ 9728/13920]\n",
      "loss: 0.163145  [ 9792/13920]\n",
      "loss: 0.088344  [ 9856/13920]\n",
      "loss: 0.211047  [ 9920/13920]\n",
      "loss: 0.099739  [ 9984/13920]\n",
      "loss: 0.093254  [10048/13920]\n",
      "loss: 0.187221  [10112/13920]\n",
      "loss: 0.115522  [10176/13920]\n",
      "loss: 0.144354  [10240/13920]\n",
      "loss: 0.075658  [10304/13920]\n",
      "loss: 0.113290  [10368/13920]\n",
      "loss: 0.068336  [10432/13920]\n",
      "loss: 0.123427  [10496/13920]\n",
      "loss: 0.044064  [10560/13920]\n",
      "loss: 0.202012  [10624/13920]\n",
      "loss: 0.208217  [10688/13920]\n",
      "loss: 0.042469  [10752/13920]\n",
      "loss: 0.159971  [10816/13920]\n",
      "loss: 0.114935  [10880/13920]\n",
      "loss: 0.030817  [10944/13920]\n",
      "loss: 0.095329  [11008/13920]\n",
      "loss: 0.202615  [11072/13920]\n",
      "loss: 0.183198  [11136/13920]\n",
      "loss: 0.108595  [11200/13920]\n",
      "loss: 0.160681  [11264/13920]\n",
      "loss: 0.144718  [11328/13920]\n",
      "loss: 0.075690  [11392/13920]\n",
      "loss: 0.062015  [11456/13920]\n",
      "loss: 0.059405  [11520/13920]\n",
      "loss: 0.203648  [11584/13920]\n",
      "loss: 0.148097  [11648/13920]\n",
      "loss: 0.101496  [11712/13920]\n",
      "loss: 0.128350  [11776/13920]\n",
      "loss: 0.208293  [11840/13920]\n",
      "loss: 0.203128  [11904/13920]\n",
      "loss: 0.078984  [11968/13920]\n",
      "loss: 0.206928  [12032/13920]\n",
      "loss: 0.135293  [12096/13920]\n",
      "loss: 0.146076  [12160/13920]\n",
      "loss: 0.057395  [12224/13920]\n",
      "loss: 0.157314  [12288/13920]\n",
      "loss: 0.072072  [12352/13920]\n",
      "loss: 0.079411  [12416/13920]\n",
      "loss: 0.052756  [12480/13920]\n",
      "loss: 0.154943  [12544/13920]\n",
      "loss: 0.157470  [12608/13920]\n",
      "loss: 0.191243  [12672/13920]\n",
      "loss: 0.026975  [12736/13920]\n",
      "loss: 0.212527  [12800/13920]\n",
      "loss: 0.185670  [12864/13920]\n",
      "loss: 0.121019  [12928/13920]\n",
      "loss: 0.111623  [12992/13920]\n",
      "loss: 0.056870  [13056/13920]\n",
      "loss: 0.089764  [13120/13920]\n",
      "loss: 0.051932  [13184/13920]\n",
      "loss: 0.151083  [13248/13920]\n",
      "loss: 0.052728  [13312/13920]\n",
      "loss: 0.091863  [13376/13920]\n",
      "loss: 0.213559  [13440/13920]\n",
      "loss: 0.150276  [13504/13920]\n",
      "loss: 0.088020  [13568/13920]\n",
      "loss: 0.041176  [13632/13920]\n",
      "loss: 0.055582  [13696/13920]\n",
      "loss: 0.139436  [13760/13920]\n",
      "loss: 0.088039  [13824/13920]\n",
      "loss: 0.040814  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.7% \n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.151181 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.151371  [    0/13920]\n",
      "loss: 0.161481  [   64/13920]\n",
      "loss: 0.048433  [  128/13920]\n",
      "loss: 0.150748  [  192/13920]\n",
      "loss: 0.064183  [  256/13920]\n",
      "loss: 0.071828  [  320/13920]\n",
      "loss: 0.079970  [  384/13920]\n",
      "loss: 0.051536  [  448/13920]\n",
      "loss: 0.146934  [  512/13920]\n",
      "loss: 0.086204  [  576/13920]\n",
      "loss: 0.076822  [  640/13920]\n",
      "loss: 0.088832  [  704/13920]\n",
      "loss: 0.087960  [  768/13920]\n",
      "loss: 0.120017  [  832/13920]\n",
      "loss: 0.134889  [  896/13920]\n",
      "loss: 0.082630  [  960/13920]\n",
      "loss: 0.096862  [ 1024/13920]\n",
      "loss: 0.074590  [ 1088/13920]\n",
      "loss: 0.206750  [ 1152/13920]\n",
      "loss: 0.105218  [ 1216/13920]\n",
      "loss: 0.088973  [ 1280/13920]\n",
      "loss: 0.037195  [ 1344/13920]\n",
      "loss: 0.093719  [ 1408/13920]\n",
      "loss: 0.109524  [ 1472/13920]\n",
      "loss: 0.082290  [ 1536/13920]\n",
      "loss: 0.060273  [ 1600/13920]\n",
      "loss: 0.040802  [ 1664/13920]\n",
      "loss: 0.088247  [ 1728/13920]\n",
      "loss: 0.128196  [ 1792/13920]\n",
      "loss: 0.069660  [ 1856/13920]\n",
      "loss: 0.048166  [ 1920/13920]\n",
      "loss: 0.072160  [ 1984/13920]\n",
      "loss: 0.108589  [ 2048/13920]\n",
      "loss: 0.104001  [ 2112/13920]\n",
      "loss: 0.117679  [ 2176/13920]\n",
      "loss: 0.051117  [ 2240/13920]\n",
      "loss: 0.277523  [ 2304/13920]\n",
      "loss: 0.102937  [ 2368/13920]\n",
      "loss: 0.101107  [ 2432/13920]\n",
      "loss: 0.222492  [ 2496/13920]\n",
      "loss: 0.068959  [ 2560/13920]\n",
      "loss: 0.068770  [ 2624/13920]\n",
      "loss: 0.125291  [ 2688/13920]\n",
      "loss: 0.078630  [ 2752/13920]\n",
      "loss: 0.110552  [ 2816/13920]\n",
      "loss: 0.146908  [ 2880/13920]\n",
      "loss: 0.071329  [ 2944/13920]\n",
      "loss: 0.181272  [ 3008/13920]\n",
      "loss: 0.023649  [ 3072/13920]\n",
      "loss: 0.078628  [ 3136/13920]\n",
      "loss: 0.077645  [ 3200/13920]\n",
      "loss: 0.037384  [ 3264/13920]\n",
      "loss: 0.109267  [ 3328/13920]\n",
      "loss: 0.148311  [ 3392/13920]\n",
      "loss: 0.123375  [ 3456/13920]\n",
      "loss: 0.155614  [ 3520/13920]\n",
      "loss: 0.180635  [ 3584/13920]\n",
      "loss: 0.212221  [ 3648/13920]\n",
      "loss: 0.114885  [ 3712/13920]\n",
      "loss: 0.064111  [ 3776/13920]\n",
      "loss: 0.197180  [ 3840/13920]\n",
      "loss: 0.084107  [ 3904/13920]\n",
      "loss: 0.108544  [ 3968/13920]\n",
      "loss: 0.130658  [ 4032/13920]\n",
      "loss: 0.115277  [ 4096/13920]\n",
      "loss: 0.117763  [ 4160/13920]\n",
      "loss: 0.131710  [ 4224/13920]\n",
      "loss: 0.149308  [ 4288/13920]\n",
      "loss: 0.030691  [ 4352/13920]\n",
      "loss: 0.031771  [ 4416/13920]\n",
      "loss: 0.083254  [ 4480/13920]\n",
      "loss: 0.089581  [ 4544/13920]\n",
      "loss: 0.059371  [ 4608/13920]\n",
      "loss: 0.069566  [ 4672/13920]\n",
      "loss: 0.119220  [ 4736/13920]\n",
      "loss: 0.080885  [ 4800/13920]\n",
      "loss: 0.100197  [ 4864/13920]\n",
      "loss: 0.107235  [ 4928/13920]\n",
      "loss: 0.210473  [ 4992/13920]\n",
      "loss: 0.025680  [ 5056/13920]\n",
      "loss: 0.107843  [ 5120/13920]\n",
      "loss: 0.107544  [ 5184/13920]\n",
      "loss: 0.067656  [ 5248/13920]\n",
      "loss: 0.102533  [ 5312/13920]\n",
      "loss: 0.082393  [ 5376/13920]\n",
      "loss: 0.208147  [ 5440/13920]\n",
      "loss: 0.279491  [ 5504/13920]\n",
      "loss: 0.178824  [ 5568/13920]\n",
      "loss: 0.056773  [ 5632/13920]\n",
      "loss: 0.164057  [ 5696/13920]\n",
      "loss: 0.070272  [ 5760/13920]\n",
      "loss: 0.170991  [ 5824/13920]\n",
      "loss: 0.152509  [ 5888/13920]\n",
      "loss: 0.127757  [ 5952/13920]\n",
      "loss: 0.047681  [ 6016/13920]\n",
      "loss: 0.085861  [ 6080/13920]\n",
      "loss: 0.054575  [ 6144/13920]\n",
      "loss: 0.101663  [ 6208/13920]\n",
      "loss: 0.130271  [ 6272/13920]\n",
      "loss: 0.075934  [ 6336/13920]\n",
      "loss: 0.084597  [ 6400/13920]\n",
      "loss: 0.051051  [ 6464/13920]\n",
      "loss: 0.089715  [ 6528/13920]\n",
      "loss: 0.082692  [ 6592/13920]\n",
      "loss: 0.303580  [ 6656/13920]\n",
      "loss: 0.090018  [ 6720/13920]\n",
      "loss: 0.039869  [ 6784/13920]\n",
      "loss: 0.089052  [ 6848/13920]\n",
      "loss: 0.117268  [ 6912/13920]\n",
      "loss: 0.059498  [ 6976/13920]\n",
      "loss: 0.071997  [ 7040/13920]\n",
      "loss: 0.061061  [ 7104/13920]\n",
      "loss: 0.215794  [ 7168/13920]\n",
      "loss: 0.184107  [ 7232/13920]\n",
      "loss: 0.055331  [ 7296/13920]\n",
      "loss: 0.133410  [ 7360/13920]\n",
      "loss: 0.139803  [ 7424/13920]\n",
      "loss: 0.081631  [ 7488/13920]\n",
      "loss: 0.108372  [ 7552/13920]\n",
      "loss: 0.040919  [ 7616/13920]\n",
      "loss: 0.095648  [ 7680/13920]\n",
      "loss: 0.124204  [ 7744/13920]\n",
      "loss: 0.118053  [ 7808/13920]\n",
      "loss: 0.052439  [ 7872/13920]\n",
      "loss: 0.070569  [ 7936/13920]\n",
      "loss: 0.069969  [ 8000/13920]\n",
      "loss: 0.078825  [ 8064/13920]\n",
      "loss: 0.138388  [ 8128/13920]\n",
      "loss: 0.069006  [ 8192/13920]\n",
      "loss: 0.062700  [ 8256/13920]\n",
      "loss: 0.121944  [ 8320/13920]\n",
      "loss: 0.075355  [ 8384/13920]\n",
      "loss: 0.110854  [ 8448/13920]\n",
      "loss: 0.096231  [ 8512/13920]\n",
      "loss: 0.141378  [ 8576/13920]\n",
      "loss: 0.186714  [ 8640/13920]\n",
      "loss: 0.037596  [ 8704/13920]\n",
      "loss: 0.158783  [ 8768/13920]\n",
      "loss: 0.055180  [ 8832/13920]\n",
      "loss: 0.092159  [ 8896/13920]\n",
      "loss: 0.171266  [ 8960/13920]\n",
      "loss: 0.126918  [ 9024/13920]\n",
      "loss: 0.052708  [ 9088/13920]\n",
      "loss: 0.052230  [ 9152/13920]\n",
      "loss: 0.052523  [ 9216/13920]\n",
      "loss: 0.109410  [ 9280/13920]\n",
      "loss: 0.126723  [ 9344/13920]\n",
      "loss: 0.066334  [ 9408/13920]\n",
      "loss: 0.043811  [ 9472/13920]\n",
      "loss: 0.079567  [ 9536/13920]\n",
      "loss: 0.112069  [ 9600/13920]\n",
      "loss: 0.132103  [ 9664/13920]\n",
      "loss: 0.107812  [ 9728/13920]\n",
      "loss: 0.063842  [ 9792/13920]\n",
      "loss: 0.071641  [ 9856/13920]\n",
      "loss: 0.070711  [ 9920/13920]\n",
      "loss: 0.092181  [ 9984/13920]\n",
      "loss: 0.060327  [10048/13920]\n",
      "loss: 0.072373  [10112/13920]\n",
      "loss: 0.146951  [10176/13920]\n",
      "loss: 0.054892  [10240/13920]\n",
      "loss: 0.100687  [10304/13920]\n",
      "loss: 0.046640  [10368/13920]\n",
      "loss: 0.049783  [10432/13920]\n",
      "loss: 0.212727  [10496/13920]\n",
      "loss: 0.063393  [10560/13920]\n",
      "loss: 0.088969  [10624/13920]\n",
      "loss: 0.113225  [10688/13920]\n",
      "loss: 0.056433  [10752/13920]\n",
      "loss: 0.087397  [10816/13920]\n",
      "loss: 0.090108  [10880/13920]\n",
      "loss: 0.113031  [10944/13920]\n",
      "loss: 0.142597  [11008/13920]\n",
      "loss: 0.044661  [11072/13920]\n",
      "loss: 0.040257  [11136/13920]\n",
      "loss: 0.106212  [11200/13920]\n",
      "loss: 0.099016  [11264/13920]\n",
      "loss: 0.037748  [11328/13920]\n",
      "loss: 0.131089  [11392/13920]\n",
      "loss: 0.193486  [11456/13920]\n",
      "loss: 0.035931  [11520/13920]\n",
      "loss: 0.118994  [11584/13920]\n",
      "loss: 0.052203  [11648/13920]\n",
      "loss: 0.097694  [11712/13920]\n",
      "loss: 0.123151  [11776/13920]\n",
      "loss: 0.118572  [11840/13920]\n",
      "loss: 0.102226  [11904/13920]\n",
      "loss: 0.127969  [11968/13920]\n",
      "loss: 0.054789  [12032/13920]\n",
      "loss: 0.052006  [12096/13920]\n",
      "loss: 0.028368  [12160/13920]\n",
      "loss: 0.042620  [12224/13920]\n",
      "loss: 0.059443  [12288/13920]\n",
      "loss: 0.075569  [12352/13920]\n",
      "loss: 0.160218  [12416/13920]\n",
      "loss: 0.096376  [12480/13920]\n",
      "loss: 0.074785  [12544/13920]\n",
      "loss: 0.043823  [12608/13920]\n",
      "loss: 0.194258  [12672/13920]\n",
      "loss: 0.069564  [12736/13920]\n",
      "loss: 0.134271  [12800/13920]\n",
      "loss: 0.069513  [12864/13920]\n",
      "loss: 0.050618  [12928/13920]\n",
      "loss: 0.082168  [12992/13920]\n",
      "loss: 0.141911  [13056/13920]\n",
      "loss: 0.170257  [13120/13920]\n",
      "loss: 0.136305  [13184/13920]\n",
      "loss: 0.088772  [13248/13920]\n",
      "loss: 0.053054  [13312/13920]\n",
      "loss: 0.077218  [13376/13920]\n",
      "loss: 0.056367  [13440/13920]\n",
      "loss: 0.053837  [13504/13920]\n",
      "loss: 0.157664  [13568/13920]\n",
      "loss: 0.140181  [13632/13920]\n",
      "loss: 0.163920  [13696/13920]\n",
      "loss: 0.052973  [13760/13920]\n",
      "loss: 0.135580  [13824/13920]\n",
      "loss: 0.053529  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 96.7% \n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.125608 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.059150  [    0/13920]\n",
      "loss: 0.041218  [   64/13920]\n",
      "loss: 0.100980  [  128/13920]\n",
      "loss: 0.113409  [  192/13920]\n",
      "loss: 0.190749  [  256/13920]\n",
      "loss: 0.133403  [  320/13920]\n",
      "loss: 0.129862  [  384/13920]\n",
      "loss: 0.085114  [  448/13920]\n",
      "loss: 0.076168  [  512/13920]\n",
      "loss: 0.109324  [  576/13920]\n",
      "loss: 0.100220  [  640/13920]\n",
      "loss: 0.055901  [  704/13920]\n",
      "loss: 0.106116  [  768/13920]\n",
      "loss: 0.090675  [  832/13920]\n",
      "loss: 0.038028  [  896/13920]\n",
      "loss: 0.033076  [  960/13920]\n",
      "loss: 0.039376  [ 1024/13920]\n",
      "loss: 0.061035  [ 1088/13920]\n",
      "loss: 0.110410  [ 1152/13920]\n",
      "loss: 0.066549  [ 1216/13920]\n",
      "loss: 0.048426  [ 1280/13920]\n",
      "loss: 0.064317  [ 1344/13920]\n",
      "loss: 0.109943  [ 1408/13920]\n",
      "loss: 0.062033  [ 1472/13920]\n",
      "loss: 0.033580  [ 1536/13920]\n",
      "loss: 0.122459  [ 1600/13920]\n",
      "loss: 0.040319  [ 1664/13920]\n",
      "loss: 0.087024  [ 1728/13920]\n",
      "loss: 0.135336  [ 1792/13920]\n",
      "loss: 0.072587  [ 1856/13920]\n",
      "loss: 0.030579  [ 1920/13920]\n",
      "loss: 0.041994  [ 1984/13920]\n",
      "loss: 0.015975  [ 2048/13920]\n",
      "loss: 0.046442  [ 2112/13920]\n",
      "loss: 0.112950  [ 2176/13920]\n",
      "loss: 0.117549  [ 2240/13920]\n",
      "loss: 0.102144  [ 2304/13920]\n",
      "loss: 0.088317  [ 2368/13920]\n",
      "loss: 0.098612  [ 2432/13920]\n",
      "loss: 0.141974  [ 2496/13920]\n",
      "loss: 0.075132  [ 2560/13920]\n",
      "loss: 0.045175  [ 2624/13920]\n",
      "loss: 0.134185  [ 2688/13920]\n",
      "loss: 0.122476  [ 2752/13920]\n",
      "loss: 0.033191  [ 2816/13920]\n",
      "loss: 0.113601  [ 2880/13920]\n",
      "loss: 0.060587  [ 2944/13920]\n",
      "loss: 0.052571  [ 3008/13920]\n",
      "loss: 0.064119  [ 3072/13920]\n",
      "loss: 0.071740  [ 3136/13920]\n",
      "loss: 0.097233  [ 3200/13920]\n",
      "loss: 0.098997  [ 3264/13920]\n",
      "loss: 0.039259  [ 3328/13920]\n",
      "loss: 0.098198  [ 3392/13920]\n",
      "loss: 0.096795  [ 3456/13920]\n",
      "loss: 0.094281  [ 3520/13920]\n",
      "loss: 0.172023  [ 3584/13920]\n",
      "loss: 0.084683  [ 3648/13920]\n",
      "loss: 0.051657  [ 3712/13920]\n",
      "loss: 0.075601  [ 3776/13920]\n",
      "loss: 0.066812  [ 3840/13920]\n",
      "loss: 0.105165  [ 3904/13920]\n",
      "loss: 0.042075  [ 3968/13920]\n",
      "loss: 0.072208  [ 4032/13920]\n",
      "loss: 0.056376  [ 4096/13920]\n",
      "loss: 0.017915  [ 4160/13920]\n",
      "loss: 0.043118  [ 4224/13920]\n",
      "loss: 0.156491  [ 4288/13920]\n",
      "loss: 0.045648  [ 4352/13920]\n",
      "loss: 0.087409  [ 4416/13920]\n",
      "loss: 0.113884  [ 4480/13920]\n",
      "loss: 0.076048  [ 4544/13920]\n",
      "loss: 0.071629  [ 4608/13920]\n",
      "loss: 0.107204  [ 4672/13920]\n",
      "loss: 0.105610  [ 4736/13920]\n",
      "loss: 0.071878  [ 4800/13920]\n",
      "loss: 0.048701  [ 4864/13920]\n",
      "loss: 0.034509  [ 4928/13920]\n",
      "loss: 0.163830  [ 4992/13920]\n",
      "loss: 0.117559  [ 5056/13920]\n",
      "loss: 0.030407  [ 5120/13920]\n",
      "loss: 0.195342  [ 5184/13920]\n",
      "loss: 0.066377  [ 5248/13920]\n",
      "loss: 0.051630  [ 5312/13920]\n",
      "loss: 0.093120  [ 5376/13920]\n",
      "loss: 0.085230  [ 5440/13920]\n",
      "loss: 0.069552  [ 5504/13920]\n",
      "loss: 0.101853  [ 5568/13920]\n",
      "loss: 0.141332  [ 5632/13920]\n",
      "loss: 0.269577  [ 5696/13920]\n",
      "loss: 0.100374  [ 5760/13920]\n",
      "loss: 0.050420  [ 5824/13920]\n",
      "loss: 0.059470  [ 5888/13920]\n",
      "loss: 0.139201  [ 5952/13920]\n",
      "loss: 0.104820  [ 6016/13920]\n",
      "loss: 0.139686  [ 6080/13920]\n",
      "loss: 0.131309  [ 6144/13920]\n",
      "loss: 0.081505  [ 6208/13920]\n",
      "loss: 0.069605  [ 6272/13920]\n",
      "loss: 0.045145  [ 6336/13920]\n",
      "loss: 0.074308  [ 6400/13920]\n",
      "loss: 0.087439  [ 6464/13920]\n",
      "loss: 0.085274  [ 6528/13920]\n",
      "loss: 0.129637  [ 6592/13920]\n",
      "loss: 0.058751  [ 6656/13920]\n",
      "loss: 0.076873  [ 6720/13920]\n",
      "loss: 0.080040  [ 6784/13920]\n",
      "loss: 0.070473  [ 6848/13920]\n",
      "loss: 0.197687  [ 6912/13920]\n",
      "loss: 0.072014  [ 6976/13920]\n",
      "loss: 0.058668  [ 7040/13920]\n",
      "loss: 0.092585  [ 7104/13920]\n",
      "loss: 0.074476  [ 7168/13920]\n",
      "loss: 0.207034  [ 7232/13920]\n",
      "loss: 0.068582  [ 7296/13920]\n",
      "loss: 0.096816  [ 7360/13920]\n",
      "loss: 0.051540  [ 7424/13920]\n",
      "loss: 0.070135  [ 7488/13920]\n",
      "loss: 0.030939  [ 7552/13920]\n",
      "loss: 0.118009  [ 7616/13920]\n",
      "loss: 0.072172  [ 7680/13920]\n",
      "loss: 0.056118  [ 7744/13920]\n",
      "loss: 0.096463  [ 7808/13920]\n",
      "loss: 0.076598  [ 7872/13920]\n",
      "loss: 0.085911  [ 7936/13920]\n",
      "loss: 0.085062  [ 8000/13920]\n",
      "loss: 0.116344  [ 8064/13920]\n",
      "loss: 0.048515  [ 8128/13920]\n",
      "loss: 0.103346  [ 8192/13920]\n",
      "loss: 0.145533  [ 8256/13920]\n",
      "loss: 0.144193  [ 8320/13920]\n",
      "loss: 0.064991  [ 8384/13920]\n",
      "loss: 0.061687  [ 8448/13920]\n",
      "loss: 0.106869  [ 8512/13920]\n",
      "loss: 0.028389  [ 8576/13920]\n",
      "loss: 0.170577  [ 8640/13920]\n",
      "loss: 0.079622  [ 8704/13920]\n",
      "loss: 0.155131  [ 8768/13920]\n",
      "loss: 0.049637  [ 8832/13920]\n",
      "loss: 0.138214  [ 8896/13920]\n",
      "loss: 0.096931  [ 8960/13920]\n",
      "loss: 0.026253  [ 9024/13920]\n",
      "loss: 0.031911  [ 9088/13920]\n",
      "loss: 0.233021  [ 9152/13920]\n",
      "loss: 0.053175  [ 9216/13920]\n",
      "loss: 0.058597  [ 9280/13920]\n",
      "loss: 0.050651  [ 9344/13920]\n",
      "loss: 0.045656  [ 9408/13920]\n",
      "loss: 0.193256  [ 9472/13920]\n",
      "loss: 0.136611  [ 9536/13920]\n",
      "loss: 0.156026  [ 9600/13920]\n",
      "loss: 0.043620  [ 9664/13920]\n",
      "loss: 0.031820  [ 9728/13920]\n",
      "loss: 0.019993  [ 9792/13920]\n",
      "loss: 0.120608  [ 9856/13920]\n",
      "loss: 0.049484  [ 9920/13920]\n",
      "loss: 0.095994  [ 9984/13920]\n",
      "loss: 0.112000  [10048/13920]\n",
      "loss: 0.131258  [10112/13920]\n",
      "loss: 0.058504  [10176/13920]\n",
      "loss: 0.065170  [10240/13920]\n",
      "loss: 0.088220  [10304/13920]\n",
      "loss: 0.130171  [10368/13920]\n",
      "loss: 0.053690  [10432/13920]\n",
      "loss: 0.072780  [10496/13920]\n",
      "loss: 0.049832  [10560/13920]\n",
      "loss: 0.074821  [10624/13920]\n",
      "loss: 0.074179  [10688/13920]\n",
      "loss: 0.066979  [10752/13920]\n",
      "loss: 0.058514  [10816/13920]\n",
      "loss: 0.091860  [10880/13920]\n",
      "loss: 0.084449  [10944/13920]\n",
      "loss: 0.101587  [11008/13920]\n",
      "loss: 0.032270  [11072/13920]\n",
      "loss: 0.167435  [11136/13920]\n",
      "loss: 0.057842  [11200/13920]\n",
      "loss: 0.070297  [11264/13920]\n",
      "loss: 0.028678  [11328/13920]\n",
      "loss: 0.076037  [11392/13920]\n",
      "loss: 0.058970  [11456/13920]\n",
      "loss: 0.078760  [11520/13920]\n",
      "loss: 0.029848  [11584/13920]\n",
      "loss: 0.079010  [11648/13920]\n",
      "loss: 0.126663  [11712/13920]\n",
      "loss: 0.109356  [11776/13920]\n",
      "loss: 0.055191  [11840/13920]\n",
      "loss: 0.055799  [11904/13920]\n",
      "loss: 0.049368  [11968/13920]\n",
      "loss: 0.302829  [12032/13920]\n",
      "loss: 0.057643  [12096/13920]\n",
      "loss: 0.036223  [12160/13920]\n",
      "loss: 0.049358  [12224/13920]\n",
      "loss: 0.113823  [12288/13920]\n",
      "loss: 0.057798  [12352/13920]\n",
      "loss: 0.122915  [12416/13920]\n",
      "loss: 0.034223  [12480/13920]\n",
      "loss: 0.036017  [12544/13920]\n",
      "loss: 0.083036  [12608/13920]\n",
      "loss: 0.118978  [12672/13920]\n",
      "loss: 0.063389  [12736/13920]\n",
      "loss: 0.056435  [12800/13920]\n",
      "loss: 0.058665  [12864/13920]\n",
      "loss: 0.075780  [12928/13920]\n",
      "loss: 0.069264  [12992/13920]\n",
      "loss: 0.092015  [13056/13920]\n",
      "loss: 0.076893  [13120/13920]\n",
      "loss: 0.075274  [13184/13920]\n",
      "loss: 0.051418  [13248/13920]\n",
      "loss: 0.115370  [13312/13920]\n",
      "loss: 0.084858  [13376/13920]\n",
      "loss: 0.095948  [13440/13920]\n",
      "loss: 0.032063  [13504/13920]\n",
      "loss: 0.047349  [13568/13920]\n",
      "loss: 0.060497  [13632/13920]\n",
      "loss: 0.067685  [13696/13920]\n",
      "loss: 0.111629  [13760/13920]\n",
      "loss: 0.106065  [13824/13920]\n",
      "loss: 0.045682  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.2% \n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.110729 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.033421  [    0/13920]\n",
      "loss: 0.038255  [   64/13920]\n",
      "loss: 0.061353  [  128/13920]\n",
      "loss: 0.086687  [  192/13920]\n",
      "loss: 0.092898  [  256/13920]\n",
      "loss: 0.048768  [  320/13920]\n",
      "loss: 0.055265  [  384/13920]\n",
      "loss: 0.060345  [  448/13920]\n",
      "loss: 0.150788  [  512/13920]\n",
      "loss: 0.055829  [  576/13920]\n",
      "loss: 0.174528  [  640/13920]\n",
      "loss: 0.096285  [  704/13920]\n",
      "loss: 0.060395  [  768/13920]\n",
      "loss: 0.032496  [  832/13920]\n",
      "loss: 0.044252  [  896/13920]\n",
      "loss: 0.080541  [  960/13920]\n",
      "loss: 0.026717  [ 1024/13920]\n",
      "loss: 0.036012  [ 1088/13920]\n",
      "loss: 0.114150  [ 1152/13920]\n",
      "loss: 0.028610  [ 1216/13920]\n",
      "loss: 0.061028  [ 1280/13920]\n",
      "loss: 0.021377  [ 1344/13920]\n",
      "loss: 0.049909  [ 1408/13920]\n",
      "loss: 0.130447  [ 1472/13920]\n",
      "loss: 0.013681  [ 1536/13920]\n",
      "loss: 0.036842  [ 1600/13920]\n",
      "loss: 0.031798  [ 1664/13920]\n",
      "loss: 0.050489  [ 1728/13920]\n",
      "loss: 0.080826  [ 1792/13920]\n",
      "loss: 0.036789  [ 1856/13920]\n",
      "loss: 0.099574  [ 1920/13920]\n",
      "loss: 0.081953  [ 1984/13920]\n",
      "loss: 0.035190  [ 2048/13920]\n",
      "loss: 0.078548  [ 2112/13920]\n",
      "loss: 0.025354  [ 2176/13920]\n",
      "loss: 0.013350  [ 2240/13920]\n",
      "loss: 0.045984  [ 2304/13920]\n",
      "loss: 0.032945  [ 2368/13920]\n",
      "loss: 0.022067  [ 2432/13920]\n",
      "loss: 0.082348  [ 2496/13920]\n",
      "loss: 0.059749  [ 2560/13920]\n",
      "loss: 0.096741  [ 2624/13920]\n",
      "loss: 0.065277  [ 2688/13920]\n",
      "loss: 0.127972  [ 2752/13920]\n",
      "loss: 0.042807  [ 2816/13920]\n",
      "loss: 0.067326  [ 2880/13920]\n",
      "loss: 0.089120  [ 2944/13920]\n",
      "loss: 0.056100  [ 3008/13920]\n",
      "loss: 0.049188  [ 3072/13920]\n",
      "loss: 0.078302  [ 3136/13920]\n",
      "loss: 0.088522  [ 3200/13920]\n",
      "loss: 0.032901  [ 3264/13920]\n",
      "loss: 0.140905  [ 3328/13920]\n",
      "loss: 0.045834  [ 3392/13920]\n",
      "loss: 0.048650  [ 3456/13920]\n",
      "loss: 0.046457  [ 3520/13920]\n",
      "loss: 0.069776  [ 3584/13920]\n",
      "loss: 0.040498  [ 3648/13920]\n",
      "loss: 0.132653  [ 3712/13920]\n",
      "loss: 0.122865  [ 3776/13920]\n",
      "loss: 0.052535  [ 3840/13920]\n",
      "loss: 0.132752  [ 3904/13920]\n",
      "loss: 0.037369  [ 3968/13920]\n",
      "loss: 0.111157  [ 4032/13920]\n",
      "loss: 0.144478  [ 4096/13920]\n",
      "loss: 0.092320  [ 4160/13920]\n",
      "loss: 0.049063  [ 4224/13920]\n",
      "loss: 0.056503  [ 4288/13920]\n",
      "loss: 0.041471  [ 4352/13920]\n",
      "loss: 0.114039  [ 4416/13920]\n",
      "loss: 0.098790  [ 4480/13920]\n",
      "loss: 0.068531  [ 4544/13920]\n",
      "loss: 0.037127  [ 4608/13920]\n",
      "loss: 0.155201  [ 4672/13920]\n",
      "loss: 0.031443  [ 4736/13920]\n",
      "loss: 0.037556  [ 4800/13920]\n",
      "loss: 0.025218  [ 4864/13920]\n",
      "loss: 0.087408  [ 4928/13920]\n",
      "loss: 0.099089  [ 4992/13920]\n",
      "loss: 0.098852  [ 5056/13920]\n",
      "loss: 0.044388  [ 5120/13920]\n",
      "loss: 0.085138  [ 5184/13920]\n",
      "loss: 0.089045  [ 5248/13920]\n",
      "loss: 0.066276  [ 5312/13920]\n",
      "loss: 0.116561  [ 5376/13920]\n",
      "loss: 0.067217  [ 5440/13920]\n",
      "loss: 0.112778  [ 5504/13920]\n",
      "loss: 0.083167  [ 5568/13920]\n",
      "loss: 0.113448  [ 5632/13920]\n",
      "loss: 0.101785  [ 5696/13920]\n",
      "loss: 0.040343  [ 5760/13920]\n",
      "loss: 0.078433  [ 5824/13920]\n",
      "loss: 0.073483  [ 5888/13920]\n",
      "loss: 0.088856  [ 5952/13920]\n",
      "loss: 0.036315  [ 6016/13920]\n",
      "loss: 0.053582  [ 6080/13920]\n",
      "loss: 0.067926  [ 6144/13920]\n",
      "loss: 0.078481  [ 6208/13920]\n",
      "loss: 0.080493  [ 6272/13920]\n",
      "loss: 0.040405  [ 6336/13920]\n",
      "loss: 0.136010  [ 6400/13920]\n",
      "loss: 0.061220  [ 6464/13920]\n",
      "loss: 0.042022  [ 6528/13920]\n",
      "loss: 0.107730  [ 6592/13920]\n",
      "loss: 0.043025  [ 6656/13920]\n",
      "loss: 0.105393  [ 6720/13920]\n",
      "loss: 0.046217  [ 6784/13920]\n",
      "loss: 0.041475  [ 6848/13920]\n",
      "loss: 0.054506  [ 6912/13920]\n",
      "loss: 0.039831  [ 6976/13920]\n",
      "loss: 0.111358  [ 7040/13920]\n",
      "loss: 0.169822  [ 7104/13920]\n",
      "loss: 0.053563  [ 7168/13920]\n",
      "loss: 0.065090  [ 7232/13920]\n",
      "loss: 0.093200  [ 7296/13920]\n",
      "loss: 0.043441  [ 7360/13920]\n",
      "loss: 0.053482  [ 7424/13920]\n",
      "loss: 0.093804  [ 7488/13920]\n",
      "loss: 0.086092  [ 7552/13920]\n",
      "loss: 0.030752  [ 7616/13920]\n",
      "loss: 0.076048  [ 7680/13920]\n",
      "loss: 0.096010  [ 7744/13920]\n",
      "loss: 0.039345  [ 7808/13920]\n",
      "loss: 0.037480  [ 7872/13920]\n",
      "loss: 0.024655  [ 7936/13920]\n",
      "loss: 0.053857  [ 8000/13920]\n",
      "loss: 0.030515  [ 8064/13920]\n",
      "loss: 0.073851  [ 8128/13920]\n",
      "loss: 0.094493  [ 8192/13920]\n",
      "loss: 0.081921  [ 8256/13920]\n",
      "loss: 0.160420  [ 8320/13920]\n",
      "loss: 0.051552  [ 8384/13920]\n",
      "loss: 0.057984  [ 8448/13920]\n",
      "loss: 0.021570  [ 8512/13920]\n",
      "loss: 0.222046  [ 8576/13920]\n",
      "loss: 0.023138  [ 8640/13920]\n",
      "loss: 0.072614  [ 8704/13920]\n",
      "loss: 0.071299  [ 8768/13920]\n",
      "loss: 0.090190  [ 8832/13920]\n",
      "loss: 0.095665  [ 8896/13920]\n",
      "loss: 0.047836  [ 8960/13920]\n",
      "loss: 0.032607  [ 9024/13920]\n",
      "loss: 0.106832  [ 9088/13920]\n",
      "loss: 0.039952  [ 9152/13920]\n",
      "loss: 0.036591  [ 9216/13920]\n",
      "loss: 0.049588  [ 9280/13920]\n",
      "loss: 0.055637  [ 9344/13920]\n",
      "loss: 0.052808  [ 9408/13920]\n",
      "loss: 0.058298  [ 9472/13920]\n",
      "loss: 0.059636  [ 9536/13920]\n",
      "loss: 0.072823  [ 9600/13920]\n",
      "loss: 0.076277  [ 9664/13920]\n",
      "loss: 0.037905  [ 9728/13920]\n",
      "loss: 0.084874  [ 9792/13920]\n",
      "loss: 0.074065  [ 9856/13920]\n",
      "loss: 0.109866  [ 9920/13920]\n",
      "loss: 0.074335  [ 9984/13920]\n",
      "loss: 0.072239  [10048/13920]\n",
      "loss: 0.097649  [10112/13920]\n",
      "loss: 0.152707  [10176/13920]\n",
      "loss: 0.091007  [10240/13920]\n",
      "loss: 0.124224  [10304/13920]\n",
      "loss: 0.078704  [10368/13920]\n",
      "loss: 0.052657  [10432/13920]\n",
      "loss: 0.042603  [10496/13920]\n",
      "loss: 0.034714  [10560/13920]\n",
      "loss: 0.023614  [10624/13920]\n",
      "loss: 0.044920  [10688/13920]\n",
      "loss: 0.109434  [10752/13920]\n",
      "loss: 0.105354  [10816/13920]\n",
      "loss: 0.035143  [10880/13920]\n",
      "loss: 0.068684  [10944/13920]\n",
      "loss: 0.052471  [11008/13920]\n",
      "loss: 0.067961  [11072/13920]\n",
      "loss: 0.046582  [11136/13920]\n",
      "loss: 0.073953  [11200/13920]\n",
      "loss: 0.066685  [11264/13920]\n",
      "loss: 0.096066  [11328/13920]\n",
      "loss: 0.039439  [11392/13920]\n",
      "loss: 0.069185  [11456/13920]\n",
      "loss: 0.051823  [11520/13920]\n",
      "loss: 0.090208  [11584/13920]\n",
      "loss: 0.071109  [11648/13920]\n",
      "loss: 0.040775  [11712/13920]\n",
      "loss: 0.083337  [11776/13920]\n",
      "loss: 0.054037  [11840/13920]\n",
      "loss: 0.061283  [11904/13920]\n",
      "loss: 0.026880  [11968/13920]\n",
      "loss: 0.101320  [12032/13920]\n",
      "loss: 0.100576  [12096/13920]\n",
      "loss: 0.118562  [12160/13920]\n",
      "loss: 0.062414  [12224/13920]\n",
      "loss: 0.099832  [12288/13920]\n",
      "loss: 0.066485  [12352/13920]\n",
      "loss: 0.194575  [12416/13920]\n",
      "loss: 0.065187  [12480/13920]\n",
      "loss: 0.053367  [12544/13920]\n",
      "loss: 0.129745  [12608/13920]\n",
      "loss: 0.023555  [12672/13920]\n",
      "loss: 0.066483  [12736/13920]\n",
      "loss: 0.057213  [12800/13920]\n",
      "loss: 0.032324  [12864/13920]\n",
      "loss: 0.054862  [12928/13920]\n",
      "loss: 0.104521  [12992/13920]\n",
      "loss: 0.114269  [13056/13920]\n",
      "loss: 0.090257  [13120/13920]\n",
      "loss: 0.039217  [13184/13920]\n",
      "loss: 0.038863  [13248/13920]\n",
      "loss: 0.079361  [13312/13920]\n",
      "loss: 0.067186  [13376/13920]\n",
      "loss: 0.081129  [13440/13920]\n",
      "loss: 0.191548  [13504/13920]\n",
      "loss: 0.087873  [13568/13920]\n",
      "loss: 0.102117  [13632/13920]\n",
      "loss: 0.017747  [13696/13920]\n",
      "loss: 0.019003  [13760/13920]\n",
      "loss: 0.137592  [13824/13920]\n",
      "loss: 0.053944  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.7% \n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.118251 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.043678  [    0/13920]\n",
      "loss: 0.076064  [   64/13920]\n",
      "loss: 0.039600  [  128/13920]\n",
      "loss: 0.036775  [  192/13920]\n",
      "loss: 0.051955  [  256/13920]\n",
      "loss: 0.028625  [  320/13920]\n",
      "loss: 0.031640  [  384/13920]\n",
      "loss: 0.065746  [  448/13920]\n",
      "loss: 0.039834  [  512/13920]\n",
      "loss: 0.046838  [  576/13920]\n",
      "loss: 0.059723  [  640/13920]\n",
      "loss: 0.110567  [  704/13920]\n",
      "loss: 0.035605  [  768/13920]\n",
      "loss: 0.059294  [  832/13920]\n",
      "loss: 0.067622  [  896/13920]\n",
      "loss: 0.074287  [  960/13920]\n",
      "loss: 0.131492  [ 1024/13920]\n",
      "loss: 0.033810  [ 1088/13920]\n",
      "loss: 0.141443  [ 1152/13920]\n",
      "loss: 0.029847  [ 1216/13920]\n",
      "loss: 0.033980  [ 1280/13920]\n",
      "loss: 0.054114  [ 1344/13920]\n",
      "loss: 0.054313  [ 1408/13920]\n",
      "loss: 0.057317  [ 1472/13920]\n",
      "loss: 0.045540  [ 1536/13920]\n",
      "loss: 0.106175  [ 1600/13920]\n",
      "loss: 0.043387  [ 1664/13920]\n",
      "loss: 0.051980  [ 1728/13920]\n",
      "loss: 0.013520  [ 1792/13920]\n",
      "loss: 0.019296  [ 1856/13920]\n",
      "loss: 0.025855  [ 1920/13920]\n",
      "loss: 0.061071  [ 1984/13920]\n",
      "loss: 0.035012  [ 2048/13920]\n",
      "loss: 0.038098  [ 2112/13920]\n",
      "loss: 0.056858  [ 2176/13920]\n",
      "loss: 0.022534  [ 2240/13920]\n",
      "loss: 0.051473  [ 2304/13920]\n",
      "loss: 0.082893  [ 2368/13920]\n",
      "loss: 0.017296  [ 2432/13920]\n",
      "loss: 0.051762  [ 2496/13920]\n",
      "loss: 0.034336  [ 2560/13920]\n",
      "loss: 0.092504  [ 2624/13920]\n",
      "loss: 0.045656  [ 2688/13920]\n",
      "loss: 0.061903  [ 2752/13920]\n",
      "loss: 0.126741  [ 2816/13920]\n",
      "loss: 0.058076  [ 2880/13920]\n",
      "loss: 0.034226  [ 2944/13920]\n",
      "loss: 0.036562  [ 3008/13920]\n",
      "loss: 0.078511  [ 3072/13920]\n",
      "loss: 0.046642  [ 3136/13920]\n",
      "loss: 0.145680  [ 3200/13920]\n",
      "loss: 0.096107  [ 3264/13920]\n",
      "loss: 0.036985  [ 3328/13920]\n",
      "loss: 0.058846  [ 3392/13920]\n",
      "loss: 0.019964  [ 3456/13920]\n",
      "loss: 0.050818  [ 3520/13920]\n",
      "loss: 0.071781  [ 3584/13920]\n",
      "loss: 0.063913  [ 3648/13920]\n",
      "loss: 0.042758  [ 3712/13920]\n",
      "loss: 0.207637  [ 3776/13920]\n",
      "loss: 0.018895  [ 3840/13920]\n",
      "loss: 0.066039  [ 3904/13920]\n",
      "loss: 0.061918  [ 3968/13920]\n",
      "loss: 0.102950  [ 4032/13920]\n",
      "loss: 0.149478  [ 4096/13920]\n",
      "loss: 0.064027  [ 4160/13920]\n",
      "loss: 0.084326  [ 4224/13920]\n",
      "loss: 0.106561  [ 4288/13920]\n",
      "loss: 0.064349  [ 4352/13920]\n",
      "loss: 0.050270  [ 4416/13920]\n",
      "loss: 0.085231  [ 4480/13920]\n",
      "loss: 0.085937  [ 4544/13920]\n",
      "loss: 0.074817  [ 4608/13920]\n",
      "loss: 0.027879  [ 4672/13920]\n",
      "loss: 0.082448  [ 4736/13920]\n",
      "loss: 0.035736  [ 4800/13920]\n",
      "loss: 0.017855  [ 4864/13920]\n",
      "loss: 0.088812  [ 4928/13920]\n",
      "loss: 0.057777  [ 4992/13920]\n",
      "loss: 0.092028  [ 5056/13920]\n",
      "loss: 0.053007  [ 5120/13920]\n",
      "loss: 0.095719  [ 5184/13920]\n",
      "loss: 0.034598  [ 5248/13920]\n",
      "loss: 0.144197  [ 5312/13920]\n",
      "loss: 0.037970  [ 5376/13920]\n",
      "loss: 0.044793  [ 5440/13920]\n",
      "loss: 0.029768  [ 5504/13920]\n",
      "loss: 0.066950  [ 5568/13920]\n",
      "loss: 0.090552  [ 5632/13920]\n",
      "loss: 0.072328  [ 5696/13920]\n",
      "loss: 0.045133  [ 5760/13920]\n",
      "loss: 0.096249  [ 5824/13920]\n",
      "loss: 0.040697  [ 5888/13920]\n",
      "loss: 0.040895  [ 5952/13920]\n",
      "loss: 0.025866  [ 6016/13920]\n",
      "loss: 0.073933  [ 6080/13920]\n",
      "loss: 0.064696  [ 6144/13920]\n",
      "loss: 0.033106  [ 6208/13920]\n",
      "loss: 0.029241  [ 6272/13920]\n",
      "loss: 0.060136  [ 6336/13920]\n",
      "loss: 0.031894  [ 6400/13920]\n",
      "loss: 0.087054  [ 6464/13920]\n",
      "loss: 0.055624  [ 6528/13920]\n",
      "loss: 0.020630  [ 6592/13920]\n",
      "loss: 0.077447  [ 6656/13920]\n",
      "loss: 0.074451  [ 6720/13920]\n",
      "loss: 0.111186  [ 6784/13920]\n",
      "loss: 0.033502  [ 6848/13920]\n",
      "loss: 0.045214  [ 6912/13920]\n",
      "loss: 0.032297  [ 6976/13920]\n",
      "loss: 0.072173  [ 7040/13920]\n",
      "loss: 0.051872  [ 7104/13920]\n",
      "loss: 0.021906  [ 7168/13920]\n",
      "loss: 0.059210  [ 7232/13920]\n",
      "loss: 0.104952  [ 7296/13920]\n",
      "loss: 0.078012  [ 7360/13920]\n",
      "loss: 0.053216  [ 7424/13920]\n",
      "loss: 0.037525  [ 7488/13920]\n",
      "loss: 0.086659  [ 7552/13920]\n",
      "loss: 0.077963  [ 7616/13920]\n",
      "loss: 0.098905  [ 7680/13920]\n",
      "loss: 0.087797  [ 7744/13920]\n",
      "loss: 0.015363  [ 7808/13920]\n",
      "loss: 0.044841  [ 7872/13920]\n",
      "loss: 0.082099  [ 7936/13920]\n",
      "loss: 0.052114  [ 8000/13920]\n",
      "loss: 0.067724  [ 8064/13920]\n",
      "loss: 0.093628  [ 8128/13920]\n",
      "loss: 0.034386  [ 8192/13920]\n",
      "loss: 0.040418  [ 8256/13920]\n",
      "loss: 0.157655  [ 8320/13920]\n",
      "loss: 0.015762  [ 8384/13920]\n",
      "loss: 0.105349  [ 8448/13920]\n",
      "loss: 0.055666  [ 8512/13920]\n",
      "loss: 0.075013  [ 8576/13920]\n",
      "loss: 0.085324  [ 8640/13920]\n",
      "loss: 0.057899  [ 8704/13920]\n",
      "loss: 0.016708  [ 8768/13920]\n",
      "loss: 0.056636  [ 8832/13920]\n",
      "loss: 0.053965  [ 8896/13920]\n",
      "loss: 0.047328  [ 8960/13920]\n",
      "loss: 0.054104  [ 9024/13920]\n",
      "loss: 0.038354  [ 9088/13920]\n",
      "loss: 0.030935  [ 9152/13920]\n",
      "loss: 0.069954  [ 9216/13920]\n",
      "loss: 0.027970  [ 9280/13920]\n",
      "loss: 0.059205  [ 9344/13920]\n",
      "loss: 0.077328  [ 9408/13920]\n",
      "loss: 0.035268  [ 9472/13920]\n",
      "loss: 0.031633  [ 9536/13920]\n",
      "loss: 0.085375  [ 9600/13920]\n",
      "loss: 0.072258  [ 9664/13920]\n",
      "loss: 0.083299  [ 9728/13920]\n",
      "loss: 0.210399  [ 9792/13920]\n",
      "loss: 0.047942  [ 9856/13920]\n",
      "loss: 0.044803  [ 9920/13920]\n",
      "loss: 0.040828  [ 9984/13920]\n",
      "loss: 0.040469  [10048/13920]\n",
      "loss: 0.074731  [10112/13920]\n",
      "loss: 0.121471  [10176/13920]\n",
      "loss: 0.083019  [10240/13920]\n",
      "loss: 0.032743  [10304/13920]\n",
      "loss: 0.012433  [10368/13920]\n",
      "loss: 0.092991  [10432/13920]\n",
      "loss: 0.044736  [10496/13920]\n",
      "loss: 0.053310  [10560/13920]\n",
      "loss: 0.018668  [10624/13920]\n",
      "loss: 0.038227  [10688/13920]\n",
      "loss: 0.058762  [10752/13920]\n",
      "loss: 0.033950  [10816/13920]\n",
      "loss: 0.021884  [10880/13920]\n",
      "loss: 0.120791  [10944/13920]\n",
      "loss: 0.018635  [11008/13920]\n",
      "loss: 0.036340  [11072/13920]\n",
      "loss: 0.029699  [11136/13920]\n",
      "loss: 0.036894  [11200/13920]\n",
      "loss: 0.087438  [11264/13920]\n",
      "loss: 0.271974  [11328/13920]\n",
      "loss: 0.129716  [11392/13920]\n",
      "loss: 0.129300  [11456/13920]\n",
      "loss: 0.038294  [11520/13920]\n",
      "loss: 0.043696  [11584/13920]\n",
      "loss: 0.056667  [11648/13920]\n",
      "loss: 0.060658  [11712/13920]\n",
      "loss: 0.091675  [11776/13920]\n",
      "loss: 0.090853  [11840/13920]\n",
      "loss: 0.039959  [11904/13920]\n",
      "loss: 0.053514  [11968/13920]\n",
      "loss: 0.075197  [12032/13920]\n",
      "loss: 0.095120  [12096/13920]\n",
      "loss: 0.122141  [12160/13920]\n",
      "loss: 0.024403  [12224/13920]\n",
      "loss: 0.027597  [12288/13920]\n",
      "loss: 0.016309  [12352/13920]\n",
      "loss: 0.077854  [12416/13920]\n",
      "loss: 0.093689  [12480/13920]\n",
      "loss: 0.084124  [12544/13920]\n",
      "loss: 0.160927  [12608/13920]\n",
      "loss: 0.056429  [12672/13920]\n",
      "loss: 0.067146  [12736/13920]\n",
      "loss: 0.056272  [12800/13920]\n",
      "loss: 0.103264  [12864/13920]\n",
      "loss: 0.011176  [12928/13920]\n",
      "loss: 0.046448  [12992/13920]\n",
      "loss: 0.049468  [13056/13920]\n",
      "loss: 0.068312  [13120/13920]\n",
      "loss: 0.048234  [13184/13920]\n",
      "loss: 0.088912  [13248/13920]\n",
      "loss: 0.035716  [13312/13920]\n",
      "loss: 0.115509  [13376/13920]\n",
      "loss: 0.035450  [13440/13920]\n",
      "loss: 0.078826  [13504/13920]\n",
      "loss: 0.055274  [13568/13920]\n",
      "loss: 0.026869  [13632/13920]\n",
      "loss: 0.026819  [13696/13920]\n",
      "loss: 0.050159  [13760/13920]\n",
      "loss: 0.069586  [13824/13920]\n",
      "loss: 0.017949  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 98.0% \n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.110525 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.129050  [    0/13920]\n",
      "loss: 1.087358  [   64/13920]\n",
      "loss: 1.056897  [  128/13920]\n",
      "loss: 1.086739  [  192/13920]\n",
      "loss: 0.939356  [  256/13920]\n",
      "loss: 1.116104  [  320/13920]\n",
      "loss: 0.982917  [  384/13920]\n",
      "loss: 0.962109  [  448/13920]\n",
      "loss: 1.040146  [  512/13920]\n",
      "loss: 0.895222  [  576/13920]\n",
      "loss: 0.920069  [  640/13920]\n",
      "loss: 0.963433  [  704/13920]\n",
      "loss: 0.947089  [  768/13920]\n",
      "loss: 0.940478  [  832/13920]\n",
      "loss: 0.974192  [  896/13920]\n",
      "loss: 1.031889  [  960/13920]\n",
      "loss: 0.967513  [ 1024/13920]\n",
      "loss: 0.890690  [ 1088/13920]\n",
      "loss: 0.964744  [ 1152/13920]\n",
      "loss: 0.870833  [ 1216/13920]\n",
      "loss: 0.961704  [ 1280/13920]\n",
      "loss: 0.920071  [ 1344/13920]\n",
      "loss: 0.971724  [ 1408/13920]\n",
      "loss: 0.757242  [ 1472/13920]\n",
      "loss: 0.860073  [ 1536/13920]\n",
      "loss: 0.938189  [ 1600/13920]\n",
      "loss: 0.888035  [ 1664/13920]\n",
      "loss: 0.880964  [ 1728/13920]\n",
      "loss: 0.883812  [ 1792/13920]\n",
      "loss: 0.884945  [ 1856/13920]\n",
      "loss: 0.911473  [ 1920/13920]\n",
      "loss: 0.757670  [ 1984/13920]\n",
      "loss: 0.792370  [ 2048/13920]\n",
      "loss: 0.846555  [ 2112/13920]\n",
      "loss: 0.858547  [ 2176/13920]\n",
      "loss: 0.857888  [ 2240/13920]\n",
      "loss: 0.938840  [ 2304/13920]\n",
      "loss: 0.979946  [ 2368/13920]\n",
      "loss: 0.788394  [ 2432/13920]\n",
      "loss: 0.831866  [ 2496/13920]\n",
      "loss: 0.887347  [ 2560/13920]\n",
      "loss: 0.897385  [ 2624/13920]\n",
      "loss: 0.848612  [ 2688/13920]\n",
      "loss: 0.883261  [ 2752/13920]\n",
      "loss: 0.721234  [ 2816/13920]\n",
      "loss: 0.904429  [ 2880/13920]\n",
      "loss: 0.871808  [ 2944/13920]\n",
      "loss: 0.990406  [ 3008/13920]\n",
      "loss: 0.814365  [ 3072/13920]\n",
      "loss: 0.860668  [ 3136/13920]\n",
      "loss: 0.749620  [ 3200/13920]\n",
      "loss: 0.695397  [ 3264/13920]\n",
      "loss: 0.742172  [ 3328/13920]\n",
      "loss: 0.842608  [ 3392/13920]\n",
      "loss: 0.845294  [ 3456/13920]\n",
      "loss: 0.758880  [ 3520/13920]\n",
      "loss: 0.812936  [ 3584/13920]\n",
      "loss: 0.841311  [ 3648/13920]\n",
      "loss: 0.863690  [ 3712/13920]\n",
      "loss: 0.844534  [ 3776/13920]\n",
      "loss: 0.778778  [ 3840/13920]\n",
      "loss: 0.822426  [ 3904/13920]\n",
      "loss: 0.633009  [ 3968/13920]\n",
      "loss: 0.853566  [ 4032/13920]\n",
      "loss: 0.803620  [ 4096/13920]\n",
      "loss: 0.709827  [ 4160/13920]\n",
      "loss: 0.797060  [ 4224/13920]\n",
      "loss: 0.729126  [ 4288/13920]\n",
      "loss: 0.733784  [ 4352/13920]\n",
      "loss: 0.820881  [ 4416/13920]\n",
      "loss: 0.686209  [ 4480/13920]\n",
      "loss: 0.786795  [ 4544/13920]\n",
      "loss: 0.732458  [ 4608/13920]\n",
      "loss: 0.770207  [ 4672/13920]\n",
      "loss: 0.721770  [ 4736/13920]\n",
      "loss: 0.706027  [ 4800/13920]\n",
      "loss: 0.767328  [ 4864/13920]\n",
      "loss: 0.839086  [ 4928/13920]\n",
      "loss: 0.823500  [ 4992/13920]\n",
      "loss: 0.814297  [ 5056/13920]\n",
      "loss: 0.722291  [ 5120/13920]\n",
      "loss: 0.619050  [ 5184/13920]\n",
      "loss: 0.802442  [ 5248/13920]\n",
      "loss: 0.736118  [ 5312/13920]\n",
      "loss: 0.854257  [ 5376/13920]\n",
      "loss: 0.855801  [ 5440/13920]\n",
      "loss: 0.764737  [ 5504/13920]\n",
      "loss: 0.678591  [ 5568/13920]\n",
      "loss: 0.575944  [ 5632/13920]\n",
      "loss: 0.854927  [ 5696/13920]\n",
      "loss: 0.671106  [ 5760/13920]\n",
      "loss: 0.798544  [ 5824/13920]\n",
      "loss: 0.794586  [ 5888/13920]\n",
      "loss: 0.723577  [ 5952/13920]\n",
      "loss: 0.640011  [ 6016/13920]\n",
      "loss: 0.727199  [ 6080/13920]\n",
      "loss: 0.671873  [ 6144/13920]\n",
      "loss: 0.859861  [ 6208/13920]\n",
      "loss: 0.742753  [ 6272/13920]\n",
      "loss: 0.817322  [ 6336/13920]\n",
      "loss: 0.698672  [ 6400/13920]\n",
      "loss: 0.700457  [ 6464/13920]\n",
      "loss: 0.685894  [ 6528/13920]\n",
      "loss: 0.772501  [ 6592/13920]\n",
      "loss: 0.727142  [ 6656/13920]\n",
      "loss: 0.607391  [ 6720/13920]\n",
      "loss: 0.686057  [ 6784/13920]\n",
      "loss: 0.784096  [ 6848/13920]\n",
      "loss: 0.693647  [ 6912/13920]\n",
      "loss: 0.696371  [ 6976/13920]\n",
      "loss: 0.776803  [ 7040/13920]\n",
      "loss: 0.635454  [ 7104/13920]\n",
      "loss: 0.651811  [ 7168/13920]\n",
      "loss: 0.725875  [ 7232/13920]\n",
      "loss: 0.789227  [ 7296/13920]\n",
      "loss: 0.713978  [ 7360/13920]\n",
      "loss: 0.656659  [ 7424/13920]\n",
      "loss: 0.642807  [ 7488/13920]\n",
      "loss: 0.704783  [ 7552/13920]\n",
      "loss: 0.765004  [ 7616/13920]\n",
      "loss: 0.625217  [ 7680/13920]\n",
      "loss: 0.632121  [ 7744/13920]\n",
      "loss: 0.563700  [ 7808/13920]\n",
      "loss: 0.694160  [ 7872/13920]\n",
      "loss: 0.724366  [ 7936/13920]\n",
      "loss: 0.596830  [ 8000/13920]\n",
      "loss: 0.525624  [ 8064/13920]\n",
      "loss: 0.694927  [ 8128/13920]\n",
      "loss: 0.716954  [ 8192/13920]\n",
      "loss: 0.595321  [ 8256/13920]\n",
      "loss: 0.640449  [ 8320/13920]\n",
      "loss: 0.746399  [ 8384/13920]\n",
      "loss: 0.532961  [ 8448/13920]\n",
      "loss: 0.728152  [ 8512/13920]\n",
      "loss: 0.673265  [ 8576/13920]\n",
      "loss: 0.583949  [ 8640/13920]\n",
      "loss: 0.541169  [ 8704/13920]\n",
      "loss: 0.684315  [ 8768/13920]\n",
      "loss: 0.659655  [ 8832/13920]\n",
      "loss: 0.667472  [ 8896/13920]\n",
      "loss: 0.630196  [ 8960/13920]\n",
      "loss: 0.679345  [ 9024/13920]\n",
      "loss: 0.609163  [ 9088/13920]\n",
      "loss: 0.624423  [ 9152/13920]\n",
      "loss: 0.635815  [ 9216/13920]\n",
      "loss: 0.651778  [ 9280/13920]\n",
      "loss: 0.548278  [ 9344/13920]\n",
      "loss: 0.559697  [ 9408/13920]\n",
      "loss: 0.586895  [ 9472/13920]\n",
      "loss: 0.620649  [ 9536/13920]\n",
      "loss: 0.574548  [ 9600/13920]\n",
      "loss: 0.520331  [ 9664/13920]\n",
      "loss: 0.763641  [ 9728/13920]\n",
      "loss: 0.545128  [ 9792/13920]\n",
      "loss: 0.568242  [ 9856/13920]\n",
      "loss: 0.537342  [ 9920/13920]\n",
      "loss: 0.504450  [ 9984/13920]\n",
      "loss: 0.576690  [10048/13920]\n",
      "loss: 0.678423  [10112/13920]\n",
      "loss: 0.625671  [10176/13920]\n",
      "loss: 0.710707  [10240/13920]\n",
      "loss: 0.521119  [10304/13920]\n",
      "loss: 0.515134  [10368/13920]\n",
      "loss: 0.566226  [10432/13920]\n",
      "loss: 0.570291  [10496/13920]\n",
      "loss: 0.575051  [10560/13920]\n",
      "loss: 0.655300  [10624/13920]\n",
      "loss: 0.768465  [10688/13920]\n",
      "loss: 0.559609  [10752/13920]\n",
      "loss: 0.663555  [10816/13920]\n",
      "loss: 0.540538  [10880/13920]\n",
      "loss: 0.646128  [10944/13920]\n",
      "loss: 0.604151  [11008/13920]\n",
      "loss: 0.552837  [11072/13920]\n",
      "loss: 0.605156  [11136/13920]\n",
      "loss: 0.566499  [11200/13920]\n",
      "loss: 0.571984  [11264/13920]\n",
      "loss: 0.620228  [11328/13920]\n",
      "loss: 0.589075  [11392/13920]\n",
      "loss: 0.744814  [11456/13920]\n",
      "loss: 0.604615  [11520/13920]\n",
      "loss: 0.611692  [11584/13920]\n",
      "loss: 0.572525  [11648/13920]\n",
      "loss: 0.467996  [11712/13920]\n",
      "loss: 0.627919  [11776/13920]\n",
      "loss: 0.698437  [11840/13920]\n",
      "loss: 0.723808  [11904/13920]\n",
      "loss: 0.576805  [11968/13920]\n",
      "loss: 0.535491  [12032/13920]\n",
      "loss: 0.553497  [12096/13920]\n",
      "loss: 0.480616  [12160/13920]\n",
      "loss: 0.527131  [12224/13920]\n",
      "loss: 0.575468  [12288/13920]\n",
      "loss: 0.477906  [12352/13920]\n",
      "loss: 0.493372  [12416/13920]\n",
      "loss: 0.545071  [12480/13920]\n",
      "loss: 0.652048  [12544/13920]\n",
      "loss: 0.487707  [12608/13920]\n",
      "loss: 0.573587  [12672/13920]\n",
      "loss: 0.547869  [12736/13920]\n",
      "loss: 0.658682  [12800/13920]\n",
      "loss: 0.467404  [12864/13920]\n",
      "loss: 0.574474  [12928/13920]\n",
      "loss: 0.509971  [12992/13920]\n",
      "loss: 0.605440  [13056/13920]\n",
      "loss: 0.505509  [13120/13920]\n",
      "loss: 0.508324  [13184/13920]\n",
      "loss: 0.581973  [13248/13920]\n",
      "loss: 0.501332  [13312/13920]\n",
      "loss: 0.539623  [13376/13920]\n",
      "loss: 0.785657  [13440/13920]\n",
      "loss: 0.546662  [13504/13920]\n",
      "loss: 0.724051  [13568/13920]\n",
      "loss: 0.434142  [13632/13920]\n",
      "loss: 0.539439  [13696/13920]\n",
      "loss: 0.537025  [13760/13920]\n",
      "loss: 0.495809  [13824/13920]\n",
      "loss: 0.596861  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 67.8% \n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.515789 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.499327  [    0/13920]\n",
      "loss: 0.550580  [   64/13920]\n",
      "loss: 0.507296  [  128/13920]\n",
      "loss: 0.484665  [  192/13920]\n",
      "loss: 0.504015  [  256/13920]\n",
      "loss: 0.575640  [  320/13920]\n",
      "loss: 0.479966  [  384/13920]\n",
      "loss: 0.450874  [  448/13920]\n",
      "loss: 0.410574  [  512/13920]\n",
      "loss: 0.417828  [  576/13920]\n",
      "loss: 0.612338  [  640/13920]\n",
      "loss: 0.494561  [  704/13920]\n",
      "loss: 0.531406  [  768/13920]\n",
      "loss: 0.584094  [  832/13920]\n",
      "loss: 0.546126  [  896/13920]\n",
      "loss: 0.533155  [  960/13920]\n",
      "loss: 0.493196  [ 1024/13920]\n",
      "loss: 0.458190  [ 1088/13920]\n",
      "loss: 0.454583  [ 1152/13920]\n",
      "loss: 0.444691  [ 1216/13920]\n",
      "loss: 0.358528  [ 1280/13920]\n",
      "loss: 0.461557  [ 1344/13920]\n",
      "loss: 0.510830  [ 1408/13920]\n",
      "loss: 0.484618  [ 1472/13920]\n",
      "loss: 0.405059  [ 1536/13920]\n",
      "loss: 0.503800  [ 1600/13920]\n",
      "loss: 0.414372  [ 1664/13920]\n",
      "loss: 0.407612  [ 1728/13920]\n",
      "loss: 0.509718  [ 1792/13920]\n",
      "loss: 0.442659  [ 1856/13920]\n",
      "loss: 0.452940  [ 1920/13920]\n",
      "loss: 0.492680  [ 1984/13920]\n",
      "loss: 0.484566  [ 2048/13920]\n",
      "loss: 0.521048  [ 2112/13920]\n",
      "loss: 0.453222  [ 2176/13920]\n",
      "loss: 0.448650  [ 2240/13920]\n",
      "loss: 0.483926  [ 2304/13920]\n",
      "loss: 0.453877  [ 2368/13920]\n",
      "loss: 0.504194  [ 2432/13920]\n",
      "loss: 0.434382  [ 2496/13920]\n",
      "loss: 0.637999  [ 2560/13920]\n",
      "loss: 0.404371  [ 2624/13920]\n",
      "loss: 0.435490  [ 2688/13920]\n",
      "loss: 0.490935  [ 2752/13920]\n",
      "loss: 0.366288  [ 2816/13920]\n",
      "loss: 0.463903  [ 2880/13920]\n",
      "loss: 0.437138  [ 2944/13920]\n",
      "loss: 0.407670  [ 3008/13920]\n",
      "loss: 0.415493  [ 3072/13920]\n",
      "loss: 0.514736  [ 3136/13920]\n",
      "loss: 0.331558  [ 3200/13920]\n",
      "loss: 0.556099  [ 3264/13920]\n",
      "loss: 0.497170  [ 3328/13920]\n",
      "loss: 0.405158  [ 3392/13920]\n",
      "loss: 0.555447  [ 3456/13920]\n",
      "loss: 0.451642  [ 3520/13920]\n",
      "loss: 0.439485  [ 3584/13920]\n",
      "loss: 0.495232  [ 3648/13920]\n",
      "loss: 0.511816  [ 3712/13920]\n",
      "loss: 0.398509  [ 3776/13920]\n",
      "loss: 0.448737  [ 3840/13920]\n",
      "loss: 0.459042  [ 3904/13920]\n",
      "loss: 0.546371  [ 3968/13920]\n",
      "loss: 0.311297  [ 4032/13920]\n",
      "loss: 0.364258  [ 4096/13920]\n",
      "loss: 0.416634  [ 4160/13920]\n",
      "loss: 0.502618  [ 4224/13920]\n",
      "loss: 0.555865  [ 4288/13920]\n",
      "loss: 0.455623  [ 4352/13920]\n",
      "loss: 0.458470  [ 4416/13920]\n",
      "loss: 0.412015  [ 4480/13920]\n",
      "loss: 0.392857  [ 4544/13920]\n",
      "loss: 0.436428  [ 4608/13920]\n",
      "loss: 0.414766  [ 4672/13920]\n",
      "loss: 0.452622  [ 4736/13920]\n",
      "loss: 0.362241  [ 4800/13920]\n",
      "loss: 0.320506  [ 4864/13920]\n",
      "loss: 0.364557  [ 4928/13920]\n",
      "loss: 0.346527  [ 4992/13920]\n",
      "loss: 0.357717  [ 5056/13920]\n",
      "loss: 0.327140  [ 5120/13920]\n",
      "loss: 0.385811  [ 5184/13920]\n",
      "loss: 0.500146  [ 5248/13920]\n",
      "loss: 0.505841  [ 5312/13920]\n",
      "loss: 0.429401  [ 5376/13920]\n",
      "loss: 0.513811  [ 5440/13920]\n",
      "loss: 0.440847  [ 5504/13920]\n",
      "loss: 0.531845  [ 5568/13920]\n",
      "loss: 0.330609  [ 5632/13920]\n",
      "loss: 0.470523  [ 5696/13920]\n",
      "loss: 0.444102  [ 5760/13920]\n",
      "loss: 0.361837  [ 5824/13920]\n",
      "loss: 0.359122  [ 5888/13920]\n",
      "loss: 0.431624  [ 5952/13920]\n",
      "loss: 0.460419  [ 6016/13920]\n",
      "loss: 0.552872  [ 6080/13920]\n",
      "loss: 0.367036  [ 6144/13920]\n",
      "loss: 0.404831  [ 6208/13920]\n",
      "loss: 0.457881  [ 6272/13920]\n",
      "loss: 0.609061  [ 6336/13920]\n",
      "loss: 0.455735  [ 6400/13920]\n",
      "loss: 0.362405  [ 6464/13920]\n",
      "loss: 0.400386  [ 6528/13920]\n",
      "loss: 0.417999  [ 6592/13920]\n",
      "loss: 0.359373  [ 6656/13920]\n",
      "loss: 0.480291  [ 6720/13920]\n",
      "loss: 0.547073  [ 6784/13920]\n",
      "loss: 0.416887  [ 6848/13920]\n",
      "loss: 0.364730  [ 6912/13920]\n",
      "loss: 0.290597  [ 6976/13920]\n",
      "loss: 0.414939  [ 7040/13920]\n",
      "loss: 0.410217  [ 7104/13920]\n",
      "loss: 0.428134  [ 7168/13920]\n",
      "loss: 0.364938  [ 7232/13920]\n",
      "loss: 0.393495  [ 7296/13920]\n",
      "loss: 0.528812  [ 7360/13920]\n",
      "loss: 0.317886  [ 7424/13920]\n",
      "loss: 0.422301  [ 7488/13920]\n",
      "loss: 0.482510  [ 7552/13920]\n",
      "loss: 0.426826  [ 7616/13920]\n",
      "loss: 0.386264  [ 7680/13920]\n",
      "loss: 0.411435  [ 7744/13920]\n",
      "loss: 0.434545  [ 7808/13920]\n",
      "loss: 0.357410  [ 7872/13920]\n",
      "loss: 0.344578  [ 7936/13920]\n",
      "loss: 0.306372  [ 8000/13920]\n",
      "loss: 0.410892  [ 8064/13920]\n",
      "loss: 0.364753  [ 8128/13920]\n",
      "loss: 0.466796  [ 8192/13920]\n",
      "loss: 0.464573  [ 8256/13920]\n",
      "loss: 0.484427  [ 8320/13920]\n",
      "loss: 0.382788  [ 8384/13920]\n",
      "loss: 0.341576  [ 8448/13920]\n",
      "loss: 0.318722  [ 8512/13920]\n",
      "loss: 0.293671  [ 8576/13920]\n",
      "loss: 0.521557  [ 8640/13920]\n",
      "loss: 0.355322  [ 8704/13920]\n",
      "loss: 0.457526  [ 8768/13920]\n",
      "loss: 0.413975  [ 8832/13920]\n",
      "loss: 0.370957  [ 8896/13920]\n",
      "loss: 0.507262  [ 8960/13920]\n",
      "loss: 0.284861  [ 9024/13920]\n",
      "loss: 0.221705  [ 9088/13920]\n",
      "loss: 0.438799  [ 9152/13920]\n",
      "loss: 0.352623  [ 9216/13920]\n",
      "loss: 0.352653  [ 9280/13920]\n",
      "loss: 0.443398  [ 9344/13920]\n",
      "loss: 0.395439  [ 9408/13920]\n",
      "loss: 0.367444  [ 9472/13920]\n",
      "loss: 0.324593  [ 9536/13920]\n",
      "loss: 0.363439  [ 9600/13920]\n",
      "loss: 0.370008  [ 9664/13920]\n",
      "loss: 0.409095  [ 9728/13920]\n",
      "loss: 0.402702  [ 9792/13920]\n",
      "loss: 0.250448  [ 9856/13920]\n",
      "loss: 0.311349  [ 9920/13920]\n",
      "loss: 0.291116  [ 9984/13920]\n",
      "loss: 0.381343  [10048/13920]\n",
      "loss: 0.452612  [10112/13920]\n",
      "loss: 0.423432  [10176/13920]\n",
      "loss: 0.343738  [10240/13920]\n",
      "loss: 0.393319  [10304/13920]\n",
      "loss: 0.387210  [10368/13920]\n",
      "loss: 0.393473  [10432/13920]\n",
      "loss: 0.283335  [10496/13920]\n",
      "loss: 0.303905  [10560/13920]\n",
      "loss: 0.432245  [10624/13920]\n",
      "loss: 0.361040  [10688/13920]\n",
      "loss: 0.400227  [10752/13920]\n",
      "loss: 0.486849  [10816/13920]\n",
      "loss: 0.319984  [10880/13920]\n",
      "loss: 0.219211  [10944/13920]\n",
      "loss: 0.359423  [11008/13920]\n",
      "loss: 0.317146  [11072/13920]\n",
      "loss: 0.241460  [11136/13920]\n",
      "loss: 0.350784  [11200/13920]\n",
      "loss: 0.403253  [11264/13920]\n",
      "loss: 0.572767  [11328/13920]\n",
      "loss: 0.438611  [11392/13920]\n",
      "loss: 0.414991  [11456/13920]\n",
      "loss: 0.465258  [11520/13920]\n",
      "loss: 0.456557  [11584/13920]\n",
      "loss: 0.429106  [11648/13920]\n",
      "loss: 0.409534  [11712/13920]\n",
      "loss: 0.392217  [11776/13920]\n",
      "loss: 0.314389  [11840/13920]\n",
      "loss: 0.427024  [11904/13920]\n",
      "loss: 0.293130  [11968/13920]\n",
      "loss: 0.517834  [12032/13920]\n",
      "loss: 0.455313  [12096/13920]\n",
      "loss: 0.569022  [12160/13920]\n",
      "loss: 0.356923  [12224/13920]\n",
      "loss: 0.418393  [12288/13920]\n",
      "loss: 0.386080  [12352/13920]\n",
      "loss: 0.330548  [12416/13920]\n",
      "loss: 0.307791  [12480/13920]\n",
      "loss: 0.318742  [12544/13920]\n",
      "loss: 0.328938  [12608/13920]\n",
      "loss: 0.384430  [12672/13920]\n",
      "loss: 0.355973  [12736/13920]\n",
      "loss: 0.289466  [12800/13920]\n",
      "loss: 0.387657  [12864/13920]\n",
      "loss: 0.515599  [12928/13920]\n",
      "loss: 0.286961  [12992/13920]\n",
      "loss: 0.304763  [13056/13920]\n",
      "loss: 0.308005  [13120/13920]\n",
      "loss: 0.316664  [13184/13920]\n",
      "loss: 0.334492  [13248/13920]\n",
      "loss: 0.283678  [13312/13920]\n",
      "loss: 0.270350  [13376/13920]\n",
      "loss: 0.365053  [13440/13920]\n",
      "loss: 0.300391  [13504/13920]\n",
      "loss: 0.546309  [13568/13920]\n",
      "loss: 0.242200  [13632/13920]\n",
      "loss: 0.516064  [13696/13920]\n",
      "loss: 0.384627  [13760/13920]\n",
      "loss: 0.297739  [13824/13920]\n",
      "loss: 0.326232  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 84.4% \n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.349100 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.408961  [    0/13920]\n",
      "loss: 0.392421  [   64/13920]\n",
      "loss: 0.357669  [  128/13920]\n",
      "loss: 0.400075  [  192/13920]\n",
      "loss: 0.312682  [  256/13920]\n",
      "loss: 0.388840  [  320/13920]\n",
      "loss: 0.266694  [  384/13920]\n",
      "loss: 0.384771  [  448/13920]\n",
      "loss: 0.286162  [  512/13920]\n",
      "loss: 0.310957  [  576/13920]\n",
      "loss: 0.416226  [  640/13920]\n",
      "loss: 0.252874  [  704/13920]\n",
      "loss: 0.451887  [  768/13920]\n",
      "loss: 0.270172  [  832/13920]\n",
      "loss: 0.335660  [  896/13920]\n",
      "loss: 0.225588  [  960/13920]\n",
      "loss: 0.478563  [ 1024/13920]\n",
      "loss: 0.314742  [ 1088/13920]\n",
      "loss: 0.270157  [ 1152/13920]\n",
      "loss: 0.335825  [ 1216/13920]\n",
      "loss: 0.252565  [ 1280/13920]\n",
      "loss: 0.417368  [ 1344/13920]\n",
      "loss: 0.264601  [ 1408/13920]\n",
      "loss: 0.273156  [ 1472/13920]\n",
      "loss: 0.286773  [ 1536/13920]\n",
      "loss: 0.382743  [ 1600/13920]\n",
      "loss: 0.399537  [ 1664/13920]\n",
      "loss: 0.276238  [ 1728/13920]\n",
      "loss: 0.353734  [ 1792/13920]\n",
      "loss: 0.366811  [ 1856/13920]\n",
      "loss: 0.320260  [ 1920/13920]\n",
      "loss: 0.210571  [ 1984/13920]\n",
      "loss: 0.209011  [ 2048/13920]\n",
      "loss: 0.394932  [ 2112/13920]\n",
      "loss: 0.329769  [ 2176/13920]\n",
      "loss: 0.219964  [ 2240/13920]\n",
      "loss: 0.311186  [ 2304/13920]\n",
      "loss: 0.436402  [ 2368/13920]\n",
      "loss: 0.343857  [ 2432/13920]\n",
      "loss: 0.270098  [ 2496/13920]\n",
      "loss: 0.212920  [ 2560/13920]\n",
      "loss: 0.298792  [ 2624/13920]\n",
      "loss: 0.606202  [ 2688/13920]\n",
      "loss: 0.234569  [ 2752/13920]\n",
      "loss: 0.271614  [ 2816/13920]\n",
      "loss: 0.295351  [ 2880/13920]\n",
      "loss: 0.216447  [ 2944/13920]\n",
      "loss: 0.220953  [ 3008/13920]\n",
      "loss: 0.251732  [ 3072/13920]\n",
      "loss: 0.286483  [ 3136/13920]\n",
      "loss: 0.241807  [ 3200/13920]\n",
      "loss: 0.357769  [ 3264/13920]\n",
      "loss: 0.281679  [ 3328/13920]\n",
      "loss: 0.248995  [ 3392/13920]\n",
      "loss: 0.328315  [ 3456/13920]\n",
      "loss: 0.288636  [ 3520/13920]\n",
      "loss: 0.312064  [ 3584/13920]\n",
      "loss: 0.153320  [ 3648/13920]\n",
      "loss: 0.246461  [ 3712/13920]\n",
      "loss: 0.362605  [ 3776/13920]\n",
      "loss: 0.311593  [ 3840/13920]\n",
      "loss: 0.381732  [ 3904/13920]\n",
      "loss: 0.352156  [ 3968/13920]\n",
      "loss: 0.303155  [ 4032/13920]\n",
      "loss: 0.305947  [ 4096/13920]\n",
      "loss: 0.232213  [ 4160/13920]\n",
      "loss: 0.289136  [ 4224/13920]\n",
      "loss: 0.302493  [ 4288/13920]\n",
      "loss: 0.175699  [ 4352/13920]\n",
      "loss: 0.210341  [ 4416/13920]\n",
      "loss: 0.309913  [ 4480/13920]\n",
      "loss: 0.349079  [ 4544/13920]\n",
      "loss: 0.273281  [ 4608/13920]\n",
      "loss: 0.323779  [ 4672/13920]\n",
      "loss: 0.174487  [ 4736/13920]\n",
      "loss: 0.236907  [ 4800/13920]\n",
      "loss: 0.242469  [ 4864/13920]\n",
      "loss: 0.449786  [ 4928/13920]\n",
      "loss: 0.213975  [ 4992/13920]\n",
      "loss: 0.241209  [ 5056/13920]\n",
      "loss: 0.202532  [ 5120/13920]\n",
      "loss: 0.237398  [ 5184/13920]\n",
      "loss: 0.151191  [ 5248/13920]\n",
      "loss: 0.521719  [ 5312/13920]\n",
      "loss: 0.490027  [ 5376/13920]\n",
      "loss: 0.189520  [ 5440/13920]\n",
      "loss: 0.327771  [ 5504/13920]\n",
      "loss: 0.178955  [ 5568/13920]\n",
      "loss: 0.284403  [ 5632/13920]\n",
      "loss: 0.236212  [ 5696/13920]\n",
      "loss: 0.242927  [ 5760/13920]\n",
      "loss: 0.458309  [ 5824/13920]\n",
      "loss: 0.288611  [ 5888/13920]\n",
      "loss: 0.275497  [ 5952/13920]\n",
      "loss: 0.305772  [ 6016/13920]\n",
      "loss: 0.230602  [ 6080/13920]\n",
      "loss: 0.236560  [ 6144/13920]\n",
      "loss: 0.447176  [ 6208/13920]\n",
      "loss: 0.288265  [ 6272/13920]\n",
      "loss: 0.185793  [ 6336/13920]\n",
      "loss: 0.312199  [ 6400/13920]\n",
      "loss: 0.397999  [ 6464/13920]\n",
      "loss: 0.170016  [ 6528/13920]\n",
      "loss: 0.282423  [ 6592/13920]\n",
      "loss: 0.407516  [ 6656/13920]\n",
      "loss: 0.285422  [ 6720/13920]\n",
      "loss: 0.314863  [ 6784/13920]\n",
      "loss: 0.382066  [ 6848/13920]\n",
      "loss: 0.338187  [ 6912/13920]\n",
      "loss: 0.173038  [ 6976/13920]\n",
      "loss: 0.260909  [ 7040/13920]\n",
      "loss: 0.212896  [ 7104/13920]\n",
      "loss: 0.282111  [ 7168/13920]\n",
      "loss: 0.187336  [ 7232/13920]\n",
      "loss: 0.220430  [ 7296/13920]\n",
      "loss: 0.288022  [ 7360/13920]\n",
      "loss: 0.252731  [ 7424/13920]\n",
      "loss: 0.165229  [ 7488/13920]\n",
      "loss: 0.164656  [ 7552/13920]\n",
      "loss: 0.220714  [ 7616/13920]\n",
      "loss: 0.215299  [ 7680/13920]\n",
      "loss: 0.340874  [ 7744/13920]\n",
      "loss: 0.277064  [ 7808/13920]\n",
      "loss: 0.326643  [ 7872/13920]\n",
      "loss: 0.308699  [ 7936/13920]\n",
      "loss: 0.350309  [ 8000/13920]\n",
      "loss: 0.286130  [ 8064/13920]\n",
      "loss: 0.384198  [ 8128/13920]\n",
      "loss: 0.253145  [ 8192/13920]\n",
      "loss: 0.336561  [ 8256/13920]\n",
      "loss: 0.192546  [ 8320/13920]\n",
      "loss: 0.181229  [ 8384/13920]\n",
      "loss: 0.193203  [ 8448/13920]\n",
      "loss: 0.231437  [ 8512/13920]\n",
      "loss: 0.358876  [ 8576/13920]\n",
      "loss: 0.340866  [ 8640/13920]\n",
      "loss: 0.303120  [ 8704/13920]\n",
      "loss: 0.420292  [ 8768/13920]\n",
      "loss: 0.249771  [ 8832/13920]\n",
      "loss: 0.335740  [ 8896/13920]\n",
      "loss: 0.152191  [ 8960/13920]\n",
      "loss: 0.217587  [ 9024/13920]\n",
      "loss: 0.362978  [ 9088/13920]\n",
      "loss: 0.236698  [ 9152/13920]\n",
      "loss: 0.226316  [ 9216/13920]\n",
      "loss: 0.236955  [ 9280/13920]\n",
      "loss: 0.267354  [ 9344/13920]\n",
      "loss: 0.284666  [ 9408/13920]\n",
      "loss: 0.280777  [ 9472/13920]\n",
      "loss: 0.321928  [ 9536/13920]\n",
      "loss: 0.253226  [ 9600/13920]\n",
      "loss: 0.235020  [ 9664/13920]\n",
      "loss: 0.282904  [ 9728/13920]\n",
      "loss: 0.239447  [ 9792/13920]\n",
      "loss: 0.225228  [ 9856/13920]\n",
      "loss: 0.450136  [ 9920/13920]\n",
      "loss: 0.251346  [ 9984/13920]\n",
      "loss: 0.295138  [10048/13920]\n",
      "loss: 0.250000  [10112/13920]\n",
      "loss: 0.299248  [10176/13920]\n",
      "loss: 0.168436  [10240/13920]\n",
      "loss: 0.180124  [10304/13920]\n",
      "loss: 0.288666  [10368/13920]\n",
      "loss: 0.272151  [10432/13920]\n",
      "loss: 0.289962  [10496/13920]\n",
      "loss: 0.189296  [10560/13920]\n",
      "loss: 0.273930  [10624/13920]\n",
      "loss: 0.172543  [10688/13920]\n",
      "loss: 0.179487  [10752/13920]\n",
      "loss: 0.335670  [10816/13920]\n",
      "loss: 0.236731  [10880/13920]\n",
      "loss: 0.310071  [10944/13920]\n",
      "loss: 0.227413  [11008/13920]\n",
      "loss: 0.221924  [11072/13920]\n",
      "loss: 0.154780  [11136/13920]\n",
      "loss: 0.243980  [11200/13920]\n",
      "loss: 0.243090  [11264/13920]\n",
      "loss: 0.201452  [11328/13920]\n",
      "loss: 0.328116  [11392/13920]\n",
      "loss: 0.319268  [11456/13920]\n",
      "loss: 0.195964  [11520/13920]\n",
      "loss: 0.253869  [11584/13920]\n",
      "loss: 0.240434  [11648/13920]\n",
      "loss: 0.398772  [11712/13920]\n",
      "loss: 0.298107  [11776/13920]\n",
      "loss: 0.330523  [11840/13920]\n",
      "loss: 0.266667  [11904/13920]\n",
      "loss: 0.333996  [11968/13920]\n",
      "loss: 0.238122  [12032/13920]\n",
      "loss: 0.172527  [12096/13920]\n",
      "loss: 0.245129  [12160/13920]\n",
      "loss: 0.177094  [12224/13920]\n",
      "loss: 0.449032  [12288/13920]\n",
      "loss: 0.264223  [12352/13920]\n",
      "loss: 0.332254  [12416/13920]\n",
      "loss: 0.180375  [12480/13920]\n",
      "loss: 0.272131  [12544/13920]\n",
      "loss: 0.156470  [12608/13920]\n",
      "loss: 0.313188  [12672/13920]\n",
      "loss: 0.240385  [12736/13920]\n",
      "loss: 0.166523  [12800/13920]\n",
      "loss: 0.197871  [12864/13920]\n",
      "loss: 0.154599  [12928/13920]\n",
      "loss: 0.255240  [12992/13920]\n",
      "loss: 0.278479  [13056/13920]\n",
      "loss: 0.238003  [13120/13920]\n",
      "loss: 0.205506  [13184/13920]\n",
      "loss: 0.230248  [13248/13920]\n",
      "loss: 0.140195  [13312/13920]\n",
      "loss: 0.192132  [13376/13920]\n",
      "loss: 0.325754  [13440/13920]\n",
      "loss: 0.254219  [13504/13920]\n",
      "loss: 0.242313  [13568/13920]\n",
      "loss: 0.315974  [13632/13920]\n",
      "loss: 0.304773  [13696/13920]\n",
      "loss: 0.288281  [13760/13920]\n",
      "loss: 0.238027  [13824/13920]\n",
      "loss: 0.398033  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 90.2% \n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265128 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.214574  [    0/13920]\n",
      "loss: 0.289446  [   64/13920]\n",
      "loss: 0.207589  [  128/13920]\n",
      "loss: 0.179958  [  192/13920]\n",
      "loss: 0.311481  [  256/13920]\n",
      "loss: 0.201039  [  320/13920]\n",
      "loss: 0.234216  [  384/13920]\n",
      "loss: 0.236510  [  448/13920]\n",
      "loss: 0.262430  [  512/13920]\n",
      "loss: 0.183410  [  576/13920]\n",
      "loss: 0.220209  [  640/13920]\n",
      "loss: 0.230884  [  704/13920]\n",
      "loss: 0.201161  [  768/13920]\n",
      "loss: 0.180149  [  832/13920]\n",
      "loss: 0.271335  [  896/13920]\n",
      "loss: 0.231278  [  960/13920]\n",
      "loss: 0.188793  [ 1024/13920]\n",
      "loss: 0.154111  [ 1088/13920]\n",
      "loss: 0.233367  [ 1152/13920]\n",
      "loss: 0.317471  [ 1216/13920]\n",
      "loss: 0.244177  [ 1280/13920]\n",
      "loss: 0.321716  [ 1344/13920]\n",
      "loss: 0.138793  [ 1408/13920]\n",
      "loss: 0.335638  [ 1472/13920]\n",
      "loss: 0.132616  [ 1536/13920]\n",
      "loss: 0.349509  [ 1600/13920]\n",
      "loss: 0.239280  [ 1664/13920]\n",
      "loss: 0.274776  [ 1728/13920]\n",
      "loss: 0.151409  [ 1792/13920]\n",
      "loss: 0.286948  [ 1856/13920]\n",
      "loss: 0.150067  [ 1920/13920]\n",
      "loss: 0.192095  [ 1984/13920]\n",
      "loss: 0.270070  [ 2048/13920]\n",
      "loss: 0.212655  [ 2112/13920]\n",
      "loss: 0.258385  [ 2176/13920]\n",
      "loss: 0.171989  [ 2240/13920]\n",
      "loss: 0.134728  [ 2304/13920]\n",
      "loss: 0.145875  [ 2368/13920]\n",
      "loss: 0.200974  [ 2432/13920]\n",
      "loss: 0.283453  [ 2496/13920]\n",
      "loss: 0.154301  [ 2560/13920]\n",
      "loss: 0.142598  [ 2624/13920]\n",
      "loss: 0.185993  [ 2688/13920]\n",
      "loss: 0.226502  [ 2752/13920]\n",
      "loss: 0.166088  [ 2816/13920]\n",
      "loss: 0.289658  [ 2880/13920]\n",
      "loss: 0.145823  [ 2944/13920]\n",
      "loss: 0.251701  [ 3008/13920]\n",
      "loss: 0.233691  [ 3072/13920]\n",
      "loss: 0.219889  [ 3136/13920]\n",
      "loss: 0.251929  [ 3200/13920]\n",
      "loss: 0.260089  [ 3264/13920]\n",
      "loss: 0.229825  [ 3328/13920]\n",
      "loss: 0.389586  [ 3392/13920]\n",
      "loss: 0.302067  [ 3456/13920]\n",
      "loss: 0.241518  [ 3520/13920]\n",
      "loss: 0.227941  [ 3584/13920]\n",
      "loss: 0.236313  [ 3648/13920]\n",
      "loss: 0.207233  [ 3712/13920]\n",
      "loss: 0.194862  [ 3776/13920]\n",
      "loss: 0.187918  [ 3840/13920]\n",
      "loss: 0.452167  [ 3904/13920]\n",
      "loss: 0.383743  [ 3968/13920]\n",
      "loss: 0.192816  [ 4032/13920]\n",
      "loss: 0.126666  [ 4096/13920]\n",
      "loss: 0.176901  [ 4160/13920]\n",
      "loss: 0.144282  [ 4224/13920]\n",
      "loss: 0.223872  [ 4288/13920]\n",
      "loss: 0.181649  [ 4352/13920]\n",
      "loss: 0.253368  [ 4416/13920]\n",
      "loss: 0.153659  [ 4480/13920]\n",
      "loss: 0.178407  [ 4544/13920]\n",
      "loss: 0.234203  [ 4608/13920]\n",
      "loss: 0.203574  [ 4672/13920]\n",
      "loss: 0.163902  [ 4736/13920]\n",
      "loss: 0.208545  [ 4800/13920]\n",
      "loss: 0.185587  [ 4864/13920]\n",
      "loss: 0.227462  [ 4928/13920]\n",
      "loss: 0.252391  [ 4992/13920]\n",
      "loss: 0.149048  [ 5056/13920]\n",
      "loss: 0.137519  [ 5120/13920]\n",
      "loss: 0.173202  [ 5184/13920]\n",
      "loss: 0.185239  [ 5248/13920]\n",
      "loss: 0.254282  [ 5312/13920]\n",
      "loss: 0.455062  [ 5376/13920]\n",
      "loss: 0.361073  [ 5440/13920]\n",
      "loss: 0.223964  [ 5504/13920]\n",
      "loss: 0.196657  [ 5568/13920]\n",
      "loss: 0.135462  [ 5632/13920]\n",
      "loss: 0.273474  [ 5696/13920]\n",
      "loss: 0.167732  [ 5760/13920]\n",
      "loss: 0.215271  [ 5824/13920]\n",
      "loss: 0.198416  [ 5888/13920]\n",
      "loss: 0.184289  [ 5952/13920]\n",
      "loss: 0.228604  [ 6016/13920]\n",
      "loss: 0.230361  [ 6080/13920]\n",
      "loss: 0.276526  [ 6144/13920]\n",
      "loss: 0.309983  [ 6208/13920]\n",
      "loss: 0.267341  [ 6272/13920]\n",
      "loss: 0.250361  [ 6336/13920]\n",
      "loss: 0.243845  [ 6400/13920]\n",
      "loss: 0.140393  [ 6464/13920]\n",
      "loss: 0.240403  [ 6528/13920]\n",
      "loss: 0.211665  [ 6592/13920]\n",
      "loss: 0.191492  [ 6656/13920]\n",
      "loss: 0.146469  [ 6720/13920]\n",
      "loss: 0.148716  [ 6784/13920]\n",
      "loss: 0.171710  [ 6848/13920]\n",
      "loss: 0.272840  [ 6912/13920]\n",
      "loss: 0.178073  [ 6976/13920]\n",
      "loss: 0.267813  [ 7040/13920]\n",
      "loss: 0.178358  [ 7104/13920]\n",
      "loss: 0.280657  [ 7168/13920]\n",
      "loss: 0.195391  [ 7232/13920]\n",
      "loss: 0.165800  [ 7296/13920]\n",
      "loss: 0.201624  [ 7360/13920]\n",
      "loss: 0.274906  [ 7424/13920]\n",
      "loss: 0.141961  [ 7488/13920]\n",
      "loss: 0.157166  [ 7552/13920]\n",
      "loss: 0.286570  [ 7616/13920]\n",
      "loss: 0.206163  [ 7680/13920]\n",
      "loss: 0.216433  [ 7744/13920]\n",
      "loss: 0.197938  [ 7808/13920]\n",
      "loss: 0.157185  [ 7872/13920]\n",
      "loss: 0.446232  [ 7936/13920]\n",
      "loss: 0.149912  [ 8000/13920]\n",
      "loss: 0.193972  [ 8064/13920]\n",
      "loss: 0.295265  [ 8128/13920]\n",
      "loss: 0.201121  [ 8192/13920]\n",
      "loss: 0.212972  [ 8256/13920]\n",
      "loss: 0.244401  [ 8320/13920]\n",
      "loss: 0.142810  [ 8384/13920]\n",
      "loss: 0.147045  [ 8448/13920]\n",
      "loss: 0.249343  [ 8512/13920]\n",
      "loss: 0.133834  [ 8576/13920]\n",
      "loss: 0.233422  [ 8640/13920]\n",
      "loss: 0.200247  [ 8704/13920]\n",
      "loss: 0.315152  [ 8768/13920]\n",
      "loss: 0.185301  [ 8832/13920]\n",
      "loss: 0.207051  [ 8896/13920]\n",
      "loss: 0.183858  [ 8960/13920]\n",
      "loss: 0.249940  [ 9024/13920]\n",
      "loss: 0.245588  [ 9088/13920]\n",
      "loss: 0.303491  [ 9152/13920]\n",
      "loss: 0.149101  [ 9216/13920]\n",
      "loss: 0.290525  [ 9280/13920]\n",
      "loss: 0.344155  [ 9344/13920]\n",
      "loss: 0.181090  [ 9408/13920]\n",
      "loss: 0.166807  [ 9472/13920]\n",
      "loss: 0.207883  [ 9536/13920]\n",
      "loss: 0.195185  [ 9600/13920]\n",
      "loss: 0.196409  [ 9664/13920]\n",
      "loss: 0.194634  [ 9728/13920]\n",
      "loss: 0.182511  [ 9792/13920]\n",
      "loss: 0.135419  [ 9856/13920]\n",
      "loss: 0.267248  [ 9920/13920]\n",
      "loss: 0.218496  [ 9984/13920]\n",
      "loss: 0.223092  [10048/13920]\n",
      "loss: 0.272995  [10112/13920]\n",
      "loss: 0.091631  [10176/13920]\n",
      "loss: 0.116058  [10240/13920]\n",
      "loss: 0.288475  [10304/13920]\n",
      "loss: 0.190025  [10368/13920]\n",
      "loss: 0.156583  [10432/13920]\n",
      "loss: 0.102304  [10496/13920]\n",
      "loss: 0.183685  [10560/13920]\n",
      "loss: 0.213964  [10624/13920]\n",
      "loss: 0.125554  [10688/13920]\n",
      "loss: 0.163644  [10752/13920]\n",
      "loss: 0.146031  [10816/13920]\n",
      "loss: 0.090050  [10880/13920]\n",
      "loss: 0.119040  [10944/13920]\n",
      "loss: 0.175613  [11008/13920]\n",
      "loss: 0.132722  [11072/13920]\n",
      "loss: 0.218651  [11136/13920]\n",
      "loss: 0.285631  [11200/13920]\n",
      "loss: 0.139099  [11264/13920]\n",
      "loss: 0.113064  [11328/13920]\n",
      "loss: 0.316370  [11392/13920]\n",
      "loss: 0.158489  [11456/13920]\n",
      "loss: 0.133618  [11520/13920]\n",
      "loss: 0.232420  [11584/13920]\n",
      "loss: 0.112685  [11648/13920]\n",
      "loss: 0.151175  [11712/13920]\n",
      "loss: 0.087530  [11776/13920]\n",
      "loss: 0.153383  [11840/13920]\n",
      "loss: 0.165289  [11904/13920]\n",
      "loss: 0.169965  [11968/13920]\n",
      "loss: 0.176420  [12032/13920]\n",
      "loss: 0.193036  [12096/13920]\n",
      "loss: 0.312320  [12160/13920]\n",
      "loss: 0.251941  [12224/13920]\n",
      "loss: 0.103405  [12288/13920]\n",
      "loss: 0.110164  [12352/13920]\n",
      "loss: 0.168652  [12416/13920]\n",
      "loss: 0.228462  [12480/13920]\n",
      "loss: 0.178226  [12544/13920]\n",
      "loss: 0.196368  [12608/13920]\n",
      "loss: 0.162052  [12672/13920]\n",
      "loss: 0.156577  [12736/13920]\n",
      "loss: 0.110286  [12800/13920]\n",
      "loss: 0.231501  [12864/13920]\n",
      "loss: 0.146984  [12928/13920]\n",
      "loss: 0.130324  [12992/13920]\n",
      "loss: 0.178798  [13056/13920]\n",
      "loss: 0.283732  [13120/13920]\n",
      "loss: 0.225588  [13184/13920]\n",
      "loss: 0.081423  [13248/13920]\n",
      "loss: 0.081590  [13312/13920]\n",
      "loss: 0.133694  [13376/13920]\n",
      "loss: 0.197150  [13440/13920]\n",
      "loss: 0.118944  [13504/13920]\n",
      "loss: 0.100472  [13568/13920]\n",
      "loss: 0.261569  [13632/13920]\n",
      "loss: 0.233783  [13696/13920]\n",
      "loss: 0.180008  [13760/13920]\n",
      "loss: 0.122723  [13824/13920]\n",
      "loss: 0.220879  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 92.9% \n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.186529 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.154530  [    0/13920]\n",
      "loss: 0.183039  [   64/13920]\n",
      "loss: 0.177191  [  128/13920]\n",
      "loss: 0.116437  [  192/13920]\n",
      "loss: 0.164329  [  256/13920]\n",
      "loss: 0.125528  [  320/13920]\n",
      "loss: 0.212056  [  384/13920]\n",
      "loss: 0.086276  [  448/13920]\n",
      "loss: 0.186549  [  512/13920]\n",
      "loss: 0.236970  [  576/13920]\n",
      "loss: 0.096800  [  640/13920]\n",
      "loss: 0.222295  [  704/13920]\n",
      "loss: 0.133409  [  768/13920]\n",
      "loss: 0.128120  [  832/13920]\n",
      "loss: 0.087943  [  896/13920]\n",
      "loss: 0.183244  [  960/13920]\n",
      "loss: 0.078914  [ 1024/13920]\n",
      "loss: 0.134225  [ 1088/13920]\n",
      "loss: 0.226575  [ 1152/13920]\n",
      "loss: 0.134904  [ 1216/13920]\n",
      "loss: 0.195529  [ 1280/13920]\n",
      "loss: 0.177274  [ 1344/13920]\n",
      "loss: 0.173397  [ 1408/13920]\n",
      "loss: 0.202529  [ 1472/13920]\n",
      "loss: 0.134360  [ 1536/13920]\n",
      "loss: 0.160307  [ 1600/13920]\n",
      "loss: 0.143146  [ 1664/13920]\n",
      "loss: 0.108145  [ 1728/13920]\n",
      "loss: 0.108754  [ 1792/13920]\n",
      "loss: 0.202036  [ 1856/13920]\n",
      "loss: 0.157544  [ 1920/13920]\n",
      "loss: 0.067788  [ 1984/13920]\n",
      "loss: 0.135129  [ 2048/13920]\n",
      "loss: 0.105141  [ 2112/13920]\n",
      "loss: 0.162852  [ 2176/13920]\n",
      "loss: 0.152928  [ 2240/13920]\n",
      "loss: 0.147675  [ 2304/13920]\n",
      "loss: 0.093629  [ 2368/13920]\n",
      "loss: 0.068565  [ 2432/13920]\n",
      "loss: 0.302515  [ 2496/13920]\n",
      "loss: 0.142287  [ 2560/13920]\n",
      "loss: 0.096513  [ 2624/13920]\n",
      "loss: 0.261013  [ 2688/13920]\n",
      "loss: 0.117515  [ 2752/13920]\n",
      "loss: 0.306444  [ 2816/13920]\n",
      "loss: 0.126382  [ 2880/13920]\n",
      "loss: 0.230024  [ 2944/13920]\n",
      "loss: 0.208570  [ 3008/13920]\n",
      "loss: 0.233089  [ 3072/13920]\n",
      "loss: 0.065996  [ 3136/13920]\n",
      "loss: 0.073344  [ 3200/13920]\n",
      "loss: 0.148453  [ 3264/13920]\n",
      "loss: 0.124353  [ 3328/13920]\n",
      "loss: 0.178926  [ 3392/13920]\n",
      "loss: 0.173074  [ 3456/13920]\n",
      "loss: 0.103549  [ 3520/13920]\n",
      "loss: 0.089296  [ 3584/13920]\n",
      "loss: 0.135921  [ 3648/13920]\n",
      "loss: 0.151262  [ 3712/13920]\n",
      "loss: 0.109148  [ 3776/13920]\n",
      "loss: 0.150463  [ 3840/13920]\n",
      "loss: 0.102411  [ 3904/13920]\n",
      "loss: 0.238127  [ 3968/13920]\n",
      "loss: 0.088848  [ 4032/13920]\n",
      "loss: 0.059856  [ 4096/13920]\n",
      "loss: 0.089173  [ 4160/13920]\n",
      "loss: 0.143122  [ 4224/13920]\n",
      "loss: 0.150864  [ 4288/13920]\n",
      "loss: 0.182515  [ 4352/13920]\n",
      "loss: 0.075056  [ 4416/13920]\n",
      "loss: 0.140712  [ 4480/13920]\n",
      "loss: 0.157984  [ 4544/13920]\n",
      "loss: 0.180937  [ 4608/13920]\n",
      "loss: 0.156493  [ 4672/13920]\n",
      "loss: 0.101192  [ 4736/13920]\n",
      "loss: 0.094764  [ 4800/13920]\n",
      "loss: 0.074034  [ 4864/13920]\n",
      "loss: 0.172307  [ 4928/13920]\n",
      "loss: 0.171369  [ 4992/13920]\n",
      "loss: 0.147116  [ 5056/13920]\n",
      "loss: 0.123026  [ 5120/13920]\n",
      "loss: 0.110126  [ 5184/13920]\n",
      "loss: 0.145434  [ 5248/13920]\n",
      "loss: 0.108169  [ 5312/13920]\n",
      "loss: 0.094239  [ 5376/13920]\n",
      "loss: 0.095860  [ 5440/13920]\n",
      "loss: 0.166264  [ 5504/13920]\n",
      "loss: 0.306517  [ 5568/13920]\n",
      "loss: 0.199575  [ 5632/13920]\n",
      "loss: 0.161499  [ 5696/13920]\n",
      "loss: 0.154248  [ 5760/13920]\n",
      "loss: 0.239100  [ 5824/13920]\n",
      "loss: 0.138787  [ 5888/13920]\n",
      "loss: 0.156332  [ 5952/13920]\n",
      "loss: 0.141712  [ 6016/13920]\n",
      "loss: 0.101546  [ 6080/13920]\n",
      "loss: 0.109367  [ 6144/13920]\n",
      "loss: 0.148767  [ 6208/13920]\n",
      "loss: 0.251027  [ 6272/13920]\n",
      "loss: 0.136741  [ 6336/13920]\n",
      "loss: 0.107542  [ 6400/13920]\n",
      "loss: 0.155179  [ 6464/13920]\n",
      "loss: 0.322662  [ 6528/13920]\n",
      "loss: 0.087450  [ 6592/13920]\n",
      "loss: 0.151976  [ 6656/13920]\n",
      "loss: 0.234087  [ 6720/13920]\n",
      "loss: 0.216456  [ 6784/13920]\n",
      "loss: 0.118781  [ 6848/13920]\n",
      "loss: 0.095217  [ 6912/13920]\n",
      "loss: 0.170881  [ 6976/13920]\n",
      "loss: 0.053736  [ 7040/13920]\n",
      "loss: 0.108220  [ 7104/13920]\n",
      "loss: 0.091383  [ 7168/13920]\n",
      "loss: 0.189516  [ 7232/13920]\n",
      "loss: 0.197133  [ 7296/13920]\n",
      "loss: 0.145481  [ 7360/13920]\n",
      "loss: 0.298299  [ 7424/13920]\n",
      "loss: 0.123160  [ 7488/13920]\n",
      "loss: 0.116262  [ 7552/13920]\n",
      "loss: 0.137574  [ 7616/13920]\n",
      "loss: 0.161332  [ 7680/13920]\n",
      "loss: 0.094510  [ 7744/13920]\n",
      "loss: 0.090657  [ 7808/13920]\n",
      "loss: 0.130045  [ 7872/13920]\n",
      "loss: 0.123544  [ 7936/13920]\n",
      "loss: 0.088521  [ 8000/13920]\n",
      "loss: 0.097290  [ 8064/13920]\n",
      "loss: 0.101996  [ 8128/13920]\n",
      "loss: 0.133981  [ 8192/13920]\n",
      "loss: 0.076474  [ 8256/13920]\n",
      "loss: 0.244106  [ 8320/13920]\n",
      "loss: 0.129905  [ 8384/13920]\n",
      "loss: 0.184558  [ 8448/13920]\n",
      "loss: 0.222558  [ 8512/13920]\n",
      "loss: 0.071039  [ 8576/13920]\n",
      "loss: 0.252745  [ 8640/13920]\n",
      "loss: 0.126121  [ 8704/13920]\n",
      "loss: 0.193578  [ 8768/13920]\n",
      "loss: 0.222607  [ 8832/13920]\n",
      "loss: 0.069948  [ 8896/13920]\n",
      "loss: 0.145644  [ 8960/13920]\n",
      "loss: 0.059265  [ 9024/13920]\n",
      "loss: 0.158042  [ 9088/13920]\n",
      "loss: 0.152291  [ 9152/13920]\n",
      "loss: 0.310489  [ 9216/13920]\n",
      "loss: 0.125281  [ 9280/13920]\n",
      "loss: 0.122548  [ 9344/13920]\n",
      "loss: 0.090364  [ 9408/13920]\n",
      "loss: 0.125688  [ 9472/13920]\n",
      "loss: 0.128116  [ 9536/13920]\n",
      "loss: 0.169792  [ 9600/13920]\n",
      "loss: 0.201204  [ 9664/13920]\n",
      "loss: 0.151968  [ 9728/13920]\n",
      "loss: 0.123912  [ 9792/13920]\n",
      "loss: 0.124884  [ 9856/13920]\n",
      "loss: 0.107707  [ 9920/13920]\n",
      "loss: 0.137149  [ 9984/13920]\n",
      "loss: 0.167728  [10048/13920]\n",
      "loss: 0.114278  [10112/13920]\n",
      "loss: 0.213168  [10176/13920]\n",
      "loss: 0.152646  [10240/13920]\n",
      "loss: 0.110401  [10304/13920]\n",
      "loss: 0.171696  [10368/13920]\n",
      "loss: 0.122823  [10432/13920]\n",
      "loss: 0.062164  [10496/13920]\n",
      "loss: 0.067448  [10560/13920]\n",
      "loss: 0.112161  [10624/13920]\n",
      "loss: 0.117436  [10688/13920]\n",
      "loss: 0.160812  [10752/13920]\n",
      "loss: 0.092678  [10816/13920]\n",
      "loss: 0.145746  [10880/13920]\n",
      "loss: 0.097896  [10944/13920]\n",
      "loss: 0.129707  [11008/13920]\n",
      "loss: 0.198530  [11072/13920]\n",
      "loss: 0.184950  [11136/13920]\n",
      "loss: 0.145436  [11200/13920]\n",
      "loss: 0.079576  [11264/13920]\n",
      "loss: 0.184386  [11328/13920]\n",
      "loss: 0.080231  [11392/13920]\n",
      "loss: 0.198450  [11456/13920]\n",
      "loss: 0.197146  [11520/13920]\n",
      "loss: 0.086026  [11584/13920]\n",
      "loss: 0.118038  [11648/13920]\n",
      "loss: 0.158407  [11712/13920]\n",
      "loss: 0.195582  [11776/13920]\n",
      "loss: 0.229718  [11840/13920]\n",
      "loss: 0.073142  [11904/13920]\n",
      "loss: 0.178438  [11968/13920]\n",
      "loss: 0.259886  [12032/13920]\n",
      "loss: 0.128240  [12096/13920]\n",
      "loss: 0.183702  [12160/13920]\n",
      "loss: 0.137452  [12224/13920]\n",
      "loss: 0.205982  [12288/13920]\n",
      "loss: 0.177134  [12352/13920]\n",
      "loss: 0.185765  [12416/13920]\n",
      "loss: 0.188348  [12480/13920]\n",
      "loss: 0.171948  [12544/13920]\n",
      "loss: 0.186155  [12608/13920]\n",
      "loss: 0.232863  [12672/13920]\n",
      "loss: 0.170514  [12736/13920]\n",
      "loss: 0.144440  [12800/13920]\n",
      "loss: 0.152849  [12864/13920]\n",
      "loss: 0.181323  [12928/13920]\n",
      "loss: 0.211346  [12992/13920]\n",
      "loss: 0.291062  [13056/13920]\n",
      "loss: 0.103140  [13120/13920]\n",
      "loss: 0.135048  [13184/13920]\n",
      "loss: 0.071847  [13248/13920]\n",
      "loss: 0.132398  [13312/13920]\n",
      "loss: 0.105569  [13376/13920]\n",
      "loss: 0.208936  [13440/13920]\n",
      "loss: 0.143532  [13504/13920]\n",
      "loss: 0.208844  [13568/13920]\n",
      "loss: 0.193364  [13632/13920]\n",
      "loss: 0.109087  [13696/13920]\n",
      "loss: 0.179246  [13760/13920]\n",
      "loss: 0.218815  [13824/13920]\n",
      "loss: 0.164044  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.2% \n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.159427 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.165308  [    0/13920]\n",
      "loss: 0.188420  [   64/13920]\n",
      "loss: 0.105242  [  128/13920]\n",
      "loss: 0.087052  [  192/13920]\n",
      "loss: 0.113454  [  256/13920]\n",
      "loss: 0.102709  [  320/13920]\n",
      "loss: 0.173623  [  384/13920]\n",
      "loss: 0.117012  [  448/13920]\n",
      "loss: 0.203278  [  512/13920]\n",
      "loss: 0.252968  [  576/13920]\n",
      "loss: 0.083753  [  640/13920]\n",
      "loss: 0.075330  [  704/13920]\n",
      "loss: 0.134738  [  768/13920]\n",
      "loss: 0.100680  [  832/13920]\n",
      "loss: 0.149912  [  896/13920]\n",
      "loss: 0.098393  [  960/13920]\n",
      "loss: 0.172944  [ 1024/13920]\n",
      "loss: 0.105127  [ 1088/13920]\n",
      "loss: 0.073648  [ 1152/13920]\n",
      "loss: 0.159833  [ 1216/13920]\n",
      "loss: 0.176323  [ 1280/13920]\n",
      "loss: 0.140555  [ 1344/13920]\n",
      "loss: 0.127259  [ 1408/13920]\n",
      "loss: 0.140313  [ 1472/13920]\n",
      "loss: 0.082858  [ 1536/13920]\n",
      "loss: 0.137149  [ 1600/13920]\n",
      "loss: 0.138786  [ 1664/13920]\n",
      "loss: 0.076697  [ 1728/13920]\n",
      "loss: 0.090140  [ 1792/13920]\n",
      "loss: 0.098112  [ 1856/13920]\n",
      "loss: 0.046728  [ 1920/13920]\n",
      "loss: 0.121527  [ 1984/13920]\n",
      "loss: 0.157262  [ 2048/13920]\n",
      "loss: 0.068416  [ 2112/13920]\n",
      "loss: 0.104452  [ 2176/13920]\n",
      "loss: 0.150987  [ 2240/13920]\n",
      "loss: 0.267928  [ 2304/13920]\n",
      "loss: 0.118414  [ 2368/13920]\n",
      "loss: 0.116534  [ 2432/13920]\n",
      "loss: 0.210493  [ 2496/13920]\n",
      "loss: 0.056773  [ 2560/13920]\n",
      "loss: 0.158499  [ 2624/13920]\n",
      "loss: 0.091966  [ 2688/13920]\n",
      "loss: 0.091016  [ 2752/13920]\n",
      "loss: 0.153403  [ 2816/13920]\n",
      "loss: 0.174826  [ 2880/13920]\n",
      "loss: 0.104930  [ 2944/13920]\n",
      "loss: 0.136832  [ 3008/13920]\n",
      "loss: 0.104359  [ 3072/13920]\n",
      "loss: 0.111076  [ 3136/13920]\n",
      "loss: 0.098690  [ 3200/13920]\n",
      "loss: 0.073533  [ 3264/13920]\n",
      "loss: 0.088067  [ 3328/13920]\n",
      "loss: 0.083537  [ 3392/13920]\n",
      "loss: 0.218077  [ 3456/13920]\n",
      "loss: 0.163589  [ 3520/13920]\n",
      "loss: 0.050188  [ 3584/13920]\n",
      "loss: 0.057471  [ 3648/13920]\n",
      "loss: 0.053292  [ 3712/13920]\n",
      "loss: 0.104004  [ 3776/13920]\n",
      "loss: 0.096451  [ 3840/13920]\n",
      "loss: 0.103448  [ 3904/13920]\n",
      "loss: 0.137937  [ 3968/13920]\n",
      "loss: 0.238602  [ 4032/13920]\n",
      "loss: 0.122962  [ 4096/13920]\n",
      "loss: 0.090018  [ 4160/13920]\n",
      "loss: 0.125919  [ 4224/13920]\n",
      "loss: 0.130020  [ 4288/13920]\n",
      "loss: 0.158964  [ 4352/13920]\n",
      "loss: 0.044550  [ 4416/13920]\n",
      "loss: 0.247987  [ 4480/13920]\n",
      "loss: 0.127621  [ 4544/13920]\n",
      "loss: 0.135092  [ 4608/13920]\n",
      "loss: 0.127371  [ 4672/13920]\n",
      "loss: 0.171621  [ 4736/13920]\n",
      "loss: 0.109123  [ 4800/13920]\n",
      "loss: 0.113377  [ 4864/13920]\n",
      "loss: 0.083410  [ 4928/13920]\n",
      "loss: 0.121085  [ 4992/13920]\n",
      "loss: 0.135360  [ 5056/13920]\n",
      "loss: 0.070842  [ 5120/13920]\n",
      "loss: 0.094574  [ 5184/13920]\n",
      "loss: 0.151646  [ 5248/13920]\n",
      "loss: 0.114424  [ 5312/13920]\n",
      "loss: 0.140370  [ 5376/13920]\n",
      "loss: 0.076519  [ 5440/13920]\n",
      "loss: 0.107813  [ 5504/13920]\n",
      "loss: 0.144546  [ 5568/13920]\n",
      "loss: 0.152724  [ 5632/13920]\n",
      "loss: 0.117862  [ 5696/13920]\n",
      "loss: 0.112106  [ 5760/13920]\n",
      "loss: 0.184030  [ 5824/13920]\n",
      "loss: 0.109957  [ 5888/13920]\n",
      "loss: 0.245836  [ 5952/13920]\n",
      "loss: 0.119378  [ 6016/13920]\n",
      "loss: 0.126092  [ 6080/13920]\n",
      "loss: 0.118662  [ 6144/13920]\n",
      "loss: 0.187991  [ 6208/13920]\n",
      "loss: 0.155388  [ 6272/13920]\n",
      "loss: 0.116401  [ 6336/13920]\n",
      "loss: 0.049580  [ 6400/13920]\n",
      "loss: 0.086597  [ 6464/13920]\n",
      "loss: 0.159603  [ 6528/13920]\n",
      "loss: 0.192422  [ 6592/13920]\n",
      "loss: 0.104170  [ 6656/13920]\n",
      "loss: 0.196221  [ 6720/13920]\n",
      "loss: 0.127561  [ 6784/13920]\n",
      "loss: 0.123090  [ 6848/13920]\n",
      "loss: 0.098338  [ 6912/13920]\n",
      "loss: 0.127137  [ 6976/13920]\n",
      "loss: 0.093723  [ 7040/13920]\n",
      "loss: 0.104783  [ 7104/13920]\n",
      "loss: 0.103340  [ 7168/13920]\n",
      "loss: 0.072176  [ 7232/13920]\n",
      "loss: 0.161257  [ 7296/13920]\n",
      "loss: 0.100794  [ 7360/13920]\n",
      "loss: 0.089492  [ 7424/13920]\n",
      "loss: 0.187686  [ 7488/13920]\n",
      "loss: 0.073911  [ 7552/13920]\n",
      "loss: 0.218993  [ 7616/13920]\n",
      "loss: 0.230083  [ 7680/13920]\n",
      "loss: 0.183847  [ 7744/13920]\n",
      "loss: 0.139990  [ 7808/13920]\n",
      "loss: 0.259545  [ 7872/13920]\n",
      "loss: 0.142875  [ 7936/13920]\n",
      "loss: 0.166545  [ 8000/13920]\n",
      "loss: 0.074768  [ 8064/13920]\n",
      "loss: 0.103106  [ 8128/13920]\n",
      "loss: 0.083174  [ 8192/13920]\n",
      "loss: 0.170438  [ 8256/13920]\n",
      "loss: 0.113680  [ 8320/13920]\n",
      "loss: 0.236544  [ 8384/13920]\n",
      "loss: 0.132905  [ 8448/13920]\n",
      "loss: 0.120700  [ 8512/13920]\n",
      "loss: 0.140661  [ 8576/13920]\n",
      "loss: 0.179462  [ 8640/13920]\n",
      "loss: 0.154990  [ 8704/13920]\n",
      "loss: 0.198779  [ 8768/13920]\n",
      "loss: 0.110946  [ 8832/13920]\n",
      "loss: 0.041490  [ 8896/13920]\n",
      "loss: 0.170234  [ 8960/13920]\n",
      "loss: 0.081577  [ 9024/13920]\n",
      "loss: 0.046656  [ 9088/13920]\n",
      "loss: 0.293906  [ 9152/13920]\n",
      "loss: 0.074082  [ 9216/13920]\n",
      "loss: 0.078086  [ 9280/13920]\n",
      "loss: 0.103962  [ 9344/13920]\n",
      "loss: 0.093282  [ 9408/13920]\n",
      "loss: 0.052219  [ 9472/13920]\n",
      "loss: 0.136227  [ 9536/13920]\n",
      "loss: 0.178224  [ 9600/13920]\n",
      "loss: 0.268645  [ 9664/13920]\n",
      "loss: 0.130543  [ 9728/13920]\n",
      "loss: 0.134101  [ 9792/13920]\n",
      "loss: 0.086439  [ 9856/13920]\n",
      "loss: 0.199367  [ 9920/13920]\n",
      "loss: 0.162842  [ 9984/13920]\n",
      "loss: 0.067354  [10048/13920]\n",
      "loss: 0.225797  [10112/13920]\n",
      "loss: 0.085261  [10176/13920]\n",
      "loss: 0.085816  [10240/13920]\n",
      "loss: 0.082087  [10304/13920]\n",
      "loss: 0.209218  [10368/13920]\n",
      "loss: 0.099544  [10432/13920]\n",
      "loss: 0.096189  [10496/13920]\n",
      "loss: 0.120167  [10560/13920]\n",
      "loss: 0.134017  [10624/13920]\n",
      "loss: 0.113453  [10688/13920]\n",
      "loss: 0.159307  [10752/13920]\n",
      "loss: 0.195924  [10816/13920]\n",
      "loss: 0.042407  [10880/13920]\n",
      "loss: 0.094965  [10944/13920]\n",
      "loss: 0.113274  [11008/13920]\n",
      "loss: 0.103422  [11072/13920]\n",
      "loss: 0.176850  [11136/13920]\n",
      "loss: 0.116764  [11200/13920]\n",
      "loss: 0.163009  [11264/13920]\n",
      "loss: 0.129069  [11328/13920]\n",
      "loss: 0.222593  [11392/13920]\n",
      "loss: 0.120236  [11456/13920]\n",
      "loss: 0.163485  [11520/13920]\n",
      "loss: 0.145995  [11584/13920]\n",
      "loss: 0.201397  [11648/13920]\n",
      "loss: 0.156028  [11712/13920]\n",
      "loss: 0.038865  [11776/13920]\n",
      "loss: 0.188168  [11840/13920]\n",
      "loss: 0.053124  [11904/13920]\n",
      "loss: 0.047296  [11968/13920]\n",
      "loss: 0.072307  [12032/13920]\n",
      "loss: 0.113302  [12096/13920]\n",
      "loss: 0.089061  [12160/13920]\n",
      "loss: 0.099356  [12224/13920]\n",
      "loss: 0.186291  [12288/13920]\n",
      "loss: 0.149722  [12352/13920]\n",
      "loss: 0.094367  [12416/13920]\n",
      "loss: 0.110495  [12480/13920]\n",
      "loss: 0.063792  [12544/13920]\n",
      "loss: 0.109488  [12608/13920]\n",
      "loss: 0.091657  [12672/13920]\n",
      "loss: 0.095428  [12736/13920]\n",
      "loss: 0.093408  [12800/13920]\n",
      "loss: 0.139187  [12864/13920]\n",
      "loss: 0.059052  [12928/13920]\n",
      "loss: 0.145964  [12992/13920]\n",
      "loss: 0.167075  [13056/13920]\n",
      "loss: 0.098893  [13120/13920]\n",
      "loss: 0.065104  [13184/13920]\n",
      "loss: 0.087999  [13248/13920]\n",
      "loss: 0.032375  [13312/13920]\n",
      "loss: 0.198613  [13376/13920]\n",
      "loss: 0.145694  [13440/13920]\n",
      "loss: 0.070977  [13504/13920]\n",
      "loss: 0.165078  [13568/13920]\n",
      "loss: 0.091418  [13632/13920]\n",
      "loss: 0.119264  [13696/13920]\n",
      "loss: 0.136987  [13760/13920]\n",
      "loss: 0.121595  [13824/13920]\n",
      "loss: 0.141772  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.7% \n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.158758 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.102374  [    0/13920]\n",
      "loss: 0.112134  [   64/13920]\n",
      "loss: 0.099036  [  128/13920]\n",
      "loss: 0.066253  [  192/13920]\n",
      "loss: 0.122287  [  256/13920]\n",
      "loss: 0.184874  [  320/13920]\n",
      "loss: 0.151686  [  384/13920]\n",
      "loss: 0.170711  [  448/13920]\n",
      "loss: 0.154357  [  512/13920]\n",
      "loss: 0.096589  [  576/13920]\n",
      "loss: 0.032070  [  640/13920]\n",
      "loss: 0.115753  [  704/13920]\n",
      "loss: 0.168658  [  768/13920]\n",
      "loss: 0.190289  [  832/13920]\n",
      "loss: 0.135085  [  896/13920]\n",
      "loss: 0.106600  [  960/13920]\n",
      "loss: 0.034586  [ 1024/13920]\n",
      "loss: 0.064755  [ 1088/13920]\n",
      "loss: 0.072516  [ 1152/13920]\n",
      "loss: 0.123051  [ 1216/13920]\n",
      "loss: 0.127127  [ 1280/13920]\n",
      "loss: 0.127807  [ 1344/13920]\n",
      "loss: 0.144933  [ 1408/13920]\n",
      "loss: 0.066092  [ 1472/13920]\n",
      "loss: 0.065656  [ 1536/13920]\n",
      "loss: 0.085770  [ 1600/13920]\n",
      "loss: 0.170377  [ 1664/13920]\n",
      "loss: 0.107524  [ 1728/13920]\n",
      "loss: 0.116078  [ 1792/13920]\n",
      "loss: 0.036657  [ 1856/13920]\n",
      "loss: 0.050922  [ 1920/13920]\n",
      "loss: 0.132415  [ 1984/13920]\n",
      "loss: 0.122594  [ 2048/13920]\n",
      "loss: 0.091102  [ 2112/13920]\n",
      "loss: 0.096701  [ 2176/13920]\n",
      "loss: 0.076618  [ 2240/13920]\n",
      "loss: 0.075948  [ 2304/13920]\n",
      "loss: 0.083160  [ 2368/13920]\n",
      "loss: 0.086946  [ 2432/13920]\n",
      "loss: 0.120820  [ 2496/13920]\n",
      "loss: 0.067488  [ 2560/13920]\n",
      "loss: 0.107486  [ 2624/13920]\n",
      "loss: 0.099073  [ 2688/13920]\n",
      "loss: 0.076819  [ 2752/13920]\n",
      "loss: 0.060575  [ 2816/13920]\n",
      "loss: 0.055090  [ 2880/13920]\n",
      "loss: 0.096870  [ 2944/13920]\n",
      "loss: 0.062035  [ 3008/13920]\n",
      "loss: 0.104191  [ 3072/13920]\n",
      "loss: 0.082103  [ 3136/13920]\n",
      "loss: 0.139860  [ 3200/13920]\n",
      "loss: 0.084786  [ 3264/13920]\n",
      "loss: 0.136144  [ 3328/13920]\n",
      "loss: 0.095787  [ 3392/13920]\n",
      "loss: 0.123043  [ 3456/13920]\n",
      "loss: 0.105229  [ 3520/13920]\n",
      "loss: 0.035709  [ 3584/13920]\n",
      "loss: 0.114460  [ 3648/13920]\n",
      "loss: 0.078763  [ 3712/13920]\n",
      "loss: 0.071036  [ 3776/13920]\n",
      "loss: 0.085273  [ 3840/13920]\n",
      "loss: 0.050476  [ 3904/13920]\n",
      "loss: 0.142872  [ 3968/13920]\n",
      "loss: 0.109915  [ 4032/13920]\n",
      "loss: 0.062657  [ 4096/13920]\n",
      "loss: 0.116605  [ 4160/13920]\n",
      "loss: 0.109595  [ 4224/13920]\n",
      "loss: 0.066672  [ 4288/13920]\n",
      "loss: 0.122583  [ 4352/13920]\n",
      "loss: 0.126336  [ 4416/13920]\n",
      "loss: 0.105703  [ 4480/13920]\n",
      "loss: 0.143206  [ 4544/13920]\n",
      "loss: 0.053141  [ 4608/13920]\n",
      "loss: 0.089889  [ 4672/13920]\n",
      "loss: 0.181512  [ 4736/13920]\n",
      "loss: 0.037240  [ 4800/13920]\n",
      "loss: 0.074748  [ 4864/13920]\n",
      "loss: 0.088898  [ 4928/13920]\n",
      "loss: 0.075706  [ 4992/13920]\n",
      "loss: 0.111847  [ 5056/13920]\n",
      "loss: 0.101725  [ 5120/13920]\n",
      "loss: 0.088790  [ 5184/13920]\n",
      "loss: 0.085064  [ 5248/13920]\n",
      "loss: 0.032028  [ 5312/13920]\n",
      "loss: 0.117307  [ 5376/13920]\n",
      "loss: 0.031392  [ 5440/13920]\n",
      "loss: 0.044157  [ 5504/13920]\n",
      "loss: 0.099961  [ 5568/13920]\n",
      "loss: 0.038368  [ 5632/13920]\n",
      "loss: 0.083291  [ 5696/13920]\n",
      "loss: 0.172883  [ 5760/13920]\n",
      "loss: 0.125822  [ 5824/13920]\n",
      "loss: 0.098222  [ 5888/13920]\n",
      "loss: 0.066617  [ 5952/13920]\n",
      "loss: 0.092349  [ 6016/13920]\n",
      "loss: 0.070146  [ 6080/13920]\n",
      "loss: 0.096440  [ 6144/13920]\n",
      "loss: 0.085273  [ 6208/13920]\n",
      "loss: 0.191076  [ 6272/13920]\n",
      "loss: 0.070086  [ 6336/13920]\n",
      "loss: 0.050799  [ 6400/13920]\n",
      "loss: 0.120715  [ 6464/13920]\n",
      "loss: 0.111862  [ 6528/13920]\n",
      "loss: 0.113720  [ 6592/13920]\n",
      "loss: 0.189070  [ 6656/13920]\n",
      "loss: 0.019357  [ 6720/13920]\n",
      "loss: 0.065381  [ 6784/13920]\n",
      "loss: 0.154062  [ 6848/13920]\n",
      "loss: 0.077295  [ 6912/13920]\n",
      "loss: 0.041765  [ 6976/13920]\n",
      "loss: 0.099467  [ 7040/13920]\n",
      "loss: 0.322551  [ 7104/13920]\n",
      "loss: 0.108281  [ 7168/13920]\n",
      "loss: 0.051634  [ 7232/13920]\n",
      "loss: 0.078704  [ 7296/13920]\n",
      "loss: 0.072694  [ 7360/13920]\n",
      "loss: 0.164260  [ 7424/13920]\n",
      "loss: 0.161904  [ 7488/13920]\n",
      "loss: 0.135399  [ 7552/13920]\n",
      "loss: 0.177730  [ 7616/13920]\n",
      "loss: 0.094240  [ 7680/13920]\n",
      "loss: 0.138217  [ 7744/13920]\n",
      "loss: 0.051418  [ 7808/13920]\n",
      "loss: 0.126844  [ 7872/13920]\n",
      "loss: 0.048067  [ 7936/13920]\n",
      "loss: 0.075564  [ 8000/13920]\n",
      "loss: 0.226662  [ 8064/13920]\n",
      "loss: 0.059302  [ 8128/13920]\n",
      "loss: 0.068984  [ 8192/13920]\n",
      "loss: 0.073747  [ 8256/13920]\n",
      "loss: 0.220523  [ 8320/13920]\n",
      "loss: 0.124087  [ 8384/13920]\n",
      "loss: 0.171345  [ 8448/13920]\n",
      "loss: 0.114425  [ 8512/13920]\n",
      "loss: 0.085030  [ 8576/13920]\n",
      "loss: 0.054551  [ 8640/13920]\n",
      "loss: 0.109954  [ 8704/13920]\n",
      "loss: 0.071840  [ 8768/13920]\n",
      "loss: 0.094887  [ 8832/13920]\n",
      "loss: 0.091962  [ 8896/13920]\n",
      "loss: 0.113661  [ 8960/13920]\n",
      "loss: 0.110645  [ 9024/13920]\n",
      "loss: 0.121140  [ 9088/13920]\n",
      "loss: 0.080672  [ 9152/13920]\n",
      "loss: 0.073787  [ 9216/13920]\n",
      "loss: 0.064239  [ 9280/13920]\n",
      "loss: 0.084895  [ 9344/13920]\n",
      "loss: 0.056893  [ 9408/13920]\n",
      "loss: 0.110252  [ 9472/13920]\n",
      "loss: 0.305477  [ 9536/13920]\n",
      "loss: 0.097371  [ 9600/13920]\n",
      "loss: 0.044333  [ 9664/13920]\n",
      "loss: 0.133784  [ 9728/13920]\n",
      "loss: 0.082991  [ 9792/13920]\n",
      "loss: 0.089965  [ 9856/13920]\n",
      "loss: 0.044619  [ 9920/13920]\n",
      "loss: 0.085436  [ 9984/13920]\n",
      "loss: 0.086193  [10048/13920]\n",
      "loss: 0.075152  [10112/13920]\n",
      "loss: 0.084990  [10176/13920]\n",
      "loss: 0.036753  [10240/13920]\n",
      "loss: 0.072788  [10304/13920]\n",
      "loss: 0.024609  [10368/13920]\n",
      "loss: 0.240448  [10432/13920]\n",
      "loss: 0.087278  [10496/13920]\n",
      "loss: 0.053391  [10560/13920]\n",
      "loss: 0.099435  [10624/13920]\n",
      "loss: 0.096152  [10688/13920]\n",
      "loss: 0.055617  [10752/13920]\n",
      "loss: 0.205545  [10816/13920]\n",
      "loss: 0.151920  [10880/13920]\n",
      "loss: 0.082928  [10944/13920]\n",
      "loss: 0.072692  [11008/13920]\n",
      "loss: 0.142317  [11072/13920]\n",
      "loss: 0.115548  [11136/13920]\n",
      "loss: 0.074238  [11200/13920]\n",
      "loss: 0.094767  [11264/13920]\n",
      "loss: 0.072907  [11328/13920]\n",
      "loss: 0.176696  [11392/13920]\n",
      "loss: 0.102776  [11456/13920]\n",
      "loss: 0.097065  [11520/13920]\n",
      "loss: 0.105172  [11584/13920]\n",
      "loss: 0.126502  [11648/13920]\n",
      "loss: 0.099523  [11712/13920]\n",
      "loss: 0.109892  [11776/13920]\n",
      "loss: 0.066373  [11840/13920]\n",
      "loss: 0.171618  [11904/13920]\n",
      "loss: 0.088503  [11968/13920]\n",
      "loss: 0.116326  [12032/13920]\n",
      "loss: 0.043093  [12096/13920]\n",
      "loss: 0.064184  [12160/13920]\n",
      "loss: 0.032000  [12224/13920]\n",
      "loss: 0.018330  [12288/13920]\n",
      "loss: 0.130192  [12352/13920]\n",
      "loss: 0.092374  [12416/13920]\n",
      "loss: 0.108778  [12480/13920]\n",
      "loss: 0.134709  [12544/13920]\n",
      "loss: 0.162515  [12608/13920]\n",
      "loss: 0.081740  [12672/13920]\n",
      "loss: 0.046844  [12736/13920]\n",
      "loss: 0.100144  [12800/13920]\n",
      "loss: 0.091315  [12864/13920]\n",
      "loss: 0.073576  [12928/13920]\n",
      "loss: 0.049948  [12992/13920]\n",
      "loss: 0.175143  [13056/13920]\n",
      "loss: 0.089823  [13120/13920]\n",
      "loss: 0.082992  [13184/13920]\n",
      "loss: 0.061905  [13248/13920]\n",
      "loss: 0.122463  [13312/13920]\n",
      "loss: 0.134989  [13376/13920]\n",
      "loss: 0.055638  [13440/13920]\n",
      "loss: 0.055535  [13504/13920]\n",
      "loss: 0.098744  [13568/13920]\n",
      "loss: 0.085584  [13632/13920]\n",
      "loss: 0.074121  [13696/13920]\n",
      "loss: 0.149539  [13760/13920]\n",
      "loss: 0.124529  [13824/13920]\n",
      "loss: 0.051896  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 96.6% \n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.123889 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.052155  [    0/13920]\n",
      "loss: 0.051028  [   64/13920]\n",
      "loss: 0.042575  [  128/13920]\n",
      "loss: 0.065175  [  192/13920]\n",
      "loss: 0.097866  [  256/13920]\n",
      "loss: 0.133070  [  320/13920]\n",
      "loss: 0.058908  [  384/13920]\n",
      "loss: 0.098444  [  448/13920]\n",
      "loss: 0.087535  [  512/13920]\n",
      "loss: 0.061535  [  576/13920]\n",
      "loss: 0.047681  [  640/13920]\n",
      "loss: 0.075568  [  704/13920]\n",
      "loss: 0.059353  [  768/13920]\n",
      "loss: 0.060549  [  832/13920]\n",
      "loss: 0.079037  [  896/13920]\n",
      "loss: 0.111124  [  960/13920]\n",
      "loss: 0.032807  [ 1024/13920]\n",
      "loss: 0.088086  [ 1088/13920]\n",
      "loss: 0.072918  [ 1152/13920]\n",
      "loss: 0.048431  [ 1216/13920]\n",
      "loss: 0.162941  [ 1280/13920]\n",
      "loss: 0.048852  [ 1344/13920]\n",
      "loss: 0.074176  [ 1408/13920]\n",
      "loss: 0.041051  [ 1472/13920]\n",
      "loss: 0.039362  [ 1536/13920]\n",
      "loss: 0.043296  [ 1600/13920]\n",
      "loss: 0.081646  [ 1664/13920]\n",
      "loss: 0.068126  [ 1728/13920]\n",
      "loss: 0.086921  [ 1792/13920]\n",
      "loss: 0.049191  [ 1856/13920]\n",
      "loss: 0.062629  [ 1920/13920]\n",
      "loss: 0.065180  [ 1984/13920]\n",
      "loss: 0.090932  [ 2048/13920]\n",
      "loss: 0.053115  [ 2112/13920]\n",
      "loss: 0.089249  [ 2176/13920]\n",
      "loss: 0.088886  [ 2240/13920]\n",
      "loss: 0.031984  [ 2304/13920]\n",
      "loss: 0.074971  [ 2368/13920]\n",
      "loss: 0.044267  [ 2432/13920]\n",
      "loss: 0.178813  [ 2496/13920]\n",
      "loss: 0.100013  [ 2560/13920]\n",
      "loss: 0.087299  [ 2624/13920]\n",
      "loss: 0.070801  [ 2688/13920]\n",
      "loss: 0.087111  [ 2752/13920]\n",
      "loss: 0.067961  [ 2816/13920]\n",
      "loss: 0.171877  [ 2880/13920]\n",
      "loss: 0.041559  [ 2944/13920]\n",
      "loss: 0.109983  [ 3008/13920]\n",
      "loss: 0.091912  [ 3072/13920]\n",
      "loss: 0.065832  [ 3136/13920]\n",
      "loss: 0.077907  [ 3200/13920]\n",
      "loss: 0.137112  [ 3264/13920]\n",
      "loss: 0.109180  [ 3328/13920]\n",
      "loss: 0.076189  [ 3392/13920]\n",
      "loss: 0.041827  [ 3456/13920]\n",
      "loss: 0.106251  [ 3520/13920]\n",
      "loss: 0.034836  [ 3584/13920]\n",
      "loss: 0.041082  [ 3648/13920]\n",
      "loss: 0.082334  [ 3712/13920]\n",
      "loss: 0.120480  [ 3776/13920]\n",
      "loss: 0.097812  [ 3840/13920]\n",
      "loss: 0.100608  [ 3904/13920]\n",
      "loss: 0.069019  [ 3968/13920]\n",
      "loss: 0.154404  [ 4032/13920]\n",
      "loss: 0.129709  [ 4096/13920]\n",
      "loss: 0.075964  [ 4160/13920]\n",
      "loss: 0.181579  [ 4224/13920]\n",
      "loss: 0.127408  [ 4288/13920]\n",
      "loss: 0.063042  [ 4352/13920]\n",
      "loss: 0.086314  [ 4416/13920]\n",
      "loss: 0.073710  [ 4480/13920]\n",
      "loss: 0.045990  [ 4544/13920]\n",
      "loss: 0.131454  [ 4608/13920]\n",
      "loss: 0.080009  [ 4672/13920]\n",
      "loss: 0.023150  [ 4736/13920]\n",
      "loss: 0.122414  [ 4800/13920]\n",
      "loss: 0.096280  [ 4864/13920]\n",
      "loss: 0.084203  [ 4928/13920]\n",
      "loss: 0.043396  [ 4992/13920]\n",
      "loss: 0.119455  [ 5056/13920]\n",
      "loss: 0.073640  [ 5120/13920]\n",
      "loss: 0.081199  [ 5184/13920]\n",
      "loss: 0.027218  [ 5248/13920]\n",
      "loss: 0.058890  [ 5312/13920]\n",
      "loss: 0.101632  [ 5376/13920]\n",
      "loss: 0.041687  [ 5440/13920]\n",
      "loss: 0.059094  [ 5504/13920]\n",
      "loss: 0.014009  [ 5568/13920]\n",
      "loss: 0.033329  [ 5632/13920]\n",
      "loss: 0.036443  [ 5696/13920]\n",
      "loss: 0.199251  [ 5760/13920]\n",
      "loss: 0.181712  [ 5824/13920]\n",
      "loss: 0.146092  [ 5888/13920]\n",
      "loss: 0.072723  [ 5952/13920]\n",
      "loss: 0.072340  [ 6016/13920]\n",
      "loss: 0.106971  [ 6080/13920]\n",
      "loss: 0.123591  [ 6144/13920]\n",
      "loss: 0.032950  [ 6208/13920]\n",
      "loss: 0.151064  [ 6272/13920]\n",
      "loss: 0.051430  [ 6336/13920]\n",
      "loss: 0.053059  [ 6400/13920]\n",
      "loss: 0.037637  [ 6464/13920]\n",
      "loss: 0.072391  [ 6528/13920]\n",
      "loss: 0.127926  [ 6592/13920]\n",
      "loss: 0.061042  [ 6656/13920]\n",
      "loss: 0.108496  [ 6720/13920]\n",
      "loss: 0.069172  [ 6784/13920]\n",
      "loss: 0.028621  [ 6848/13920]\n",
      "loss: 0.113099  [ 6912/13920]\n",
      "loss: 0.041992  [ 6976/13920]\n",
      "loss: 0.061349  [ 7040/13920]\n",
      "loss: 0.101512  [ 7104/13920]\n",
      "loss: 0.040366  [ 7168/13920]\n",
      "loss: 0.096535  [ 7232/13920]\n",
      "loss: 0.060441  [ 7296/13920]\n",
      "loss: 0.034272  [ 7360/13920]\n",
      "loss: 0.100596  [ 7424/13920]\n",
      "loss: 0.050338  [ 7488/13920]\n",
      "loss: 0.092449  [ 7552/13920]\n",
      "loss: 0.126390  [ 7616/13920]\n",
      "loss: 0.083482  [ 7680/13920]\n",
      "loss: 0.051378  [ 7744/13920]\n",
      "loss: 0.083946  [ 7808/13920]\n",
      "loss: 0.130449  [ 7872/13920]\n",
      "loss: 0.126008  [ 7936/13920]\n",
      "loss: 0.096181  [ 8000/13920]\n",
      "loss: 0.052345  [ 8064/13920]\n",
      "loss: 0.089637  [ 8128/13920]\n",
      "loss: 0.091740  [ 8192/13920]\n",
      "loss: 0.061003  [ 8256/13920]\n",
      "loss: 0.148820  [ 8320/13920]\n",
      "loss: 0.063601  [ 8384/13920]\n",
      "loss: 0.147495  [ 8448/13920]\n",
      "loss: 0.137822  [ 8512/13920]\n",
      "loss: 0.029880  [ 8576/13920]\n",
      "loss: 0.057776  [ 8640/13920]\n",
      "loss: 0.140498  [ 8704/13920]\n",
      "loss: 0.042210  [ 8768/13920]\n",
      "loss: 0.049609  [ 8832/13920]\n",
      "loss: 0.108665  [ 8896/13920]\n",
      "loss: 0.109784  [ 8960/13920]\n",
      "loss: 0.150675  [ 9024/13920]\n",
      "loss: 0.079703  [ 9088/13920]\n",
      "loss: 0.097904  [ 9152/13920]\n",
      "loss: 0.062945  [ 9216/13920]\n",
      "loss: 0.068128  [ 9280/13920]\n",
      "loss: 0.102724  [ 9344/13920]\n",
      "loss: 0.162500  [ 9408/13920]\n",
      "loss: 0.062417  [ 9472/13920]\n",
      "loss: 0.122501  [ 9536/13920]\n",
      "loss: 0.069035  [ 9600/13920]\n",
      "loss: 0.048669  [ 9664/13920]\n",
      "loss: 0.093502  [ 9728/13920]\n",
      "loss: 0.084110  [ 9792/13920]\n",
      "loss: 0.072084  [ 9856/13920]\n",
      "loss: 0.070377  [ 9920/13920]\n",
      "loss: 0.037589  [ 9984/13920]\n",
      "loss: 0.063812  [10048/13920]\n",
      "loss: 0.060543  [10112/13920]\n",
      "loss: 0.025742  [10176/13920]\n",
      "loss: 0.100015  [10240/13920]\n",
      "loss: 0.053997  [10304/13920]\n",
      "loss: 0.092252  [10368/13920]\n",
      "loss: 0.080919  [10432/13920]\n",
      "loss: 0.044985  [10496/13920]\n",
      "loss: 0.111197  [10560/13920]\n",
      "loss: 0.101544  [10624/13920]\n",
      "loss: 0.045245  [10688/13920]\n",
      "loss: 0.069319  [10752/13920]\n",
      "loss: 0.053506  [10816/13920]\n",
      "loss: 0.059451  [10880/13920]\n",
      "loss: 0.116604  [10944/13920]\n",
      "loss: 0.209958  [11008/13920]\n",
      "loss: 0.082588  [11072/13920]\n",
      "loss: 0.057523  [11136/13920]\n",
      "loss: 0.088271  [11200/13920]\n",
      "loss: 0.131716  [11264/13920]\n",
      "loss: 0.168344  [11328/13920]\n",
      "loss: 0.149356  [11392/13920]\n",
      "loss: 0.098574  [11456/13920]\n",
      "loss: 0.040744  [11520/13920]\n",
      "loss: 0.184790  [11584/13920]\n",
      "loss: 0.045792  [11648/13920]\n",
      "loss: 0.081598  [11712/13920]\n",
      "loss: 0.060057  [11776/13920]\n",
      "loss: 0.116190  [11840/13920]\n",
      "loss: 0.060955  [11904/13920]\n",
      "loss: 0.049160  [11968/13920]\n",
      "loss: 0.074038  [12032/13920]\n",
      "loss: 0.053311  [12096/13920]\n",
      "loss: 0.051601  [12160/13920]\n",
      "loss: 0.106924  [12224/13920]\n",
      "loss: 0.176568  [12288/13920]\n",
      "loss: 0.174780  [12352/13920]\n",
      "loss: 0.016553  [12416/13920]\n",
      "loss: 0.095769  [12480/13920]\n",
      "loss: 0.030514  [12544/13920]\n",
      "loss: 0.042658  [12608/13920]\n",
      "loss: 0.131424  [12672/13920]\n",
      "loss: 0.063440  [12736/13920]\n",
      "loss: 0.063218  [12800/13920]\n",
      "loss: 0.024725  [12864/13920]\n",
      "loss: 0.059698  [12928/13920]\n",
      "loss: 0.031352  [12992/13920]\n",
      "loss: 0.020726  [13056/13920]\n",
      "loss: 0.064900  [13120/13920]\n",
      "loss: 0.031329  [13184/13920]\n",
      "loss: 0.066828  [13248/13920]\n",
      "loss: 0.093376  [13312/13920]\n",
      "loss: 0.101800  [13376/13920]\n",
      "loss: 0.121674  [13440/13920]\n",
      "loss: 0.065243  [13504/13920]\n",
      "loss: 0.075211  [13568/13920]\n",
      "loss: 0.041349  [13632/13920]\n",
      "loss: 0.147613  [13696/13920]\n",
      "loss: 0.020431  [13760/13920]\n",
      "loss: 0.058073  [13824/13920]\n",
      "loss: 0.045947  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.5% \n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.112994 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.130923  [    0/13920]\n",
      "loss: 0.019264  [   64/13920]\n",
      "loss: 0.028715  [  128/13920]\n",
      "loss: 0.097889  [  192/13920]\n",
      "loss: 0.019227  [  256/13920]\n",
      "loss: 0.099403  [  320/13920]\n",
      "loss: 0.046639  [  384/13920]\n",
      "loss: 0.029263  [  448/13920]\n",
      "loss: 0.090743  [  512/13920]\n",
      "loss: 0.018307  [  576/13920]\n",
      "loss: 0.037855  [  640/13920]\n",
      "loss: 0.026202  [  704/13920]\n",
      "loss: 0.136841  [  768/13920]\n",
      "loss: 0.022897  [  832/13920]\n",
      "loss: 0.103703  [  896/13920]\n",
      "loss: 0.037318  [  960/13920]\n",
      "loss: 0.109714  [ 1024/13920]\n",
      "loss: 0.078100  [ 1088/13920]\n",
      "loss: 0.097826  [ 1152/13920]\n",
      "loss: 0.081007  [ 1216/13920]\n",
      "loss: 0.025339  [ 1280/13920]\n",
      "loss: 0.103572  [ 1344/13920]\n",
      "loss: 0.090963  [ 1408/13920]\n",
      "loss: 0.083329  [ 1472/13920]\n",
      "loss: 0.101523  [ 1536/13920]\n",
      "loss: 0.048814  [ 1600/13920]\n",
      "loss: 0.051925  [ 1664/13920]\n",
      "loss: 0.072904  [ 1728/13920]\n",
      "loss: 0.065654  [ 1792/13920]\n",
      "loss: 0.077555  [ 1856/13920]\n",
      "loss: 0.078355  [ 1920/13920]\n",
      "loss: 0.043730  [ 1984/13920]\n",
      "loss: 0.093635  [ 2048/13920]\n",
      "loss: 0.036812  [ 2112/13920]\n",
      "loss: 0.098252  [ 2176/13920]\n",
      "loss: 0.126790  [ 2240/13920]\n",
      "loss: 0.057481  [ 2304/13920]\n",
      "loss: 0.041891  [ 2368/13920]\n",
      "loss: 0.165543  [ 2432/13920]\n",
      "loss: 0.023361  [ 2496/13920]\n",
      "loss: 0.082077  [ 2560/13920]\n",
      "loss: 0.088617  [ 2624/13920]\n",
      "loss: 0.048303  [ 2688/13920]\n",
      "loss: 0.058627  [ 2752/13920]\n",
      "loss: 0.043981  [ 2816/13920]\n",
      "loss: 0.178794  [ 2880/13920]\n",
      "loss: 0.019280  [ 2944/13920]\n",
      "loss: 0.132440  [ 3008/13920]\n",
      "loss: 0.035042  [ 3072/13920]\n",
      "loss: 0.059463  [ 3136/13920]\n",
      "loss: 0.107012  [ 3200/13920]\n",
      "loss: 0.133358  [ 3264/13920]\n",
      "loss: 0.103087  [ 3328/13920]\n",
      "loss: 0.049328  [ 3392/13920]\n",
      "loss: 0.074068  [ 3456/13920]\n",
      "loss: 0.060527  [ 3520/13920]\n",
      "loss: 0.057695  [ 3584/13920]\n",
      "loss: 0.045631  [ 3648/13920]\n",
      "loss: 0.076575  [ 3712/13920]\n",
      "loss: 0.136507  [ 3776/13920]\n",
      "loss: 0.049446  [ 3840/13920]\n",
      "loss: 0.070397  [ 3904/13920]\n",
      "loss: 0.083607  [ 3968/13920]\n",
      "loss: 0.083696  [ 4032/13920]\n",
      "loss: 0.030806  [ 4096/13920]\n",
      "loss: 0.044443  [ 4160/13920]\n",
      "loss: 0.089070  [ 4224/13920]\n",
      "loss: 0.055728  [ 4288/13920]\n",
      "loss: 0.021672  [ 4352/13920]\n",
      "loss: 0.091046  [ 4416/13920]\n",
      "loss: 0.075681  [ 4480/13920]\n",
      "loss: 0.096206  [ 4544/13920]\n",
      "loss: 0.046720  [ 4608/13920]\n",
      "loss: 0.108549  [ 4672/13920]\n",
      "loss: 0.059095  [ 4736/13920]\n",
      "loss: 0.060892  [ 4800/13920]\n",
      "loss: 0.040568  [ 4864/13920]\n",
      "loss: 0.069083  [ 4928/13920]\n",
      "loss: 0.066497  [ 4992/13920]\n",
      "loss: 0.030956  [ 5056/13920]\n",
      "loss: 0.068694  [ 5120/13920]\n",
      "loss: 0.070956  [ 5184/13920]\n",
      "loss: 0.114715  [ 5248/13920]\n",
      "loss: 0.039007  [ 5312/13920]\n",
      "loss: 0.079998  [ 5376/13920]\n",
      "loss: 0.049611  [ 5440/13920]\n",
      "loss: 0.046595  [ 5504/13920]\n",
      "loss: 0.053780  [ 5568/13920]\n",
      "loss: 0.063923  [ 5632/13920]\n",
      "loss: 0.083898  [ 5696/13920]\n",
      "loss: 0.131057  [ 5760/13920]\n",
      "loss: 0.054352  [ 5824/13920]\n",
      "loss: 0.066901  [ 5888/13920]\n",
      "loss: 0.128933  [ 5952/13920]\n",
      "loss: 0.084537  [ 6016/13920]\n",
      "loss: 0.077454  [ 6080/13920]\n",
      "loss: 0.039316  [ 6144/13920]\n",
      "loss: 0.111307  [ 6208/13920]\n",
      "loss: 0.057913  [ 6272/13920]\n",
      "loss: 0.059170  [ 6336/13920]\n",
      "loss: 0.088791  [ 6400/13920]\n",
      "loss: 0.043230  [ 6464/13920]\n",
      "loss: 0.015312  [ 6528/13920]\n",
      "loss: 0.093167  [ 6592/13920]\n",
      "loss: 0.075811  [ 6656/13920]\n",
      "loss: 0.038728  [ 6720/13920]\n",
      "loss: 0.101022  [ 6784/13920]\n",
      "loss: 0.146101  [ 6848/13920]\n",
      "loss: 0.083458  [ 6912/13920]\n",
      "loss: 0.038939  [ 6976/13920]\n",
      "loss: 0.049670  [ 7040/13920]\n",
      "loss: 0.118426  [ 7104/13920]\n",
      "loss: 0.057232  [ 7168/13920]\n",
      "loss: 0.056113  [ 7232/13920]\n",
      "loss: 0.100142  [ 7296/13920]\n",
      "loss: 0.083535  [ 7360/13920]\n",
      "loss: 0.046073  [ 7424/13920]\n",
      "loss: 0.047028  [ 7488/13920]\n",
      "loss: 0.055447  [ 7552/13920]\n",
      "loss: 0.084800  [ 7616/13920]\n",
      "loss: 0.032911  [ 7680/13920]\n",
      "loss: 0.105340  [ 7744/13920]\n",
      "loss: 0.094713  [ 7808/13920]\n",
      "loss: 0.037205  [ 7872/13920]\n",
      "loss: 0.111250  [ 7936/13920]\n",
      "loss: 0.135562  [ 8000/13920]\n",
      "loss: 0.180160  [ 8064/13920]\n",
      "loss: 0.084353  [ 8128/13920]\n",
      "loss: 0.054032  [ 8192/13920]\n",
      "loss: 0.198944  [ 8256/13920]\n",
      "loss: 0.069219  [ 8320/13920]\n",
      "loss: 0.055311  [ 8384/13920]\n",
      "loss: 0.145840  [ 8448/13920]\n",
      "loss: 0.063895  [ 8512/13920]\n",
      "loss: 0.038286  [ 8576/13920]\n",
      "loss: 0.066061  [ 8640/13920]\n",
      "loss: 0.094170  [ 8704/13920]\n",
      "loss: 0.037916  [ 8768/13920]\n",
      "loss: 0.110228  [ 8832/13920]\n",
      "loss: 0.171770  [ 8896/13920]\n",
      "loss: 0.061407  [ 8960/13920]\n",
      "loss: 0.036814  [ 9024/13920]\n",
      "loss: 0.037863  [ 9088/13920]\n",
      "loss: 0.058000  [ 9152/13920]\n",
      "loss: 0.035438  [ 9216/13920]\n",
      "loss: 0.058218  [ 9280/13920]\n",
      "loss: 0.037509  [ 9344/13920]\n",
      "loss: 0.039011  [ 9408/13920]\n",
      "loss: 0.099984  [ 9472/13920]\n",
      "loss: 0.030109  [ 9536/13920]\n",
      "loss: 0.058822  [ 9600/13920]\n",
      "loss: 0.100906  [ 9664/13920]\n",
      "loss: 0.086877  [ 9728/13920]\n",
      "loss: 0.052972  [ 9792/13920]\n",
      "loss: 0.028148  [ 9856/13920]\n",
      "loss: 0.064816  [ 9920/13920]\n",
      "loss: 0.108978  [ 9984/13920]\n",
      "loss: 0.022420  [10048/13920]\n",
      "loss: 0.041042  [10112/13920]\n",
      "loss: 0.058711  [10176/13920]\n",
      "loss: 0.158934  [10240/13920]\n",
      "loss: 0.088959  [10304/13920]\n",
      "loss: 0.138654  [10368/13920]\n",
      "loss: 0.068992  [10432/13920]\n",
      "loss: 0.049843  [10496/13920]\n",
      "loss: 0.070503  [10560/13920]\n",
      "loss: 0.041484  [10624/13920]\n",
      "loss: 0.093080  [10688/13920]\n",
      "loss: 0.043365  [10752/13920]\n",
      "loss: 0.050616  [10816/13920]\n",
      "loss: 0.062249  [10880/13920]\n",
      "loss: 0.075314  [10944/13920]\n",
      "loss: 0.049293  [11008/13920]\n",
      "loss: 0.041234  [11072/13920]\n",
      "loss: 0.089125  [11136/13920]\n",
      "loss: 0.056305  [11200/13920]\n",
      "loss: 0.084225  [11264/13920]\n",
      "loss: 0.045327  [11328/13920]\n",
      "loss: 0.040379  [11392/13920]\n",
      "loss: 0.063878  [11456/13920]\n",
      "loss: 0.053384  [11520/13920]\n",
      "loss: 0.032008  [11584/13920]\n",
      "loss: 0.094978  [11648/13920]\n",
      "loss: 0.059680  [11712/13920]\n",
      "loss: 0.071744  [11776/13920]\n",
      "loss: 0.116876  [11840/13920]\n",
      "loss: 0.066824  [11904/13920]\n",
      "loss: 0.087077  [11968/13920]\n",
      "loss: 0.048159  [12032/13920]\n",
      "loss: 0.093367  [12096/13920]\n",
      "loss: 0.038768  [12160/13920]\n",
      "loss: 0.030187  [12224/13920]\n",
      "loss: 0.079670  [12288/13920]\n",
      "loss: 0.045712  [12352/13920]\n",
      "loss: 0.052690  [12416/13920]\n",
      "loss: 0.172514  [12480/13920]\n",
      "loss: 0.098098  [12544/13920]\n",
      "loss: 0.090619  [12608/13920]\n",
      "loss: 0.021479  [12672/13920]\n",
      "loss: 0.069973  [12736/13920]\n",
      "loss: 0.213729  [12800/13920]\n",
      "loss: 0.020686  [12864/13920]\n",
      "loss: 0.031508  [12928/13920]\n",
      "loss: 0.058543  [12992/13920]\n",
      "loss: 0.089768  [13056/13920]\n",
      "loss: 0.045386  [13120/13920]\n",
      "loss: 0.028652  [13184/13920]\n",
      "loss: 0.078017  [13248/13920]\n",
      "loss: 0.116776  [13312/13920]\n",
      "loss: 0.043098  [13376/13920]\n",
      "loss: 0.067850  [13440/13920]\n",
      "loss: 0.048863  [13504/13920]\n",
      "loss: 0.046970  [13568/13920]\n",
      "loss: 0.072918  [13632/13920]\n",
      "loss: 0.027670  [13696/13920]\n",
      "loss: 0.136451  [13760/13920]\n",
      "loss: 0.077391  [13824/13920]\n",
      "loss: 0.032538  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.6% \n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.109948 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.052454  [    0/13920]\n",
      "loss: 0.059644  [   64/13920]\n",
      "loss: 0.020640  [  128/13920]\n",
      "loss: 0.076545  [  192/13920]\n",
      "loss: 0.061136  [  256/13920]\n",
      "loss: 0.045320  [  320/13920]\n",
      "loss: 0.049723  [  384/13920]\n",
      "loss: 0.068531  [  448/13920]\n",
      "loss: 0.087148  [  512/13920]\n",
      "loss: 0.046309  [  576/13920]\n",
      "loss: 0.133299  [  640/13920]\n",
      "loss: 0.107646  [  704/13920]\n",
      "loss: 0.053294  [  768/13920]\n",
      "loss: 0.015202  [  832/13920]\n",
      "loss: 0.031009  [  896/13920]\n",
      "loss: 0.020623  [  960/13920]\n",
      "loss: 0.040030  [ 1024/13920]\n",
      "loss: 0.044102  [ 1088/13920]\n",
      "loss: 0.025796  [ 1152/13920]\n",
      "loss: 0.029217  [ 1216/13920]\n",
      "loss: 0.057161  [ 1280/13920]\n",
      "loss: 0.069741  [ 1344/13920]\n",
      "loss: 0.051133  [ 1408/13920]\n",
      "loss: 0.076179  [ 1472/13920]\n",
      "loss: 0.036644  [ 1536/13920]\n",
      "loss: 0.023826  [ 1600/13920]\n",
      "loss: 0.142831  [ 1664/13920]\n",
      "loss: 0.065458  [ 1728/13920]\n",
      "loss: 0.020939  [ 1792/13920]\n",
      "loss: 0.056520  [ 1856/13920]\n",
      "loss: 0.060738  [ 1920/13920]\n",
      "loss: 0.033329  [ 1984/13920]\n",
      "loss: 0.027634  [ 2048/13920]\n",
      "loss: 0.048563  [ 2112/13920]\n",
      "loss: 0.045102  [ 2176/13920]\n",
      "loss: 0.032848  [ 2240/13920]\n",
      "loss: 0.125509  [ 2304/13920]\n",
      "loss: 0.123903  [ 2368/13920]\n",
      "loss: 0.039110  [ 2432/13920]\n",
      "loss: 0.072798  [ 2496/13920]\n",
      "loss: 0.053188  [ 2560/13920]\n",
      "loss: 0.088863  [ 2624/13920]\n",
      "loss: 0.026879  [ 2688/13920]\n",
      "loss: 0.043501  [ 2752/13920]\n",
      "loss: 0.026437  [ 2816/13920]\n",
      "loss: 0.075879  [ 2880/13920]\n",
      "loss: 0.082063  [ 2944/13920]\n",
      "loss: 0.067738  [ 3008/13920]\n",
      "loss: 0.148418  [ 3072/13920]\n",
      "loss: 0.092593  [ 3136/13920]\n",
      "loss: 0.044388  [ 3200/13920]\n",
      "loss: 0.026475  [ 3264/13920]\n",
      "loss: 0.033248  [ 3328/13920]\n",
      "loss: 0.047366  [ 3392/13920]\n",
      "loss: 0.076064  [ 3456/13920]\n",
      "loss: 0.021248  [ 3520/13920]\n",
      "loss: 0.043001  [ 3584/13920]\n",
      "loss: 0.057031  [ 3648/13920]\n",
      "loss: 0.057969  [ 3712/13920]\n",
      "loss: 0.051618  [ 3776/13920]\n",
      "loss: 0.076379  [ 3840/13920]\n",
      "loss: 0.024075  [ 3904/13920]\n",
      "loss: 0.043368  [ 3968/13920]\n",
      "loss: 0.039837  [ 4032/13920]\n",
      "loss: 0.027553  [ 4096/13920]\n",
      "loss: 0.089644  [ 4160/13920]\n",
      "loss: 0.045847  [ 4224/13920]\n",
      "loss: 0.114110  [ 4288/13920]\n",
      "loss: 0.154217  [ 4352/13920]\n",
      "loss: 0.073327  [ 4416/13920]\n",
      "loss: 0.062975  [ 4480/13920]\n",
      "loss: 0.022960  [ 4544/13920]\n",
      "loss: 0.034543  [ 4608/13920]\n",
      "loss: 0.076553  [ 4672/13920]\n",
      "loss: 0.110049  [ 4736/13920]\n",
      "loss: 0.054531  [ 4800/13920]\n",
      "loss: 0.079800  [ 4864/13920]\n",
      "loss: 0.036955  [ 4928/13920]\n",
      "loss: 0.099439  [ 4992/13920]\n",
      "loss: 0.080553  [ 5056/13920]\n",
      "loss: 0.016421  [ 5120/13920]\n",
      "loss: 0.079424  [ 5184/13920]\n",
      "loss: 0.062661  [ 5248/13920]\n",
      "loss: 0.051526  [ 5312/13920]\n",
      "loss: 0.069464  [ 5376/13920]\n",
      "loss: 0.143150  [ 5440/13920]\n",
      "loss: 0.060028  [ 5504/13920]\n",
      "loss: 0.036261  [ 5568/13920]\n",
      "loss: 0.078091  [ 5632/13920]\n",
      "loss: 0.044534  [ 5696/13920]\n",
      "loss: 0.036646  [ 5760/13920]\n",
      "loss: 0.081287  [ 5824/13920]\n",
      "loss: 0.049457  [ 5888/13920]\n",
      "loss: 0.015303  [ 5952/13920]\n",
      "loss: 0.038921  [ 6016/13920]\n",
      "loss: 0.026056  [ 6080/13920]\n",
      "loss: 0.026239  [ 6144/13920]\n",
      "loss: 0.089056  [ 6208/13920]\n",
      "loss: 0.050993  [ 6272/13920]\n",
      "loss: 0.029873  [ 6336/13920]\n",
      "loss: 0.064823  [ 6400/13920]\n",
      "loss: 0.058660  [ 6464/13920]\n",
      "loss: 0.028805  [ 6528/13920]\n",
      "loss: 0.041207  [ 6592/13920]\n",
      "loss: 0.058662  [ 6656/13920]\n",
      "loss: 0.048010  [ 6720/13920]\n",
      "loss: 0.015360  [ 6784/13920]\n",
      "loss: 0.021414  [ 6848/13920]\n",
      "loss: 0.043234  [ 6912/13920]\n",
      "loss: 0.075228  [ 6976/13920]\n",
      "loss: 0.040741  [ 7040/13920]\n",
      "loss: 0.011701  [ 7104/13920]\n",
      "loss: 0.082726  [ 7168/13920]\n",
      "loss: 0.039723  [ 7232/13920]\n",
      "loss: 0.083936  [ 7296/13920]\n",
      "loss: 0.073712  [ 7360/13920]\n",
      "loss: 0.085260  [ 7424/13920]\n",
      "loss: 0.029825  [ 7488/13920]\n",
      "loss: 0.038513  [ 7552/13920]\n",
      "loss: 0.070105  [ 7616/13920]\n",
      "loss: 0.032674  [ 7680/13920]\n",
      "loss: 0.032699  [ 7744/13920]\n",
      "loss: 0.061564  [ 7808/13920]\n",
      "loss: 0.039455  [ 7872/13920]\n",
      "loss: 0.013002  [ 7936/13920]\n",
      "loss: 0.037983  [ 8000/13920]\n",
      "loss: 0.034246  [ 8064/13920]\n",
      "loss: 0.033118  [ 8128/13920]\n",
      "loss: 0.036090  [ 8192/13920]\n",
      "loss: 0.076680  [ 8256/13920]\n",
      "loss: 0.062005  [ 8320/13920]\n",
      "loss: 0.031674  [ 8384/13920]\n",
      "loss: 0.040653  [ 8448/13920]\n",
      "loss: 0.123063  [ 8512/13920]\n",
      "loss: 0.041441  [ 8576/13920]\n",
      "loss: 0.060541  [ 8640/13920]\n",
      "loss: 0.248800  [ 8704/13920]\n",
      "loss: 0.100491  [ 8768/13920]\n",
      "loss: 0.042192  [ 8832/13920]\n",
      "loss: 0.023345  [ 8896/13920]\n",
      "loss: 0.052078  [ 8960/13920]\n",
      "loss: 0.014511  [ 9024/13920]\n",
      "loss: 0.066519  [ 9088/13920]\n",
      "loss: 0.052771  [ 9152/13920]\n",
      "loss: 0.044479  [ 9216/13920]\n",
      "loss: 0.081050  [ 9280/13920]\n",
      "loss: 0.086743  [ 9344/13920]\n",
      "loss: 0.032387  [ 9408/13920]\n",
      "loss: 0.082769  [ 9472/13920]\n",
      "loss: 0.014808  [ 9536/13920]\n",
      "loss: 0.019447  [ 9600/13920]\n",
      "loss: 0.045289  [ 9664/13920]\n",
      "loss: 0.027584  [ 9728/13920]\n",
      "loss: 0.027678  [ 9792/13920]\n",
      "loss: 0.139704  [ 9856/13920]\n",
      "loss: 0.045829  [ 9920/13920]\n",
      "loss: 0.137027  [ 9984/13920]\n",
      "loss: 0.060839  [10048/13920]\n",
      "loss: 0.048904  [10112/13920]\n",
      "loss: 0.079885  [10176/13920]\n",
      "loss: 0.048809  [10240/13920]\n",
      "loss: 0.101775  [10304/13920]\n",
      "loss: 0.090017  [10368/13920]\n",
      "loss: 0.096611  [10432/13920]\n",
      "loss: 0.042729  [10496/13920]\n",
      "loss: 0.043597  [10560/13920]\n",
      "loss: 0.072714  [10624/13920]\n",
      "loss: 0.045835  [10688/13920]\n",
      "loss: 0.070766  [10752/13920]\n",
      "loss: 0.043947  [10816/13920]\n",
      "loss: 0.089461  [10880/13920]\n",
      "loss: 0.028096  [10944/13920]\n",
      "loss: 0.078520  [11008/13920]\n",
      "loss: 0.038635  [11072/13920]\n",
      "loss: 0.029655  [11136/13920]\n",
      "loss: 0.035994  [11200/13920]\n",
      "loss: 0.065720  [11264/13920]\n",
      "loss: 0.068451  [11328/13920]\n",
      "loss: 0.032111  [11392/13920]\n",
      "loss: 0.050765  [11456/13920]\n",
      "loss: 0.054025  [11520/13920]\n",
      "loss: 0.039643  [11584/13920]\n",
      "loss: 0.058470  [11648/13920]\n",
      "loss: 0.028598  [11712/13920]\n",
      "loss: 0.057059  [11776/13920]\n",
      "loss: 0.031413  [11840/13920]\n",
      "loss: 0.037918  [11904/13920]\n",
      "loss: 0.038070  [11968/13920]\n",
      "loss: 0.114586  [12032/13920]\n",
      "loss: 0.016136  [12096/13920]\n",
      "loss: 0.025833  [12160/13920]\n",
      "loss: 0.049394  [12224/13920]\n",
      "loss: 0.084482  [12288/13920]\n",
      "loss: 0.062983  [12352/13920]\n",
      "loss: 0.028911  [12416/13920]\n",
      "loss: 0.022687  [12480/13920]\n",
      "loss: 0.080439  [12544/13920]\n",
      "loss: 0.025468  [12608/13920]\n",
      "loss: 0.049271  [12672/13920]\n",
      "loss: 0.142018  [12736/13920]\n",
      "loss: 0.040731  [12800/13920]\n",
      "loss: 0.058949  [12864/13920]\n",
      "loss: 0.105039  [12928/13920]\n",
      "loss: 0.037556  [12992/13920]\n",
      "loss: 0.046615  [13056/13920]\n",
      "loss: 0.112521  [13120/13920]\n",
      "loss: 0.087864  [13184/13920]\n",
      "loss: 0.058180  [13248/13920]\n",
      "loss: 0.066931  [13312/13920]\n",
      "loss: 0.045027  [13376/13920]\n",
      "loss: 0.140617  [13440/13920]\n",
      "loss: 0.046625  [13504/13920]\n",
      "loss: 0.066963  [13568/13920]\n",
      "loss: 0.088395  [13632/13920]\n",
      "loss: 0.019724  [13696/13920]\n",
      "loss: 0.028293  [13760/13920]\n",
      "loss: 0.058875  [13824/13920]\n",
      "loss: 0.076143  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 98.0% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.130761 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.163206  [    0/13920]\n",
      "loss: 1.187279  [   64/13920]\n",
      "loss: 1.067620  [  128/13920]\n",
      "loss: 1.059039  [  192/13920]\n",
      "loss: 1.039824  [  256/13920]\n",
      "loss: 1.129784  [  320/13920]\n",
      "loss: 1.013049  [  384/13920]\n",
      "loss: 0.955603  [  448/13920]\n",
      "loss: 0.912655  [  512/13920]\n",
      "loss: 0.990643  [  576/13920]\n",
      "loss: 1.002136  [  640/13920]\n",
      "loss: 0.949662  [  704/13920]\n",
      "loss: 0.961770  [  768/13920]\n",
      "loss: 1.032893  [  832/13920]\n",
      "loss: 1.011524  [  896/13920]\n",
      "loss: 1.096901  [  960/13920]\n",
      "loss: 0.968528  [ 1024/13920]\n",
      "loss: 1.056588  [ 1088/13920]\n",
      "loss: 0.877263  [ 1152/13920]\n",
      "loss: 0.893403  [ 1216/13920]\n",
      "loss: 0.805672  [ 1280/13920]\n",
      "loss: 0.838294  [ 1344/13920]\n",
      "loss: 0.904853  [ 1408/13920]\n",
      "loss: 0.976001  [ 1472/13920]\n",
      "loss: 0.900003  [ 1536/13920]\n",
      "loss: 0.904426  [ 1600/13920]\n",
      "loss: 0.934786  [ 1664/13920]\n",
      "loss: 0.829074  [ 1728/13920]\n",
      "loss: 0.918531  [ 1792/13920]\n",
      "loss: 0.831448  [ 1856/13920]\n",
      "loss: 0.894781  [ 1920/13920]\n",
      "loss: 0.822197  [ 1984/13920]\n",
      "loss: 0.840975  [ 2048/13920]\n",
      "loss: 0.877201  [ 2112/13920]\n",
      "loss: 0.760001  [ 2176/13920]\n",
      "loss: 0.904660  [ 2240/13920]\n",
      "loss: 0.725885  [ 2304/13920]\n",
      "loss: 0.767232  [ 2368/13920]\n",
      "loss: 0.913072  [ 2432/13920]\n",
      "loss: 0.793031  [ 2496/13920]\n",
      "loss: 0.795561  [ 2560/13920]\n",
      "loss: 0.867373  [ 2624/13920]\n",
      "loss: 0.798056  [ 2688/13920]\n",
      "loss: 0.720439  [ 2752/13920]\n",
      "loss: 0.858446  [ 2816/13920]\n",
      "loss: 0.913060  [ 2880/13920]\n",
      "loss: 0.944072  [ 2944/13920]\n",
      "loss: 0.761687  [ 3008/13920]\n",
      "loss: 0.829960  [ 3072/13920]\n",
      "loss: 0.636585  [ 3136/13920]\n",
      "loss: 0.671122  [ 3200/13920]\n",
      "loss: 0.852482  [ 3264/13920]\n",
      "loss: 0.693502  [ 3328/13920]\n",
      "loss: 0.750674  [ 3392/13920]\n",
      "loss: 0.871786  [ 3456/13920]\n",
      "loss: 0.752659  [ 3520/13920]\n",
      "loss: 0.686714  [ 3584/13920]\n",
      "loss: 0.831440  [ 3648/13920]\n",
      "loss: 0.802544  [ 3712/13920]\n",
      "loss: 0.719185  [ 3776/13920]\n",
      "loss: 0.676862  [ 3840/13920]\n",
      "loss: 0.723774  [ 3904/13920]\n",
      "loss: 0.695390  [ 3968/13920]\n",
      "loss: 0.732171  [ 4032/13920]\n",
      "loss: 0.833216  [ 4096/13920]\n",
      "loss: 0.775412  [ 4160/13920]\n",
      "loss: 0.685937  [ 4224/13920]\n",
      "loss: 0.760858  [ 4288/13920]\n",
      "loss: 0.793332  [ 4352/13920]\n",
      "loss: 0.593241  [ 4416/13920]\n",
      "loss: 0.780001  [ 4480/13920]\n",
      "loss: 0.584111  [ 4544/13920]\n",
      "loss: 0.778659  [ 4608/13920]\n",
      "loss: 0.679641  [ 4672/13920]\n",
      "loss: 0.781434  [ 4736/13920]\n",
      "loss: 0.606031  [ 4800/13920]\n",
      "loss: 0.657433  [ 4864/13920]\n",
      "loss: 0.687487  [ 4928/13920]\n",
      "loss: 0.657529  [ 4992/13920]\n",
      "loss: 0.758804  [ 5056/13920]\n",
      "loss: 0.644539  [ 5120/13920]\n",
      "loss: 0.729611  [ 5184/13920]\n",
      "loss: 0.792328  [ 5248/13920]\n",
      "loss: 0.712281  [ 5312/13920]\n",
      "loss: 0.661499  [ 5376/13920]\n",
      "loss: 0.682493  [ 5440/13920]\n",
      "loss: 0.535566  [ 5504/13920]\n",
      "loss: 0.688352  [ 5568/13920]\n",
      "loss: 0.662820  [ 5632/13920]\n",
      "loss: 0.700739  [ 5696/13920]\n",
      "loss: 0.681878  [ 5760/13920]\n",
      "loss: 0.754326  [ 5824/13920]\n",
      "loss: 0.705303  [ 5888/13920]\n",
      "loss: 0.720123  [ 5952/13920]\n",
      "loss: 0.762090  [ 6016/13920]\n",
      "loss: 0.690412  [ 6080/13920]\n",
      "loss: 0.647611  [ 6144/13920]\n",
      "loss: 0.619863  [ 6208/13920]\n",
      "loss: 0.743852  [ 6272/13920]\n",
      "loss: 0.670087  [ 6336/13920]\n",
      "loss: 0.684669  [ 6400/13920]\n",
      "loss: 0.643934  [ 6464/13920]\n",
      "loss: 0.702401  [ 6528/13920]\n",
      "loss: 0.684102  [ 6592/13920]\n",
      "loss: 0.656968  [ 6656/13920]\n",
      "loss: 0.616199  [ 6720/13920]\n",
      "loss: 0.773038  [ 6784/13920]\n",
      "loss: 0.549407  [ 6848/13920]\n",
      "loss: 0.634103  [ 6912/13920]\n",
      "loss: 0.595651  [ 6976/13920]\n",
      "loss: 0.795276  [ 7040/13920]\n",
      "loss: 0.647120  [ 7104/13920]\n",
      "loss: 0.665227  [ 7168/13920]\n",
      "loss: 0.586510  [ 7232/13920]\n",
      "loss: 0.661310  [ 7296/13920]\n",
      "loss: 0.614877  [ 7360/13920]\n",
      "loss: 0.627865  [ 7424/13920]\n",
      "loss: 0.677671  [ 7488/13920]\n",
      "loss: 0.639331  [ 7552/13920]\n",
      "loss: 0.800420  [ 7616/13920]\n",
      "loss: 0.593515  [ 7680/13920]\n",
      "loss: 0.648360  [ 7744/13920]\n",
      "loss: 0.549368  [ 7808/13920]\n",
      "loss: 0.621646  [ 7872/13920]\n",
      "loss: 0.639495  [ 7936/13920]\n",
      "loss: 0.611139  [ 8000/13920]\n",
      "loss: 0.589499  [ 8064/13920]\n",
      "loss: 0.685075  [ 8128/13920]\n",
      "loss: 0.689688  [ 8192/13920]\n",
      "loss: 0.621224  [ 8256/13920]\n",
      "loss: 0.640697  [ 8320/13920]\n",
      "loss: 0.618473  [ 8384/13920]\n",
      "loss: 0.630897  [ 8448/13920]\n",
      "loss: 0.620068  [ 8512/13920]\n",
      "loss: 0.699862  [ 8576/13920]\n",
      "loss: 0.535408  [ 8640/13920]\n",
      "loss: 0.587255  [ 8704/13920]\n",
      "loss: 0.748081  [ 8768/13920]\n",
      "loss: 0.774209  [ 8832/13920]\n",
      "loss: 0.504088  [ 8896/13920]\n",
      "loss: 0.542314  [ 8960/13920]\n",
      "loss: 0.588882  [ 9024/13920]\n",
      "loss: 0.674764  [ 9088/13920]\n",
      "loss: 0.678151  [ 9152/13920]\n",
      "loss: 0.514101  [ 9216/13920]\n",
      "loss: 0.545536  [ 9280/13920]\n",
      "loss: 0.702881  [ 9344/13920]\n",
      "loss: 0.550734  [ 9408/13920]\n",
      "loss: 0.526161  [ 9472/13920]\n",
      "loss: 0.576276  [ 9536/13920]\n",
      "loss: 0.605551  [ 9600/13920]\n",
      "loss: 0.678546  [ 9664/13920]\n",
      "loss: 0.559964  [ 9728/13920]\n",
      "loss: 0.718587  [ 9792/13920]\n",
      "loss: 0.636328  [ 9856/13920]\n",
      "loss: 0.676772  [ 9920/13920]\n",
      "loss: 0.548705  [ 9984/13920]\n",
      "loss: 0.570991  [10048/13920]\n",
      "loss: 0.732497  [10112/13920]\n",
      "loss: 0.503762  [10176/13920]\n",
      "loss: 0.496381  [10240/13920]\n",
      "loss: 0.566671  [10304/13920]\n",
      "loss: 0.555531  [10368/13920]\n",
      "loss: 0.523541  [10432/13920]\n",
      "loss: 0.546877  [10496/13920]\n",
      "loss: 0.575011  [10560/13920]\n",
      "loss: 0.382327  [10624/13920]\n",
      "loss: 0.641946  [10688/13920]\n",
      "loss: 0.564701  [10752/13920]\n",
      "loss: 0.613088  [10816/13920]\n",
      "loss: 0.583376  [10880/13920]\n",
      "loss: 0.484430  [10944/13920]\n",
      "loss: 0.601497  [11008/13920]\n",
      "loss: 0.439589  [11072/13920]\n",
      "loss: 0.554953  [11136/13920]\n",
      "loss: 0.702978  [11200/13920]\n",
      "loss: 0.565326  [11264/13920]\n",
      "loss: 0.600120  [11328/13920]\n",
      "loss: 0.530346  [11392/13920]\n",
      "loss: 0.649859  [11456/13920]\n",
      "loss: 0.473720  [11520/13920]\n",
      "loss: 0.581159  [11584/13920]\n",
      "loss: 0.578264  [11648/13920]\n",
      "loss: 0.428719  [11712/13920]\n",
      "loss: 0.534868  [11776/13920]\n",
      "loss: 0.557927  [11840/13920]\n",
      "loss: 0.504451  [11904/13920]\n",
      "loss: 0.521721  [11968/13920]\n",
      "loss: 0.465771  [12032/13920]\n",
      "loss: 0.492748  [12096/13920]\n",
      "loss: 0.579723  [12160/13920]\n",
      "loss: 0.389321  [12224/13920]\n",
      "loss: 0.566902  [12288/13920]\n",
      "loss: 0.679247  [12352/13920]\n",
      "loss: 0.517315  [12416/13920]\n",
      "loss: 0.676789  [12480/13920]\n",
      "loss: 0.419183  [12544/13920]\n",
      "loss: 0.527420  [12608/13920]\n",
      "loss: 0.463310  [12672/13920]\n",
      "loss: 0.596704  [12736/13920]\n",
      "loss: 0.454834  [12800/13920]\n",
      "loss: 0.433496  [12864/13920]\n",
      "loss: 0.523807  [12928/13920]\n",
      "loss: 0.478673  [12992/13920]\n",
      "loss: 0.502295  [13056/13920]\n",
      "loss: 0.549459  [13120/13920]\n",
      "loss: 0.503002  [13184/13920]\n",
      "loss: 0.510697  [13248/13920]\n",
      "loss: 0.460325  [13312/13920]\n",
      "loss: 0.571979  [13376/13920]\n",
      "loss: 0.447035  [13440/13920]\n",
      "loss: 0.381623  [13504/13920]\n",
      "loss: 0.455798  [13568/13920]\n",
      "loss: 0.399701  [13632/13920]\n",
      "loss: 0.509962  [13696/13920]\n",
      "loss: 0.514853  [13760/13920]\n",
      "loss: 0.428576  [13824/13920]\n",
      "loss: 0.342958  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 70.8% \n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.496752 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.502159  [    0/13920]\n",
      "loss: 0.381716  [   64/13920]\n",
      "loss: 0.432818  [  128/13920]\n",
      "loss: 0.440670  [  192/13920]\n",
      "loss: 0.466843  [  256/13920]\n",
      "loss: 0.401341  [  320/13920]\n",
      "loss: 0.387376  [  384/13920]\n",
      "loss: 0.389035  [  448/13920]\n",
      "loss: 0.547398  [  512/13920]\n",
      "loss: 0.521139  [  576/13920]\n",
      "loss: 0.443504  [  640/13920]\n",
      "loss: 0.408641  [  704/13920]\n",
      "loss: 0.381368  [  768/13920]\n",
      "loss: 0.588973  [  832/13920]\n",
      "loss: 0.361877  [  896/13920]\n",
      "loss: 0.590803  [  960/13920]\n",
      "loss: 0.438348  [ 1024/13920]\n",
      "loss: 0.319268  [ 1088/13920]\n",
      "loss: 0.515326  [ 1152/13920]\n",
      "loss: 0.505507  [ 1216/13920]\n",
      "loss: 0.450742  [ 1280/13920]\n",
      "loss: 0.407225  [ 1344/13920]\n",
      "loss: 0.419271  [ 1408/13920]\n",
      "loss: 0.468344  [ 1472/13920]\n",
      "loss: 0.430204  [ 1536/13920]\n",
      "loss: 0.505165  [ 1600/13920]\n",
      "loss: 0.406983  [ 1664/13920]\n",
      "loss: 0.429422  [ 1728/13920]\n",
      "loss: 0.659669  [ 1792/13920]\n",
      "loss: 0.420890  [ 1856/13920]\n",
      "loss: 0.352813  [ 1920/13920]\n",
      "loss: 0.493317  [ 1984/13920]\n",
      "loss: 0.446992  [ 2048/13920]\n",
      "loss: 0.353706  [ 2112/13920]\n",
      "loss: 0.422257  [ 2176/13920]\n",
      "loss: 0.346368  [ 2240/13920]\n",
      "loss: 0.354758  [ 2304/13920]\n",
      "loss: 0.499231  [ 2368/13920]\n",
      "loss: 0.371167  [ 2432/13920]\n",
      "loss: 0.648177  [ 2496/13920]\n",
      "loss: 0.354620  [ 2560/13920]\n",
      "loss: 0.375897  [ 2624/13920]\n",
      "loss: 0.516002  [ 2688/13920]\n",
      "loss: 0.505170  [ 2752/13920]\n",
      "loss: 0.544046  [ 2816/13920]\n",
      "loss: 0.354889  [ 2880/13920]\n",
      "loss: 0.395476  [ 2944/13920]\n",
      "loss: 0.395836  [ 3008/13920]\n",
      "loss: 0.500755  [ 3072/13920]\n",
      "loss: 0.597164  [ 3136/13920]\n",
      "loss: 0.439476  [ 3200/13920]\n",
      "loss: 0.382338  [ 3264/13920]\n",
      "loss: 0.481804  [ 3328/13920]\n",
      "loss: 0.487675  [ 3392/13920]\n",
      "loss: 0.320032  [ 3456/13920]\n",
      "loss: 0.618272  [ 3520/13920]\n",
      "loss: 0.408916  [ 3584/13920]\n",
      "loss: 0.558930  [ 3648/13920]\n",
      "loss: 0.633603  [ 3712/13920]\n",
      "loss: 0.400676  [ 3776/13920]\n",
      "loss: 0.421588  [ 3840/13920]\n",
      "loss: 0.416207  [ 3904/13920]\n",
      "loss: 0.380518  [ 3968/13920]\n",
      "loss: 0.406640  [ 4032/13920]\n",
      "loss: 0.466089  [ 4096/13920]\n",
      "loss: 0.324058  [ 4160/13920]\n",
      "loss: 0.376958  [ 4224/13920]\n",
      "loss: 0.381909  [ 4288/13920]\n",
      "loss: 0.342893  [ 4352/13920]\n",
      "loss: 0.352347  [ 4416/13920]\n",
      "loss: 0.493953  [ 4480/13920]\n",
      "loss: 0.411347  [ 4544/13920]\n",
      "loss: 0.347409  [ 4608/13920]\n",
      "loss: 0.410935  [ 4672/13920]\n",
      "loss: 0.542958  [ 4736/13920]\n",
      "loss: 0.358570  [ 4800/13920]\n",
      "loss: 0.290219  [ 4864/13920]\n",
      "loss: 0.418706  [ 4928/13920]\n",
      "loss: 0.441754  [ 4992/13920]\n",
      "loss: 0.295502  [ 5056/13920]\n",
      "loss: 0.391798  [ 5120/13920]\n",
      "loss: 0.482277  [ 5184/13920]\n",
      "loss: 0.366305  [ 5248/13920]\n",
      "loss: 0.402762  [ 5312/13920]\n",
      "loss: 0.447671  [ 5376/13920]\n",
      "loss: 0.577309  [ 5440/13920]\n",
      "loss: 0.408279  [ 5504/13920]\n",
      "loss: 0.386783  [ 5568/13920]\n",
      "loss: 0.333369  [ 5632/13920]\n",
      "loss: 0.406084  [ 5696/13920]\n",
      "loss: 0.455669  [ 5760/13920]\n",
      "loss: 0.451702  [ 5824/13920]\n",
      "loss: 0.300271  [ 5888/13920]\n",
      "loss: 0.427718  [ 5952/13920]\n",
      "loss: 0.613598  [ 6016/13920]\n",
      "loss: 0.378601  [ 6080/13920]\n",
      "loss: 0.332588  [ 6144/13920]\n",
      "loss: 0.480712  [ 6208/13920]\n",
      "loss: 0.444016  [ 6272/13920]\n",
      "loss: 0.391602  [ 6336/13920]\n",
      "loss: 0.339175  [ 6400/13920]\n",
      "loss: 0.352716  [ 6464/13920]\n",
      "loss: 0.526505  [ 6528/13920]\n",
      "loss: 0.397789  [ 6592/13920]\n",
      "loss: 0.372047  [ 6656/13920]\n",
      "loss: 0.379088  [ 6720/13920]\n",
      "loss: 0.404486  [ 6784/13920]\n",
      "loss: 0.345267  [ 6848/13920]\n",
      "loss: 0.349358  [ 6912/13920]\n",
      "loss: 0.407070  [ 6976/13920]\n",
      "loss: 0.452811  [ 7040/13920]\n",
      "loss: 0.315823  [ 7104/13920]\n",
      "loss: 0.364424  [ 7168/13920]\n",
      "loss: 0.359637  [ 7232/13920]\n",
      "loss: 0.513562  [ 7296/13920]\n",
      "loss: 0.323945  [ 7360/13920]\n",
      "loss: 0.543743  [ 7424/13920]\n",
      "loss: 0.399438  [ 7488/13920]\n",
      "loss: 0.412388  [ 7552/13920]\n",
      "loss: 0.277453  [ 7616/13920]\n",
      "loss: 0.325249  [ 7680/13920]\n",
      "loss: 0.343852  [ 7744/13920]\n",
      "loss: 0.293207  [ 7808/13920]\n",
      "loss: 0.347508  [ 7872/13920]\n",
      "loss: 0.325172  [ 7936/13920]\n",
      "loss: 0.309758  [ 8000/13920]\n",
      "loss: 0.417581  [ 8064/13920]\n",
      "loss: 0.470182  [ 8128/13920]\n",
      "loss: 0.465117  [ 8192/13920]\n",
      "loss: 0.373955  [ 8256/13920]\n",
      "loss: 0.289624  [ 8320/13920]\n",
      "loss: 0.336720  [ 8384/13920]\n",
      "loss: 0.473964  [ 8448/13920]\n",
      "loss: 0.299248  [ 8512/13920]\n",
      "loss: 0.315747  [ 8576/13920]\n",
      "loss: 0.345930  [ 8640/13920]\n",
      "loss: 0.410601  [ 8704/13920]\n",
      "loss: 0.401709  [ 8768/13920]\n",
      "loss: 0.333331  [ 8832/13920]\n",
      "loss: 0.379563  [ 8896/13920]\n",
      "loss: 0.317941  [ 8960/13920]\n",
      "loss: 0.385406  [ 9024/13920]\n",
      "loss: 0.250450  [ 9088/13920]\n",
      "loss: 0.494285  [ 9152/13920]\n",
      "loss: 0.405271  [ 9216/13920]\n",
      "loss: 0.450427  [ 9280/13920]\n",
      "loss: 0.382503  [ 9344/13920]\n",
      "loss: 0.356571  [ 9408/13920]\n",
      "loss: 0.303281  [ 9472/13920]\n",
      "loss: 0.429488  [ 9536/13920]\n",
      "loss: 0.336716  [ 9600/13920]\n",
      "loss: 0.394575  [ 9664/13920]\n",
      "loss: 0.274104  [ 9728/13920]\n",
      "loss: 0.252118  [ 9792/13920]\n",
      "loss: 0.407864  [ 9856/13920]\n",
      "loss: 0.347249  [ 9920/13920]\n",
      "loss: 0.265000  [ 9984/13920]\n",
      "loss: 0.372271  [10048/13920]\n",
      "loss: 0.359281  [10112/13920]\n",
      "loss: 0.469351  [10176/13920]\n",
      "loss: 0.229339  [10240/13920]\n",
      "loss: 0.425197  [10304/13920]\n",
      "loss: 0.391842  [10368/13920]\n",
      "loss: 0.283749  [10432/13920]\n",
      "loss: 0.366124  [10496/13920]\n",
      "loss: 0.278405  [10560/13920]\n",
      "loss: 0.514548  [10624/13920]\n",
      "loss: 0.308276  [10688/13920]\n",
      "loss: 0.347920  [10752/13920]\n",
      "loss: 0.463724  [10816/13920]\n",
      "loss: 0.477497  [10880/13920]\n",
      "loss: 0.333445  [10944/13920]\n",
      "loss: 0.437941  [11008/13920]\n",
      "loss: 0.349784  [11072/13920]\n",
      "loss: 0.297358  [11136/13920]\n",
      "loss: 0.314240  [11200/13920]\n",
      "loss: 0.295432  [11264/13920]\n",
      "loss: 0.348148  [11328/13920]\n",
      "loss: 0.400731  [11392/13920]\n",
      "loss: 0.441493  [11456/13920]\n",
      "loss: 0.288214  [11520/13920]\n",
      "loss: 0.322278  [11584/13920]\n",
      "loss: 0.360014  [11648/13920]\n",
      "loss: 0.264154  [11712/13920]\n",
      "loss: 0.317584  [11776/13920]\n",
      "loss: 0.422036  [11840/13920]\n",
      "loss: 0.466539  [11904/13920]\n",
      "loss: 0.327449  [11968/13920]\n",
      "loss: 0.280083  [12032/13920]\n",
      "loss: 0.296639  [12096/13920]\n",
      "loss: 0.313666  [12160/13920]\n",
      "loss: 0.335355  [12224/13920]\n",
      "loss: 0.271014  [12288/13920]\n",
      "loss: 0.370267  [12352/13920]\n",
      "loss: 0.470183  [12416/13920]\n",
      "loss: 0.306685  [12480/13920]\n",
      "loss: 0.338173  [12544/13920]\n",
      "loss: 0.463434  [12608/13920]\n",
      "loss: 0.302607  [12672/13920]\n",
      "loss: 0.495804  [12736/13920]\n",
      "loss: 0.324046  [12800/13920]\n",
      "loss: 0.248529  [12864/13920]\n",
      "loss: 0.276501  [12928/13920]\n",
      "loss: 0.268260  [12992/13920]\n",
      "loss: 0.348741  [13056/13920]\n",
      "loss: 0.394903  [13120/13920]\n",
      "loss: 0.197990  [13184/13920]\n",
      "loss: 0.300186  [13248/13920]\n",
      "loss: 0.268988  [13312/13920]\n",
      "loss: 0.293733  [13376/13920]\n",
      "loss: 0.334725  [13440/13920]\n",
      "loss: 0.378085  [13504/13920]\n",
      "loss: 0.335285  [13568/13920]\n",
      "loss: 0.245902  [13632/13920]\n",
      "loss: 0.390931  [13696/13920]\n",
      "loss: 0.338334  [13760/13920]\n",
      "loss: 0.438180  [13824/13920]\n",
      "loss: 0.188786  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 85.9% \n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.310617 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.344683  [    0/13920]\n",
      "loss: 0.341547  [   64/13920]\n",
      "loss: 0.256656  [  128/13920]\n",
      "loss: 0.216922  [  192/13920]\n",
      "loss: 0.440208  [  256/13920]\n",
      "loss: 0.372203  [  320/13920]\n",
      "loss: 0.318734  [  384/13920]\n",
      "loss: 0.201126  [  448/13920]\n",
      "loss: 0.316327  [  512/13920]\n",
      "loss: 0.216333  [  576/13920]\n",
      "loss: 0.279489  [  640/13920]\n",
      "loss: 0.258927  [  704/13920]\n",
      "loss: 0.298767  [  768/13920]\n",
      "loss: 0.290109  [  832/13920]\n",
      "loss: 0.272139  [  896/13920]\n",
      "loss: 0.335652  [  960/13920]\n",
      "loss: 0.327572  [ 1024/13920]\n",
      "loss: 0.288079  [ 1088/13920]\n",
      "loss: 0.287762  [ 1152/13920]\n",
      "loss: 0.458243  [ 1216/13920]\n",
      "loss: 0.296636  [ 1280/13920]\n",
      "loss: 0.314969  [ 1344/13920]\n",
      "loss: 0.448294  [ 1408/13920]\n",
      "loss: 0.377404  [ 1472/13920]\n",
      "loss: 0.244350  [ 1536/13920]\n",
      "loss: 0.239399  [ 1600/13920]\n",
      "loss: 0.205138  [ 1664/13920]\n",
      "loss: 0.300780  [ 1728/13920]\n",
      "loss: 0.311603  [ 1792/13920]\n",
      "loss: 0.193658  [ 1856/13920]\n",
      "loss: 0.269675  [ 1920/13920]\n",
      "loss: 0.190251  [ 1984/13920]\n",
      "loss: 0.325547  [ 2048/13920]\n",
      "loss: 0.258951  [ 2112/13920]\n",
      "loss: 0.235968  [ 2176/13920]\n",
      "loss: 0.179812  [ 2240/13920]\n",
      "loss: 0.385065  [ 2304/13920]\n",
      "loss: 0.266892  [ 2368/13920]\n",
      "loss: 0.319854  [ 2432/13920]\n",
      "loss: 0.357766  [ 2496/13920]\n",
      "loss: 0.259518  [ 2560/13920]\n",
      "loss: 0.291570  [ 2624/13920]\n",
      "loss: 0.314264  [ 2688/13920]\n",
      "loss: 0.271621  [ 2752/13920]\n",
      "loss: 0.285690  [ 2816/13920]\n",
      "loss: 0.252173  [ 2880/13920]\n",
      "loss: 0.197447  [ 2944/13920]\n",
      "loss: 0.258161  [ 3008/13920]\n",
      "loss: 0.445091  [ 3072/13920]\n",
      "loss: 0.267058  [ 3136/13920]\n",
      "loss: 0.277934  [ 3200/13920]\n",
      "loss: 0.341105  [ 3264/13920]\n",
      "loss: 0.242248  [ 3328/13920]\n",
      "loss: 0.298041  [ 3392/13920]\n",
      "loss: 0.339866  [ 3456/13920]\n",
      "loss: 0.249149  [ 3520/13920]\n",
      "loss: 0.349845  [ 3584/13920]\n",
      "loss: 0.212178  [ 3648/13920]\n",
      "loss: 0.224312  [ 3712/13920]\n",
      "loss: 0.279122  [ 3776/13920]\n",
      "loss: 0.264535  [ 3840/13920]\n",
      "loss: 0.366156  [ 3904/13920]\n",
      "loss: 0.228475  [ 3968/13920]\n",
      "loss: 0.334905  [ 4032/13920]\n",
      "loss: 0.273327  [ 4096/13920]\n",
      "loss: 0.324372  [ 4160/13920]\n",
      "loss: 0.322500  [ 4224/13920]\n",
      "loss: 0.280203  [ 4288/13920]\n",
      "loss: 0.252632  [ 4352/13920]\n",
      "loss: 0.282139  [ 4416/13920]\n",
      "loss: 0.250081  [ 4480/13920]\n",
      "loss: 0.328500  [ 4544/13920]\n",
      "loss: 0.205549  [ 4608/13920]\n",
      "loss: 0.308288  [ 4672/13920]\n",
      "loss: 0.248792  [ 4736/13920]\n",
      "loss: 0.312839  [ 4800/13920]\n",
      "loss: 0.302239  [ 4864/13920]\n",
      "loss: 0.266343  [ 4928/13920]\n",
      "loss: 0.379926  [ 4992/13920]\n",
      "loss: 0.231129  [ 5056/13920]\n",
      "loss: 0.262021  [ 5120/13920]\n",
      "loss: 0.234738  [ 5184/13920]\n",
      "loss: 0.196339  [ 5248/13920]\n",
      "loss: 0.244970  [ 5312/13920]\n",
      "loss: 0.348300  [ 5376/13920]\n",
      "loss: 0.178315  [ 5440/13920]\n",
      "loss: 0.193541  [ 5504/13920]\n",
      "loss: 0.253893  [ 5568/13920]\n",
      "loss: 0.259976  [ 5632/13920]\n",
      "loss: 0.123288  [ 5696/13920]\n",
      "loss: 0.203310  [ 5760/13920]\n",
      "loss: 0.253457  [ 5824/13920]\n",
      "loss: 0.200512  [ 5888/13920]\n",
      "loss: 0.232877  [ 5952/13920]\n",
      "loss: 0.411993  [ 6016/13920]\n",
      "loss: 0.220114  [ 6080/13920]\n",
      "loss: 0.388931  [ 6144/13920]\n",
      "loss: 0.410130  [ 6208/13920]\n",
      "loss: 0.191535  [ 6272/13920]\n",
      "loss: 0.356321  [ 6336/13920]\n",
      "loss: 0.217001  [ 6400/13920]\n",
      "loss: 0.255574  [ 6464/13920]\n",
      "loss: 0.280514  [ 6528/13920]\n",
      "loss: 0.279571  [ 6592/13920]\n",
      "loss: 0.218147  [ 6656/13920]\n",
      "loss: 0.324365  [ 6720/13920]\n",
      "loss: 0.253748  [ 6784/13920]\n",
      "loss: 0.223458  [ 6848/13920]\n",
      "loss: 0.211130  [ 6912/13920]\n",
      "loss: 0.211869  [ 6976/13920]\n",
      "loss: 0.253105  [ 7040/13920]\n",
      "loss: 0.213317  [ 7104/13920]\n",
      "loss: 0.277130  [ 7168/13920]\n",
      "loss: 0.361107  [ 7232/13920]\n",
      "loss: 0.259124  [ 7296/13920]\n",
      "loss: 0.224875  [ 7360/13920]\n",
      "loss: 0.282095  [ 7424/13920]\n",
      "loss: 0.393646  [ 7488/13920]\n",
      "loss: 0.238135  [ 7552/13920]\n",
      "loss: 0.354444  [ 7616/13920]\n",
      "loss: 0.191559  [ 7680/13920]\n",
      "loss: 0.224876  [ 7744/13920]\n",
      "loss: 0.216749  [ 7808/13920]\n",
      "loss: 0.312380  [ 7872/13920]\n",
      "loss: 0.171769  [ 7936/13920]\n",
      "loss: 0.344408  [ 8000/13920]\n",
      "loss: 0.213345  [ 8064/13920]\n",
      "loss: 0.332308  [ 8128/13920]\n",
      "loss: 0.303669  [ 8192/13920]\n",
      "loss: 0.222151  [ 8256/13920]\n",
      "loss: 0.268160  [ 8320/13920]\n",
      "loss: 0.260847  [ 8384/13920]\n",
      "loss: 0.197837  [ 8448/13920]\n",
      "loss: 0.285580  [ 8512/13920]\n",
      "loss: 0.170037  [ 8576/13920]\n",
      "loss: 0.282773  [ 8640/13920]\n",
      "loss: 0.339123  [ 8704/13920]\n",
      "loss: 0.335006  [ 8768/13920]\n",
      "loss: 0.377101  [ 8832/13920]\n",
      "loss: 0.322742  [ 8896/13920]\n",
      "loss: 0.349092  [ 8960/13920]\n",
      "loss: 0.146746  [ 9024/13920]\n",
      "loss: 0.143925  [ 9088/13920]\n",
      "loss: 0.215966  [ 9152/13920]\n",
      "loss: 0.267065  [ 9216/13920]\n",
      "loss: 0.315910  [ 9280/13920]\n",
      "loss: 0.166803  [ 9344/13920]\n",
      "loss: 0.253526  [ 9408/13920]\n",
      "loss: 0.353692  [ 9472/13920]\n",
      "loss: 0.131354  [ 9536/13920]\n",
      "loss: 0.230435  [ 9600/13920]\n",
      "loss: 0.171813  [ 9664/13920]\n",
      "loss: 0.301812  [ 9728/13920]\n",
      "loss: 0.240371  [ 9792/13920]\n",
      "loss: 0.271619  [ 9856/13920]\n",
      "loss: 0.285681  [ 9920/13920]\n",
      "loss: 0.201162  [ 9984/13920]\n",
      "loss: 0.267546  [10048/13920]\n",
      "loss: 0.256873  [10112/13920]\n",
      "loss: 0.157274  [10176/13920]\n",
      "loss: 0.398655  [10240/13920]\n",
      "loss: 0.174618  [10304/13920]\n",
      "loss: 0.290277  [10368/13920]\n",
      "loss: 0.234166  [10432/13920]\n",
      "loss: 0.293094  [10496/13920]\n",
      "loss: 0.348052  [10560/13920]\n",
      "loss: 0.347752  [10624/13920]\n",
      "loss: 0.269387  [10688/13920]\n",
      "loss: 0.227837  [10752/13920]\n",
      "loss: 0.170683  [10816/13920]\n",
      "loss: 0.269373  [10880/13920]\n",
      "loss: 0.175225  [10944/13920]\n",
      "loss: 0.249761  [11008/13920]\n",
      "loss: 0.172350  [11072/13920]\n",
      "loss: 0.170055  [11136/13920]\n",
      "loss: 0.304002  [11200/13920]\n",
      "loss: 0.202549  [11264/13920]\n",
      "loss: 0.261040  [11328/13920]\n",
      "loss: 0.239792  [11392/13920]\n",
      "loss: 0.263606  [11456/13920]\n",
      "loss: 0.307230  [11520/13920]\n",
      "loss: 0.232222  [11584/13920]\n",
      "loss: 0.186118  [11648/13920]\n",
      "loss: 0.297634  [11712/13920]\n",
      "loss: 0.317908  [11776/13920]\n",
      "loss: 0.215363  [11840/13920]\n",
      "loss: 0.212993  [11904/13920]\n",
      "loss: 0.279724  [11968/13920]\n",
      "loss: 0.458831  [12032/13920]\n",
      "loss: 0.162852  [12096/13920]\n",
      "loss: 0.217916  [12160/13920]\n",
      "loss: 0.392628  [12224/13920]\n",
      "loss: 0.246378  [12288/13920]\n",
      "loss: 0.219292  [12352/13920]\n",
      "loss: 0.173002  [12416/13920]\n",
      "loss: 0.171395  [12480/13920]\n",
      "loss: 0.143000  [12544/13920]\n",
      "loss: 0.159779  [12608/13920]\n",
      "loss: 0.249998  [12672/13920]\n",
      "loss: 0.260449  [12736/13920]\n",
      "loss: 0.299846  [12800/13920]\n",
      "loss: 0.249475  [12864/13920]\n",
      "loss: 0.224536  [12928/13920]\n",
      "loss: 0.258332  [12992/13920]\n",
      "loss: 0.285904  [13056/13920]\n",
      "loss: 0.288333  [13120/13920]\n",
      "loss: 0.237398  [13184/13920]\n",
      "loss: 0.251385  [13248/13920]\n",
      "loss: 0.156958  [13312/13920]\n",
      "loss: 0.264848  [13376/13920]\n",
      "loss: 0.224957  [13440/13920]\n",
      "loss: 0.202133  [13504/13920]\n",
      "loss: 0.148877  [13568/13920]\n",
      "loss: 0.249760  [13632/13920]\n",
      "loss: 0.392368  [13696/13920]\n",
      "loss: 0.254198  [13760/13920]\n",
      "loss: 0.186358  [13824/13920]\n",
      "loss: 0.323504  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 90.8% \n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.238444 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.161583  [    0/13920]\n",
      "loss: 0.217894  [   64/13920]\n",
      "loss: 0.174432  [  128/13920]\n",
      "loss: 0.229596  [  192/13920]\n",
      "loss: 0.321392  [  256/13920]\n",
      "loss: 0.211243  [  320/13920]\n",
      "loss: 0.212814  [  384/13920]\n",
      "loss: 0.196480  [  448/13920]\n",
      "loss: 0.146945  [  512/13920]\n",
      "loss: 0.323380  [  576/13920]\n",
      "loss: 0.212414  [  640/13920]\n",
      "loss: 0.147316  [  704/13920]\n",
      "loss: 0.261172  [  768/13920]\n",
      "loss: 0.172228  [  832/13920]\n",
      "loss: 0.127532  [  896/13920]\n",
      "loss: 0.258213  [  960/13920]\n",
      "loss: 0.234071  [ 1024/13920]\n",
      "loss: 0.170764  [ 1088/13920]\n",
      "loss: 0.142423  [ 1152/13920]\n",
      "loss: 0.338562  [ 1216/13920]\n",
      "loss: 0.157462  [ 1280/13920]\n",
      "loss: 0.323320  [ 1344/13920]\n",
      "loss: 0.213703  [ 1408/13920]\n",
      "loss: 0.261804  [ 1472/13920]\n",
      "loss: 0.236312  [ 1536/13920]\n",
      "loss: 0.191230  [ 1600/13920]\n",
      "loss: 0.203230  [ 1664/13920]\n",
      "loss: 0.212525  [ 1728/13920]\n",
      "loss: 0.287765  [ 1792/13920]\n",
      "loss: 0.219565  [ 1856/13920]\n",
      "loss: 0.142857  [ 1920/13920]\n",
      "loss: 0.163897  [ 1984/13920]\n",
      "loss: 0.231939  [ 2048/13920]\n",
      "loss: 0.283719  [ 2112/13920]\n",
      "loss: 0.193536  [ 2176/13920]\n",
      "loss: 0.140234  [ 2240/13920]\n",
      "loss: 0.379707  [ 2304/13920]\n",
      "loss: 0.264433  [ 2368/13920]\n",
      "loss: 0.144086  [ 2432/13920]\n",
      "loss: 0.167597  [ 2496/13920]\n",
      "loss: 0.236694  [ 2560/13920]\n",
      "loss: 0.112547  [ 2624/13920]\n",
      "loss: 0.285249  [ 2688/13920]\n",
      "loss: 0.231034  [ 2752/13920]\n",
      "loss: 0.228956  [ 2816/13920]\n",
      "loss: 0.258450  [ 2880/13920]\n",
      "loss: 0.304854  [ 2944/13920]\n",
      "loss: 0.226579  [ 3008/13920]\n",
      "loss: 0.273552  [ 3072/13920]\n",
      "loss: 0.247991  [ 3136/13920]\n",
      "loss: 0.173933  [ 3200/13920]\n",
      "loss: 0.227979  [ 3264/13920]\n",
      "loss: 0.087424  [ 3328/13920]\n",
      "loss: 0.277739  [ 3392/13920]\n",
      "loss: 0.247222  [ 3456/13920]\n",
      "loss: 0.236265  [ 3520/13920]\n",
      "loss: 0.115815  [ 3584/13920]\n",
      "loss: 0.149406  [ 3648/13920]\n",
      "loss: 0.163213  [ 3712/13920]\n",
      "loss: 0.241788  [ 3776/13920]\n",
      "loss: 0.267969  [ 3840/13920]\n",
      "loss: 0.341391  [ 3904/13920]\n",
      "loss: 0.299663  [ 3968/13920]\n",
      "loss: 0.227378  [ 4032/13920]\n",
      "loss: 0.198905  [ 4096/13920]\n",
      "loss: 0.115892  [ 4160/13920]\n",
      "loss: 0.188717  [ 4224/13920]\n",
      "loss: 0.314275  [ 4288/13920]\n",
      "loss: 0.200733  [ 4352/13920]\n",
      "loss: 0.165638  [ 4416/13920]\n",
      "loss: 0.161738  [ 4480/13920]\n",
      "loss: 0.228793  [ 4544/13920]\n",
      "loss: 0.138999  [ 4608/13920]\n",
      "loss: 0.222174  [ 4672/13920]\n",
      "loss: 0.319552  [ 4736/13920]\n",
      "loss: 0.226390  [ 4800/13920]\n",
      "loss: 0.231683  [ 4864/13920]\n",
      "loss: 0.172817  [ 4928/13920]\n",
      "loss: 0.145193  [ 4992/13920]\n",
      "loss: 0.191402  [ 5056/13920]\n",
      "loss: 0.179410  [ 5120/13920]\n",
      "loss: 0.176611  [ 5184/13920]\n",
      "loss: 0.156774  [ 5248/13920]\n",
      "loss: 0.257705  [ 5312/13920]\n",
      "loss: 0.178655  [ 5376/13920]\n",
      "loss: 0.187053  [ 5440/13920]\n",
      "loss: 0.194282  [ 5504/13920]\n",
      "loss: 0.184810  [ 5568/13920]\n",
      "loss: 0.189980  [ 5632/13920]\n",
      "loss: 0.209784  [ 5696/13920]\n",
      "loss: 0.307987  [ 5760/13920]\n",
      "loss: 0.392348  [ 5824/13920]\n",
      "loss: 0.237041  [ 5888/13920]\n",
      "loss: 0.104840  [ 5952/13920]\n",
      "loss: 0.259012  [ 6016/13920]\n",
      "loss: 0.107541  [ 6080/13920]\n",
      "loss: 0.217604  [ 6144/13920]\n",
      "loss: 0.137457  [ 6208/13920]\n",
      "loss: 0.158939  [ 6272/13920]\n",
      "loss: 0.179934  [ 6336/13920]\n",
      "loss: 0.135184  [ 6400/13920]\n",
      "loss: 0.164408  [ 6464/13920]\n",
      "loss: 0.154033  [ 6528/13920]\n",
      "loss: 0.180071  [ 6592/13920]\n",
      "loss: 0.119429  [ 6656/13920]\n",
      "loss: 0.140039  [ 6720/13920]\n",
      "loss: 0.166203  [ 6784/13920]\n",
      "loss: 0.214543  [ 6848/13920]\n",
      "loss: 0.112291  [ 6912/13920]\n",
      "loss: 0.186136  [ 6976/13920]\n",
      "loss: 0.169904  [ 7040/13920]\n",
      "loss: 0.129096  [ 7104/13920]\n",
      "loss: 0.264550  [ 7168/13920]\n",
      "loss: 0.322732  [ 7232/13920]\n",
      "loss: 0.143598  [ 7296/13920]\n",
      "loss: 0.246719  [ 7360/13920]\n",
      "loss: 0.141000  [ 7424/13920]\n",
      "loss: 0.200889  [ 7488/13920]\n",
      "loss: 0.180113  [ 7552/13920]\n",
      "loss: 0.172607  [ 7616/13920]\n",
      "loss: 0.327641  [ 7680/13920]\n",
      "loss: 0.150612  [ 7744/13920]\n",
      "loss: 0.220916  [ 7808/13920]\n",
      "loss: 0.100040  [ 7872/13920]\n",
      "loss: 0.162635  [ 7936/13920]\n",
      "loss: 0.171883  [ 8000/13920]\n",
      "loss: 0.283857  [ 8064/13920]\n",
      "loss: 0.186245  [ 8128/13920]\n",
      "loss: 0.176907  [ 8192/13920]\n",
      "loss: 0.125335  [ 8256/13920]\n",
      "loss: 0.137289  [ 8320/13920]\n",
      "loss: 0.242182  [ 8384/13920]\n",
      "loss: 0.227174  [ 8448/13920]\n",
      "loss: 0.221441  [ 8512/13920]\n",
      "loss: 0.155040  [ 8576/13920]\n",
      "loss: 0.135523  [ 8640/13920]\n",
      "loss: 0.182425  [ 8704/13920]\n",
      "loss: 0.228867  [ 8768/13920]\n",
      "loss: 0.208147  [ 8832/13920]\n",
      "loss: 0.155492  [ 8896/13920]\n",
      "loss: 0.163245  [ 8960/13920]\n",
      "loss: 0.171596  [ 9024/13920]\n",
      "loss: 0.160410  [ 9088/13920]\n",
      "loss: 0.170767  [ 9152/13920]\n",
      "loss: 0.217850  [ 9216/13920]\n",
      "loss: 0.343374  [ 9280/13920]\n",
      "loss: 0.155681  [ 9344/13920]\n",
      "loss: 0.119029  [ 9408/13920]\n",
      "loss: 0.150383  [ 9472/13920]\n",
      "loss: 0.072649  [ 9536/13920]\n",
      "loss: 0.167966  [ 9600/13920]\n",
      "loss: 0.151971  [ 9664/13920]\n",
      "loss: 0.254386  [ 9728/13920]\n",
      "loss: 0.158992  [ 9792/13920]\n",
      "loss: 0.153214  [ 9856/13920]\n",
      "loss: 0.202416  [ 9920/13920]\n",
      "loss: 0.123223  [ 9984/13920]\n",
      "loss: 0.183385  [10048/13920]\n",
      "loss: 0.145902  [10112/13920]\n",
      "loss: 0.235227  [10176/13920]\n",
      "loss: 0.161266  [10240/13920]\n",
      "loss: 0.142227  [10304/13920]\n",
      "loss: 0.168867  [10368/13920]\n",
      "loss: 0.218157  [10432/13920]\n",
      "loss: 0.128712  [10496/13920]\n",
      "loss: 0.115457  [10560/13920]\n",
      "loss: 0.144278  [10624/13920]\n",
      "loss: 0.237157  [10688/13920]\n",
      "loss: 0.150216  [10752/13920]\n",
      "loss: 0.394457  [10816/13920]\n",
      "loss: 0.261921  [10880/13920]\n",
      "loss: 0.178823  [10944/13920]\n",
      "loss: 0.103695  [11008/13920]\n",
      "loss: 0.253191  [11072/13920]\n",
      "loss: 0.158100  [11136/13920]\n",
      "loss: 0.271668  [11200/13920]\n",
      "loss: 0.214032  [11264/13920]\n",
      "loss: 0.338675  [11328/13920]\n",
      "loss: 0.204166  [11392/13920]\n",
      "loss: 0.162070  [11456/13920]\n",
      "loss: 0.250248  [11520/13920]\n",
      "loss: 0.284689  [11584/13920]\n",
      "loss: 0.145312  [11648/13920]\n",
      "loss: 0.185423  [11712/13920]\n",
      "loss: 0.179837  [11776/13920]\n",
      "loss: 0.112610  [11840/13920]\n",
      "loss: 0.143554  [11904/13920]\n",
      "loss: 0.211366  [11968/13920]\n",
      "loss: 0.224169  [12032/13920]\n",
      "loss: 0.113136  [12096/13920]\n",
      "loss: 0.179077  [12160/13920]\n",
      "loss: 0.155974  [12224/13920]\n",
      "loss: 0.166823  [12288/13920]\n",
      "loss: 0.182442  [12352/13920]\n",
      "loss: 0.152611  [12416/13920]\n",
      "loss: 0.274875  [12480/13920]\n",
      "loss: 0.180965  [12544/13920]\n",
      "loss: 0.194904  [12608/13920]\n",
      "loss: 0.148571  [12672/13920]\n",
      "loss: 0.278853  [12736/13920]\n",
      "loss: 0.220434  [12800/13920]\n",
      "loss: 0.174115  [12864/13920]\n",
      "loss: 0.172238  [12928/13920]\n",
      "loss: 0.146126  [12992/13920]\n",
      "loss: 0.150382  [13056/13920]\n",
      "loss: 0.183243  [13120/13920]\n",
      "loss: 0.211727  [13184/13920]\n",
      "loss: 0.175730  [13248/13920]\n",
      "loss: 0.287745  [13312/13920]\n",
      "loss: 0.302448  [13376/13920]\n",
      "loss: 0.164406  [13440/13920]\n",
      "loss: 0.192117  [13504/13920]\n",
      "loss: 0.158694  [13568/13920]\n",
      "loss: 0.117568  [13632/13920]\n",
      "loss: 0.191807  [13696/13920]\n",
      "loss: 0.271482  [13760/13920]\n",
      "loss: 0.160734  [13824/13920]\n",
      "loss: 0.251977  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 93.2% \n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.200563 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.077837  [    0/13920]\n",
      "loss: 0.197700  [   64/13920]\n",
      "loss: 0.254540  [  128/13920]\n",
      "loss: 0.097134  [  192/13920]\n",
      "loss: 0.185746  [  256/13920]\n",
      "loss: 0.155401  [  320/13920]\n",
      "loss: 0.196499  [  384/13920]\n",
      "loss: 0.080018  [  448/13920]\n",
      "loss: 0.314085  [  512/13920]\n",
      "loss: 0.154806  [  576/13920]\n",
      "loss: 0.207289  [  640/13920]\n",
      "loss: 0.251848  [  704/13920]\n",
      "loss: 0.087894  [  768/13920]\n",
      "loss: 0.211643  [  832/13920]\n",
      "loss: 0.107075  [  896/13920]\n",
      "loss: 0.307698  [  960/13920]\n",
      "loss: 0.351186  [ 1024/13920]\n",
      "loss: 0.198536  [ 1088/13920]\n",
      "loss: 0.165214  [ 1152/13920]\n",
      "loss: 0.299128  [ 1216/13920]\n",
      "loss: 0.240673  [ 1280/13920]\n",
      "loss: 0.195577  [ 1344/13920]\n",
      "loss: 0.307900  [ 1408/13920]\n",
      "loss: 0.169319  [ 1472/13920]\n",
      "loss: 0.142800  [ 1536/13920]\n",
      "loss: 0.256426  [ 1600/13920]\n",
      "loss: 0.184147  [ 1664/13920]\n",
      "loss: 0.131349  [ 1728/13920]\n",
      "loss: 0.204602  [ 1792/13920]\n",
      "loss: 0.141675  [ 1856/13920]\n",
      "loss: 0.131253  [ 1920/13920]\n",
      "loss: 0.167420  [ 1984/13920]\n",
      "loss: 0.185415  [ 2048/13920]\n",
      "loss: 0.157923  [ 2112/13920]\n",
      "loss: 0.157872  [ 2176/13920]\n",
      "loss: 0.169214  [ 2240/13920]\n",
      "loss: 0.084710  [ 2304/13920]\n",
      "loss: 0.039159  [ 2368/13920]\n",
      "loss: 0.172957  [ 2432/13920]\n",
      "loss: 0.169117  [ 2496/13920]\n",
      "loss: 0.134290  [ 2560/13920]\n",
      "loss: 0.209244  [ 2624/13920]\n",
      "loss: 0.163281  [ 2688/13920]\n",
      "loss: 0.086088  [ 2752/13920]\n",
      "loss: 0.225283  [ 2816/13920]\n",
      "loss: 0.089109  [ 2880/13920]\n",
      "loss: 0.121543  [ 2944/13920]\n",
      "loss: 0.261338  [ 3008/13920]\n",
      "loss: 0.207471  [ 3072/13920]\n",
      "loss: 0.101758  [ 3136/13920]\n",
      "loss: 0.244870  [ 3200/13920]\n",
      "loss: 0.174927  [ 3264/13920]\n",
      "loss: 0.112644  [ 3328/13920]\n",
      "loss: 0.067280  [ 3392/13920]\n",
      "loss: 0.184603  [ 3456/13920]\n",
      "loss: 0.185037  [ 3520/13920]\n",
      "loss: 0.066238  [ 3584/13920]\n",
      "loss: 0.146093  [ 3648/13920]\n",
      "loss: 0.177078  [ 3712/13920]\n",
      "loss: 0.135529  [ 3776/13920]\n",
      "loss: 0.121175  [ 3840/13920]\n",
      "loss: 0.170301  [ 3904/13920]\n",
      "loss: 0.156993  [ 3968/13920]\n",
      "loss: 0.124014  [ 4032/13920]\n",
      "loss: 0.219349  [ 4096/13920]\n",
      "loss: 0.133702  [ 4160/13920]\n",
      "loss: 0.111647  [ 4224/13920]\n",
      "loss: 0.139780  [ 4288/13920]\n",
      "loss: 0.118663  [ 4352/13920]\n",
      "loss: 0.198598  [ 4416/13920]\n",
      "loss: 0.124609  [ 4480/13920]\n",
      "loss: 0.284176  [ 4544/13920]\n",
      "loss: 0.185617  [ 4608/13920]\n",
      "loss: 0.169104  [ 4672/13920]\n",
      "loss: 0.229708  [ 4736/13920]\n",
      "loss: 0.129928  [ 4800/13920]\n",
      "loss: 0.133809  [ 4864/13920]\n",
      "loss: 0.118232  [ 4928/13920]\n",
      "loss: 0.168675  [ 4992/13920]\n",
      "loss: 0.158673  [ 5056/13920]\n",
      "loss: 0.243136  [ 5120/13920]\n",
      "loss: 0.191431  [ 5184/13920]\n",
      "loss: 0.131565  [ 5248/13920]\n",
      "loss: 0.163466  [ 5312/13920]\n",
      "loss: 0.104663  [ 5376/13920]\n",
      "loss: 0.141419  [ 5440/13920]\n",
      "loss: 0.207310  [ 5504/13920]\n",
      "loss: 0.199707  [ 5568/13920]\n",
      "loss: 0.203829  [ 5632/13920]\n",
      "loss: 0.150273  [ 5696/13920]\n",
      "loss: 0.145785  [ 5760/13920]\n",
      "loss: 0.157427  [ 5824/13920]\n",
      "loss: 0.197883  [ 5888/13920]\n",
      "loss: 0.085787  [ 5952/13920]\n",
      "loss: 0.122376  [ 6016/13920]\n",
      "loss: 0.207858  [ 6080/13920]\n",
      "loss: 0.154218  [ 6144/13920]\n",
      "loss: 0.141011  [ 6208/13920]\n",
      "loss: 0.152694  [ 6272/13920]\n",
      "loss: 0.082045  [ 6336/13920]\n",
      "loss: 0.083706  [ 6400/13920]\n",
      "loss: 0.087279  [ 6464/13920]\n",
      "loss: 0.091390  [ 6528/13920]\n",
      "loss: 0.248709  [ 6592/13920]\n",
      "loss: 0.172461  [ 6656/13920]\n",
      "loss: 0.115866  [ 6720/13920]\n",
      "loss: 0.107756  [ 6784/13920]\n",
      "loss: 0.210547  [ 6848/13920]\n",
      "loss: 0.159195  [ 6912/13920]\n",
      "loss: 0.188499  [ 6976/13920]\n",
      "loss: 0.226883  [ 7040/13920]\n",
      "loss: 0.362284  [ 7104/13920]\n",
      "loss: 0.083954  [ 7168/13920]\n",
      "loss: 0.127639  [ 7232/13920]\n",
      "loss: 0.118215  [ 7296/13920]\n",
      "loss: 0.143745  [ 7360/13920]\n",
      "loss: 0.118999  [ 7424/13920]\n",
      "loss: 0.111993  [ 7488/13920]\n",
      "loss: 0.089857  [ 7552/13920]\n",
      "loss: 0.147790  [ 7616/13920]\n",
      "loss: 0.131503  [ 7680/13920]\n",
      "loss: 0.145973  [ 7744/13920]\n",
      "loss: 0.075954  [ 7808/13920]\n",
      "loss: 0.140682  [ 7872/13920]\n",
      "loss: 0.072935  [ 7936/13920]\n",
      "loss: 0.099866  [ 8000/13920]\n",
      "loss: 0.091108  [ 8064/13920]\n",
      "loss: 0.077652  [ 8128/13920]\n",
      "loss: 0.104962  [ 8192/13920]\n",
      "loss: 0.127583  [ 8256/13920]\n",
      "loss: 0.198211  [ 8320/13920]\n",
      "loss: 0.127998  [ 8384/13920]\n",
      "loss: 0.168310  [ 8448/13920]\n",
      "loss: 0.061607  [ 8512/13920]\n",
      "loss: 0.196209  [ 8576/13920]\n",
      "loss: 0.096832  [ 8640/13920]\n",
      "loss: 0.104181  [ 8704/13920]\n",
      "loss: 0.234641  [ 8768/13920]\n",
      "loss: 0.119013  [ 8832/13920]\n",
      "loss: 0.276857  [ 8896/13920]\n",
      "loss: 0.080231  [ 8960/13920]\n",
      "loss: 0.118434  [ 9024/13920]\n",
      "loss: 0.105421  [ 9088/13920]\n",
      "loss: 0.178288  [ 9152/13920]\n",
      "loss: 0.147561  [ 9216/13920]\n",
      "loss: 0.345035  [ 9280/13920]\n",
      "loss: 0.142517  [ 9344/13920]\n",
      "loss: 0.400343  [ 9408/13920]\n",
      "loss: 0.218464  [ 9472/13920]\n",
      "loss: 0.091671  [ 9536/13920]\n",
      "loss: 0.098862  [ 9600/13920]\n",
      "loss: 0.154374  [ 9664/13920]\n",
      "loss: 0.171998  [ 9728/13920]\n",
      "loss: 0.085123  [ 9792/13920]\n",
      "loss: 0.152453  [ 9856/13920]\n",
      "loss: 0.345333  [ 9920/13920]\n",
      "loss: 0.167501  [ 9984/13920]\n",
      "loss: 0.228954  [10048/13920]\n",
      "loss: 0.107432  [10112/13920]\n",
      "loss: 0.165505  [10176/13920]\n",
      "loss: 0.127293  [10240/13920]\n",
      "loss: 0.208403  [10304/13920]\n",
      "loss: 0.113703  [10368/13920]\n",
      "loss: 0.232721  [10432/13920]\n",
      "loss: 0.192509  [10496/13920]\n",
      "loss: 0.187348  [10560/13920]\n",
      "loss: 0.156539  [10624/13920]\n",
      "loss: 0.063503  [10688/13920]\n",
      "loss: 0.159217  [10752/13920]\n",
      "loss: 0.247709  [10816/13920]\n",
      "loss: 0.139831  [10880/13920]\n",
      "loss: 0.180375  [10944/13920]\n",
      "loss: 0.170743  [11008/13920]\n",
      "loss: 0.181864  [11072/13920]\n",
      "loss: 0.065201  [11136/13920]\n",
      "loss: 0.074649  [11200/13920]\n",
      "loss: 0.087748  [11264/13920]\n",
      "loss: 0.156497  [11328/13920]\n",
      "loss: 0.087545  [11392/13920]\n",
      "loss: 0.123634  [11456/13920]\n",
      "loss: 0.127911  [11520/13920]\n",
      "loss: 0.128441  [11584/13920]\n",
      "loss: 0.106591  [11648/13920]\n",
      "loss: 0.165724  [11712/13920]\n",
      "loss: 0.158776  [11776/13920]\n",
      "loss: 0.131381  [11840/13920]\n",
      "loss: 0.119160  [11904/13920]\n",
      "loss: 0.067841  [11968/13920]\n",
      "loss: 0.336013  [12032/13920]\n",
      "loss: 0.076399  [12096/13920]\n",
      "loss: 0.129159  [12160/13920]\n",
      "loss: 0.110004  [12224/13920]\n",
      "loss: 0.091303  [12288/13920]\n",
      "loss: 0.132789  [12352/13920]\n",
      "loss: 0.122392  [12416/13920]\n",
      "loss: 0.165320  [12480/13920]\n",
      "loss: 0.102500  [12544/13920]\n",
      "loss: 0.210217  [12608/13920]\n",
      "loss: 0.084616  [12672/13920]\n",
      "loss: 0.139536  [12736/13920]\n",
      "loss: 0.153225  [12800/13920]\n",
      "loss: 0.158322  [12864/13920]\n",
      "loss: 0.178476  [12928/13920]\n",
      "loss: 0.231508  [12992/13920]\n",
      "loss: 0.168907  [13056/13920]\n",
      "loss: 0.085254  [13120/13920]\n",
      "loss: 0.092459  [13184/13920]\n",
      "loss: 0.215362  [13248/13920]\n",
      "loss: 0.086482  [13312/13920]\n",
      "loss: 0.176701  [13376/13920]\n",
      "loss: 0.116240  [13440/13920]\n",
      "loss: 0.112709  [13504/13920]\n",
      "loss: 0.097377  [13568/13920]\n",
      "loss: 0.073585  [13632/13920]\n",
      "loss: 0.121211  [13696/13920]\n",
      "loss: 0.107543  [13760/13920]\n",
      "loss: 0.172266  [13824/13920]\n",
      "loss: 0.172303  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 94.8% \n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.180961 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.073076  [    0/13920]\n",
      "loss: 0.078692  [   64/13920]\n",
      "loss: 0.090105  [  128/13920]\n",
      "loss: 0.102351  [  192/13920]\n",
      "loss: 0.154778  [  256/13920]\n",
      "loss: 0.095415  [  320/13920]\n",
      "loss: 0.172787  [  384/13920]\n",
      "loss: 0.090565  [  448/13920]\n",
      "loss: 0.091813  [  512/13920]\n",
      "loss: 0.047395  [  576/13920]\n",
      "loss: 0.048616  [  640/13920]\n",
      "loss: 0.096694  [  704/13920]\n",
      "loss: 0.075905  [  768/13920]\n",
      "loss: 0.104163  [  832/13920]\n",
      "loss: 0.151620  [  896/13920]\n",
      "loss: 0.243038  [  960/13920]\n",
      "loss: 0.222697  [ 1024/13920]\n",
      "loss: 0.025989  [ 1088/13920]\n",
      "loss: 0.090869  [ 1152/13920]\n",
      "loss: 0.096670  [ 1216/13920]\n",
      "loss: 0.130769  [ 1280/13920]\n",
      "loss: 0.044169  [ 1344/13920]\n",
      "loss: 0.084767  [ 1408/13920]\n",
      "loss: 0.166752  [ 1472/13920]\n",
      "loss: 0.089884  [ 1536/13920]\n",
      "loss: 0.198966  [ 1600/13920]\n",
      "loss: 0.139088  [ 1664/13920]\n",
      "loss: 0.070361  [ 1728/13920]\n",
      "loss: 0.194378  [ 1792/13920]\n",
      "loss: 0.082107  [ 1856/13920]\n",
      "loss: 0.102706  [ 1920/13920]\n",
      "loss: 0.057506  [ 1984/13920]\n",
      "loss: 0.196684  [ 2048/13920]\n",
      "loss: 0.066329  [ 2112/13920]\n",
      "loss: 0.117307  [ 2176/13920]\n",
      "loss: 0.201075  [ 2240/13920]\n",
      "loss: 0.216129  [ 2304/13920]\n",
      "loss: 0.102186  [ 2368/13920]\n",
      "loss: 0.155802  [ 2432/13920]\n",
      "loss: 0.068543  [ 2496/13920]\n",
      "loss: 0.075274  [ 2560/13920]\n",
      "loss: 0.092670  [ 2624/13920]\n",
      "loss: 0.204814  [ 2688/13920]\n",
      "loss: 0.186662  [ 2752/13920]\n",
      "loss: 0.110533  [ 2816/13920]\n",
      "loss: 0.096524  [ 2880/13920]\n",
      "loss: 0.116155  [ 2944/13920]\n",
      "loss: 0.091455  [ 3008/13920]\n",
      "loss: 0.111902  [ 3072/13920]\n",
      "loss: 0.110749  [ 3136/13920]\n",
      "loss: 0.254766  [ 3200/13920]\n",
      "loss: 0.263106  [ 3264/13920]\n",
      "loss: 0.128087  [ 3328/13920]\n",
      "loss: 0.243293  [ 3392/13920]\n",
      "loss: 0.059563  [ 3456/13920]\n",
      "loss: 0.192010  [ 3520/13920]\n",
      "loss: 0.180306  [ 3584/13920]\n",
      "loss: 0.063553  [ 3648/13920]\n",
      "loss: 0.149268  [ 3712/13920]\n",
      "loss: 0.157909  [ 3776/13920]\n",
      "loss: 0.134255  [ 3840/13920]\n",
      "loss: 0.148487  [ 3904/13920]\n",
      "loss: 0.140025  [ 3968/13920]\n",
      "loss: 0.147308  [ 4032/13920]\n",
      "loss: 0.081569  [ 4096/13920]\n",
      "loss: 0.145785  [ 4160/13920]\n",
      "loss: 0.081728  [ 4224/13920]\n",
      "loss: 0.118356  [ 4288/13920]\n",
      "loss: 0.142755  [ 4352/13920]\n",
      "loss: 0.131459  [ 4416/13920]\n",
      "loss: 0.058911  [ 4480/13920]\n",
      "loss: 0.056916  [ 4544/13920]\n",
      "loss: 0.118127  [ 4608/13920]\n",
      "loss: 0.234262  [ 4672/13920]\n",
      "loss: 0.123411  [ 4736/13920]\n",
      "loss: 0.141580  [ 4800/13920]\n",
      "loss: 0.078034  [ 4864/13920]\n",
      "loss: 0.138408  [ 4928/13920]\n",
      "loss: 0.067329  [ 4992/13920]\n",
      "loss: 0.086455  [ 5056/13920]\n",
      "loss: 0.051097  [ 5120/13920]\n",
      "loss: 0.075950  [ 5184/13920]\n",
      "loss: 0.070542  [ 5248/13920]\n",
      "loss: 0.168621  [ 5312/13920]\n",
      "loss: 0.107609  [ 5376/13920]\n",
      "loss: 0.163900  [ 5440/13920]\n",
      "loss: 0.114192  [ 5504/13920]\n",
      "loss: 0.105955  [ 5568/13920]\n",
      "loss: 0.153322  [ 5632/13920]\n",
      "loss: 0.171621  [ 5696/13920]\n",
      "loss: 0.210118  [ 5760/13920]\n",
      "loss: 0.168618  [ 5824/13920]\n",
      "loss: 0.091003  [ 5888/13920]\n",
      "loss: 0.121138  [ 5952/13920]\n",
      "loss: 0.142566  [ 6016/13920]\n",
      "loss: 0.100341  [ 6080/13920]\n",
      "loss: 0.175070  [ 6144/13920]\n",
      "loss: 0.077469  [ 6208/13920]\n",
      "loss: 0.095568  [ 6272/13920]\n",
      "loss: 0.097399  [ 6336/13920]\n",
      "loss: 0.162378  [ 6400/13920]\n",
      "loss: 0.129709  [ 6464/13920]\n",
      "loss: 0.218240  [ 6528/13920]\n",
      "loss: 0.152865  [ 6592/13920]\n",
      "loss: 0.151620  [ 6656/13920]\n",
      "loss: 0.193167  [ 6720/13920]\n",
      "loss: 0.109656  [ 6784/13920]\n",
      "loss: 0.040669  [ 6848/13920]\n",
      "loss: 0.151500  [ 6912/13920]\n",
      "loss: 0.065773  [ 6976/13920]\n",
      "loss: 0.107022  [ 7040/13920]\n",
      "loss: 0.268260  [ 7104/13920]\n",
      "loss: 0.094380  [ 7168/13920]\n",
      "loss: 0.112912  [ 7232/13920]\n",
      "loss: 0.108852  [ 7296/13920]\n",
      "loss: 0.163536  [ 7360/13920]\n",
      "loss: 0.071877  [ 7424/13920]\n",
      "loss: 0.134319  [ 7488/13920]\n",
      "loss: 0.142590  [ 7552/13920]\n",
      "loss: 0.186343  [ 7616/13920]\n",
      "loss: 0.156659  [ 7680/13920]\n",
      "loss: 0.112197  [ 7744/13920]\n",
      "loss: 0.193791  [ 7808/13920]\n",
      "loss: 0.143303  [ 7872/13920]\n",
      "loss: 0.185319  [ 7936/13920]\n",
      "loss: 0.181062  [ 8000/13920]\n",
      "loss: 0.099981  [ 8064/13920]\n",
      "loss: 0.045603  [ 8128/13920]\n",
      "loss: 0.192278  [ 8192/13920]\n",
      "loss: 0.073802  [ 8256/13920]\n",
      "loss: 0.075426  [ 8320/13920]\n",
      "loss: 0.276089  [ 8384/13920]\n",
      "loss: 0.108355  [ 8448/13920]\n",
      "loss: 0.115272  [ 8512/13920]\n",
      "loss: 0.100148  [ 8576/13920]\n",
      "loss: 0.230515  [ 8640/13920]\n",
      "loss: 0.207914  [ 8704/13920]\n",
      "loss: 0.127456  [ 8768/13920]\n",
      "loss: 0.108493  [ 8832/13920]\n",
      "loss: 0.238804  [ 8896/13920]\n",
      "loss: 0.172186  [ 8960/13920]\n",
      "loss: 0.108226  [ 9024/13920]\n",
      "loss: 0.110119  [ 9088/13920]\n",
      "loss: 0.158319  [ 9152/13920]\n",
      "loss: 0.215712  [ 9216/13920]\n",
      "loss: 0.072059  [ 9280/13920]\n",
      "loss: 0.184215  [ 9344/13920]\n",
      "loss: 0.089489  [ 9408/13920]\n",
      "loss: 0.081667  [ 9472/13920]\n",
      "loss: 0.235530  [ 9536/13920]\n",
      "loss: 0.055145  [ 9600/13920]\n",
      "loss: 0.140370  [ 9664/13920]\n",
      "loss: 0.257812  [ 9728/13920]\n",
      "loss: 0.100953  [ 9792/13920]\n",
      "loss: 0.133785  [ 9856/13920]\n",
      "loss: 0.135766  [ 9920/13920]\n",
      "loss: 0.111967  [ 9984/13920]\n",
      "loss: 0.135600  [10048/13920]\n",
      "loss: 0.146451  [10112/13920]\n",
      "loss: 0.115701  [10176/13920]\n",
      "loss: 0.101996  [10240/13920]\n",
      "loss: 0.083169  [10304/13920]\n",
      "loss: 0.231582  [10368/13920]\n",
      "loss: 0.114086  [10432/13920]\n",
      "loss: 0.113646  [10496/13920]\n",
      "loss: 0.077988  [10560/13920]\n",
      "loss: 0.096420  [10624/13920]\n",
      "loss: 0.091256  [10688/13920]\n",
      "loss: 0.085530  [10752/13920]\n",
      "loss: 0.053573  [10816/13920]\n",
      "loss: 0.162137  [10880/13920]\n",
      "loss: 0.180372  [10944/13920]\n",
      "loss: 0.140414  [11008/13920]\n",
      "loss: 0.144554  [11072/13920]\n",
      "loss: 0.102311  [11136/13920]\n",
      "loss: 0.139952  [11200/13920]\n",
      "loss: 0.137435  [11264/13920]\n",
      "loss: 0.076771  [11328/13920]\n",
      "loss: 0.107461  [11392/13920]\n",
      "loss: 0.107277  [11456/13920]\n",
      "loss: 0.044154  [11520/13920]\n",
      "loss: 0.222461  [11584/13920]\n",
      "loss: 0.139301  [11648/13920]\n",
      "loss: 0.092205  [11712/13920]\n",
      "loss: 0.157809  [11776/13920]\n",
      "loss: 0.127889  [11840/13920]\n",
      "loss: 0.148916  [11904/13920]\n",
      "loss: 0.097688  [11968/13920]\n",
      "loss: 0.136001  [12032/13920]\n",
      "loss: 0.085888  [12096/13920]\n",
      "loss: 0.051570  [12160/13920]\n",
      "loss: 0.126076  [12224/13920]\n",
      "loss: 0.208350  [12288/13920]\n",
      "loss: 0.112150  [12352/13920]\n",
      "loss: 0.064479  [12416/13920]\n",
      "loss: 0.139037  [12480/13920]\n",
      "loss: 0.104534  [12544/13920]\n",
      "loss: 0.091539  [12608/13920]\n",
      "loss: 0.095536  [12672/13920]\n",
      "loss: 0.106058  [12736/13920]\n",
      "loss: 0.060544  [12800/13920]\n",
      "loss: 0.058087  [12864/13920]\n",
      "loss: 0.069928  [12928/13920]\n",
      "loss: 0.080920  [12992/13920]\n",
      "loss: 0.122987  [13056/13920]\n",
      "loss: 0.061879  [13120/13920]\n",
      "loss: 0.128841  [13184/13920]\n",
      "loss: 0.179751  [13248/13920]\n",
      "loss: 0.222854  [13312/13920]\n",
      "loss: 0.253233  [13376/13920]\n",
      "loss: 0.158683  [13440/13920]\n",
      "loss: 0.085893  [13504/13920]\n",
      "loss: 0.106838  [13568/13920]\n",
      "loss: 0.099233  [13632/13920]\n",
      "loss: 0.194352  [13696/13920]\n",
      "loss: 0.145094  [13760/13920]\n",
      "loss: 0.085177  [13824/13920]\n",
      "loss: 0.181201  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.8% \n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.143137 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.053962  [    0/13920]\n",
      "loss: 0.096473  [   64/13920]\n",
      "loss: 0.182132  [  128/13920]\n",
      "loss: 0.057671  [  192/13920]\n",
      "loss: 0.091658  [  256/13920]\n",
      "loss: 0.084378  [  320/13920]\n",
      "loss: 0.173490  [  384/13920]\n",
      "loss: 0.142734  [  448/13920]\n",
      "loss: 0.128475  [  512/13920]\n",
      "loss: 0.128644  [  576/13920]\n",
      "loss: 0.038880  [  640/13920]\n",
      "loss: 0.179746  [  704/13920]\n",
      "loss: 0.184756  [  768/13920]\n",
      "loss: 0.077905  [  832/13920]\n",
      "loss: 0.206861  [  896/13920]\n",
      "loss: 0.110098  [  960/13920]\n",
      "loss: 0.066716  [ 1024/13920]\n",
      "loss: 0.064745  [ 1088/13920]\n",
      "loss: 0.077975  [ 1152/13920]\n",
      "loss: 0.118347  [ 1216/13920]\n",
      "loss: 0.112041  [ 1280/13920]\n",
      "loss: 0.079389  [ 1344/13920]\n",
      "loss: 0.098933  [ 1408/13920]\n",
      "loss: 0.156680  [ 1472/13920]\n",
      "loss: 0.109060  [ 1536/13920]\n",
      "loss: 0.056626  [ 1600/13920]\n",
      "loss: 0.088286  [ 1664/13920]\n",
      "loss: 0.233457  [ 1728/13920]\n",
      "loss: 0.139011  [ 1792/13920]\n",
      "loss: 0.076151  [ 1856/13920]\n",
      "loss: 0.099234  [ 1920/13920]\n",
      "loss: 0.109896  [ 1984/13920]\n",
      "loss: 0.109045  [ 2048/13920]\n",
      "loss: 0.090841  [ 2112/13920]\n",
      "loss: 0.113624  [ 2176/13920]\n",
      "loss: 0.201033  [ 2240/13920]\n",
      "loss: 0.054525  [ 2304/13920]\n",
      "loss: 0.069312  [ 2368/13920]\n",
      "loss: 0.102156  [ 2432/13920]\n",
      "loss: 0.102836  [ 2496/13920]\n",
      "loss: 0.077007  [ 2560/13920]\n",
      "loss: 0.074816  [ 2624/13920]\n",
      "loss: 0.035260  [ 2688/13920]\n",
      "loss: 0.091050  [ 2752/13920]\n",
      "loss: 0.148589  [ 2816/13920]\n",
      "loss: 0.078601  [ 2880/13920]\n",
      "loss: 0.092728  [ 2944/13920]\n",
      "loss: 0.094595  [ 3008/13920]\n",
      "loss: 0.128537  [ 3072/13920]\n",
      "loss: 0.055883  [ 3136/13920]\n",
      "loss: 0.172206  [ 3200/13920]\n",
      "loss: 0.127381  [ 3264/13920]\n",
      "loss: 0.146392  [ 3328/13920]\n",
      "loss: 0.095128  [ 3392/13920]\n",
      "loss: 0.116909  [ 3456/13920]\n",
      "loss: 0.090664  [ 3520/13920]\n",
      "loss: 0.184567  [ 3584/13920]\n",
      "loss: 0.062229  [ 3648/13920]\n",
      "loss: 0.117495  [ 3712/13920]\n",
      "loss: 0.047918  [ 3776/13920]\n",
      "loss: 0.108265  [ 3840/13920]\n",
      "loss: 0.151554  [ 3904/13920]\n",
      "loss: 0.114408  [ 3968/13920]\n",
      "loss: 0.097586  [ 4032/13920]\n",
      "loss: 0.156080  [ 4096/13920]\n",
      "loss: 0.114170  [ 4160/13920]\n",
      "loss: 0.099226  [ 4224/13920]\n",
      "loss: 0.111961  [ 4288/13920]\n",
      "loss: 0.198531  [ 4352/13920]\n",
      "loss: 0.043910  [ 4416/13920]\n",
      "loss: 0.086470  [ 4480/13920]\n",
      "loss: 0.117960  [ 4544/13920]\n",
      "loss: 0.164718  [ 4608/13920]\n",
      "loss: 0.064222  [ 4672/13920]\n",
      "loss: 0.063426  [ 4736/13920]\n",
      "loss: 0.073364  [ 4800/13920]\n",
      "loss: 0.119696  [ 4864/13920]\n",
      "loss: 0.090361  [ 4928/13920]\n",
      "loss: 0.185172  [ 4992/13920]\n",
      "loss: 0.108617  [ 5056/13920]\n",
      "loss: 0.082294  [ 5120/13920]\n",
      "loss: 0.122861  [ 5184/13920]\n",
      "loss: 0.092125  [ 5248/13920]\n",
      "loss: 0.184938  [ 5312/13920]\n",
      "loss: 0.140494  [ 5376/13920]\n",
      "loss: 0.041666  [ 5440/13920]\n",
      "loss: 0.148501  [ 5504/13920]\n",
      "loss: 0.080465  [ 5568/13920]\n",
      "loss: 0.115727  [ 5632/13920]\n",
      "loss: 0.212234  [ 5696/13920]\n",
      "loss: 0.142335  [ 5760/13920]\n",
      "loss: 0.085703  [ 5824/13920]\n",
      "loss: 0.110156  [ 5888/13920]\n",
      "loss: 0.134727  [ 5952/13920]\n",
      "loss: 0.080526  [ 6016/13920]\n",
      "loss: 0.145018  [ 6080/13920]\n",
      "loss: 0.089989  [ 6144/13920]\n",
      "loss: 0.281530  [ 6208/13920]\n",
      "loss: 0.050014  [ 6272/13920]\n",
      "loss: 0.091380  [ 6336/13920]\n",
      "loss: 0.083209  [ 6400/13920]\n",
      "loss: 0.155513  [ 6464/13920]\n",
      "loss: 0.120444  [ 6528/13920]\n",
      "loss: 0.098147  [ 6592/13920]\n",
      "loss: 0.048534  [ 6656/13920]\n",
      "loss: 0.204134  [ 6720/13920]\n",
      "loss: 0.114316  [ 6784/13920]\n",
      "loss: 0.131324  [ 6848/13920]\n",
      "loss: 0.147193  [ 6912/13920]\n",
      "loss: 0.080557  [ 6976/13920]\n",
      "loss: 0.089608  [ 7040/13920]\n",
      "loss: 0.194367  [ 7104/13920]\n",
      "loss: 0.234245  [ 7168/13920]\n",
      "loss: 0.168437  [ 7232/13920]\n",
      "loss: 0.089951  [ 7296/13920]\n",
      "loss: 0.072366  [ 7360/13920]\n",
      "loss: 0.113836  [ 7424/13920]\n",
      "loss: 0.143722  [ 7488/13920]\n",
      "loss: 0.052328  [ 7552/13920]\n",
      "loss: 0.121973  [ 7616/13920]\n",
      "loss: 0.115842  [ 7680/13920]\n",
      "loss: 0.032684  [ 7744/13920]\n",
      "loss: 0.107594  [ 7808/13920]\n",
      "loss: 0.078632  [ 7872/13920]\n",
      "loss: 0.093227  [ 7936/13920]\n",
      "loss: 0.110581  [ 8000/13920]\n",
      "loss: 0.077535  [ 8064/13920]\n",
      "loss: 0.169791  [ 8128/13920]\n",
      "loss: 0.035744  [ 8192/13920]\n",
      "loss: 0.108375  [ 8256/13920]\n",
      "loss: 0.064445  [ 8320/13920]\n",
      "loss: 0.036888  [ 8384/13920]\n",
      "loss: 0.048985  [ 8448/13920]\n",
      "loss: 0.107557  [ 8512/13920]\n",
      "loss: 0.058733  [ 8576/13920]\n",
      "loss: 0.081753  [ 8640/13920]\n",
      "loss: 0.035999  [ 8704/13920]\n",
      "loss: 0.120477  [ 8768/13920]\n",
      "loss: 0.122098  [ 8832/13920]\n",
      "loss: 0.092719  [ 8896/13920]\n",
      "loss: 0.068448  [ 8960/13920]\n",
      "loss: 0.068026  [ 9024/13920]\n",
      "loss: 0.092844  [ 9088/13920]\n",
      "loss: 0.103348  [ 9152/13920]\n",
      "loss: 0.114515  [ 9216/13920]\n",
      "loss: 0.018995  [ 9280/13920]\n",
      "loss: 0.154226  [ 9344/13920]\n",
      "loss: 0.039305  [ 9408/13920]\n",
      "loss: 0.095345  [ 9472/13920]\n",
      "loss: 0.085502  [ 9536/13920]\n",
      "loss: 0.059315  [ 9600/13920]\n",
      "loss: 0.119097  [ 9664/13920]\n",
      "loss: 0.050675  [ 9728/13920]\n",
      "loss: 0.048053  [ 9792/13920]\n",
      "loss: 0.227643  [ 9856/13920]\n",
      "loss: 0.165333  [ 9920/13920]\n",
      "loss: 0.050058  [ 9984/13920]\n",
      "loss: 0.158691  [10048/13920]\n",
      "loss: 0.046695  [10112/13920]\n",
      "loss: 0.060744  [10176/13920]\n",
      "loss: 0.199907  [10240/13920]\n",
      "loss: 0.196130  [10304/13920]\n",
      "loss: 0.106045  [10368/13920]\n",
      "loss: 0.088888  [10432/13920]\n",
      "loss: 0.136282  [10496/13920]\n",
      "loss: 0.094876  [10560/13920]\n",
      "loss: 0.136726  [10624/13920]\n",
      "loss: 0.213175  [10688/13920]\n",
      "loss: 0.095966  [10752/13920]\n",
      "loss: 0.114579  [10816/13920]\n",
      "loss: 0.081895  [10880/13920]\n",
      "loss: 0.052257  [10944/13920]\n",
      "loss: 0.135434  [11008/13920]\n",
      "loss: 0.077135  [11072/13920]\n",
      "loss: 0.032925  [11136/13920]\n",
      "loss: 0.084042  [11200/13920]\n",
      "loss: 0.055455  [11264/13920]\n",
      "loss: 0.076665  [11328/13920]\n",
      "loss: 0.202014  [11392/13920]\n",
      "loss: 0.072407  [11456/13920]\n",
      "loss: 0.157438  [11520/13920]\n",
      "loss: 0.096397  [11584/13920]\n",
      "loss: 0.090098  [11648/13920]\n",
      "loss: 0.072134  [11712/13920]\n",
      "loss: 0.037241  [11776/13920]\n",
      "loss: 0.106990  [11840/13920]\n",
      "loss: 0.068618  [11904/13920]\n",
      "loss: 0.130672  [11968/13920]\n",
      "loss: 0.092379  [12032/13920]\n",
      "loss: 0.064982  [12096/13920]\n",
      "loss: 0.062837  [12160/13920]\n",
      "loss: 0.193809  [12224/13920]\n",
      "loss: 0.071698  [12288/13920]\n",
      "loss: 0.047529  [12352/13920]\n",
      "loss: 0.164383  [12416/13920]\n",
      "loss: 0.095378  [12480/13920]\n",
      "loss: 0.176741  [12544/13920]\n",
      "loss: 0.046190  [12608/13920]\n",
      "loss: 0.120940  [12672/13920]\n",
      "loss: 0.130566  [12736/13920]\n",
      "loss: 0.143392  [12800/13920]\n",
      "loss: 0.080314  [12864/13920]\n",
      "loss: 0.064931  [12928/13920]\n",
      "loss: 0.036391  [12992/13920]\n",
      "loss: 0.109002  [13056/13920]\n",
      "loss: 0.138296  [13120/13920]\n",
      "loss: 0.122676  [13184/13920]\n",
      "loss: 0.053951  [13248/13920]\n",
      "loss: 0.070576  [13312/13920]\n",
      "loss: 0.047402  [13376/13920]\n",
      "loss: 0.289812  [13440/13920]\n",
      "loss: 0.068282  [13504/13920]\n",
      "loss: 0.086323  [13568/13920]\n",
      "loss: 0.084028  [13632/13920]\n",
      "loss: 0.100195  [13696/13920]\n",
      "loss: 0.055499  [13760/13920]\n",
      "loss: 0.087638  [13824/13920]\n",
      "loss: 0.452463  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 96.4% \n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.137735 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.045148  [    0/13920]\n",
      "loss: 0.071436  [   64/13920]\n",
      "loss: 0.094240  [  128/13920]\n",
      "loss: 0.080667  [  192/13920]\n",
      "loss: 0.085254  [  256/13920]\n",
      "loss: 0.078779  [  320/13920]\n",
      "loss: 0.106853  [  384/13920]\n",
      "loss: 0.036017  [  448/13920]\n",
      "loss: 0.096002  [  512/13920]\n",
      "loss: 0.033619  [  576/13920]\n",
      "loss: 0.120628  [  640/13920]\n",
      "loss: 0.293782  [  704/13920]\n",
      "loss: 0.040704  [  768/13920]\n",
      "loss: 0.052339  [  832/13920]\n",
      "loss: 0.136454  [  896/13920]\n",
      "loss: 0.130043  [  960/13920]\n",
      "loss: 0.046958  [ 1024/13920]\n",
      "loss: 0.125079  [ 1088/13920]\n",
      "loss: 0.069321  [ 1152/13920]\n",
      "loss: 0.074963  [ 1216/13920]\n",
      "loss: 0.105379  [ 1280/13920]\n",
      "loss: 0.149305  [ 1344/13920]\n",
      "loss: 0.137398  [ 1408/13920]\n",
      "loss: 0.031237  [ 1472/13920]\n",
      "loss: 0.190128  [ 1536/13920]\n",
      "loss: 0.118411  [ 1600/13920]\n",
      "loss: 0.077285  [ 1664/13920]\n",
      "loss: 0.096833  [ 1728/13920]\n",
      "loss: 0.088277  [ 1792/13920]\n",
      "loss: 0.090512  [ 1856/13920]\n",
      "loss: 0.038306  [ 1920/13920]\n",
      "loss: 0.129112  [ 1984/13920]\n",
      "loss: 0.077086  [ 2048/13920]\n",
      "loss: 0.038364  [ 2112/13920]\n",
      "loss: 0.048549  [ 2176/13920]\n",
      "loss: 0.080186  [ 2240/13920]\n",
      "loss: 0.055208  [ 2304/13920]\n",
      "loss: 0.061554  [ 2368/13920]\n",
      "loss: 0.044992  [ 2432/13920]\n",
      "loss: 0.064319  [ 2496/13920]\n",
      "loss: 0.155905  [ 2560/13920]\n",
      "loss: 0.069067  [ 2624/13920]\n",
      "loss: 0.095657  [ 2688/13920]\n",
      "loss: 0.097612  [ 2752/13920]\n",
      "loss: 0.096629  [ 2816/13920]\n",
      "loss: 0.123862  [ 2880/13920]\n",
      "loss: 0.183016  [ 2944/13920]\n",
      "loss: 0.158876  [ 3008/13920]\n",
      "loss: 0.020419  [ 3072/13920]\n",
      "loss: 0.155977  [ 3136/13920]\n",
      "loss: 0.015942  [ 3200/13920]\n",
      "loss: 0.120200  [ 3264/13920]\n",
      "loss: 0.053671  [ 3328/13920]\n",
      "loss: 0.043650  [ 3392/13920]\n",
      "loss: 0.136003  [ 3456/13920]\n",
      "loss: 0.133846  [ 3520/13920]\n",
      "loss: 0.123253  [ 3584/13920]\n",
      "loss: 0.064052  [ 3648/13920]\n",
      "loss: 0.052756  [ 3712/13920]\n",
      "loss: 0.049543  [ 3776/13920]\n",
      "loss: 0.122910  [ 3840/13920]\n",
      "loss: 0.057057  [ 3904/13920]\n",
      "loss: 0.040760  [ 3968/13920]\n",
      "loss: 0.075308  [ 4032/13920]\n",
      "loss: 0.137912  [ 4096/13920]\n",
      "loss: 0.158857  [ 4160/13920]\n",
      "loss: 0.108076  [ 4224/13920]\n",
      "loss: 0.053205  [ 4288/13920]\n",
      "loss: 0.062930  [ 4352/13920]\n",
      "loss: 0.112210  [ 4416/13920]\n",
      "loss: 0.057518  [ 4480/13920]\n",
      "loss: 0.080527  [ 4544/13920]\n",
      "loss: 0.150439  [ 4608/13920]\n",
      "loss: 0.161294  [ 4672/13920]\n",
      "loss: 0.079278  [ 4736/13920]\n",
      "loss: 0.144642  [ 4800/13920]\n",
      "loss: 0.147913  [ 4864/13920]\n",
      "loss: 0.066418  [ 4928/13920]\n",
      "loss: 0.146285  [ 4992/13920]\n",
      "loss: 0.080553  [ 5056/13920]\n",
      "loss: 0.126869  [ 5120/13920]\n",
      "loss: 0.067815  [ 5184/13920]\n",
      "loss: 0.121310  [ 5248/13920]\n",
      "loss: 0.078378  [ 5312/13920]\n",
      "loss: 0.046832  [ 5376/13920]\n",
      "loss: 0.050791  [ 5440/13920]\n",
      "loss: 0.022888  [ 5504/13920]\n",
      "loss: 0.057799  [ 5568/13920]\n",
      "loss: 0.115695  [ 5632/13920]\n",
      "loss: 0.084779  [ 5696/13920]\n",
      "loss: 0.047377  [ 5760/13920]\n",
      "loss: 0.085790  [ 5824/13920]\n",
      "loss: 0.137870  [ 5888/13920]\n",
      "loss: 0.132578  [ 5952/13920]\n",
      "loss: 0.099217  [ 6016/13920]\n",
      "loss: 0.055419  [ 6080/13920]\n",
      "loss: 0.038476  [ 6144/13920]\n",
      "loss: 0.074569  [ 6208/13920]\n",
      "loss: 0.105755  [ 6272/13920]\n",
      "loss: 0.144714  [ 6336/13920]\n",
      "loss: 0.066083  [ 6400/13920]\n",
      "loss: 0.095101  [ 6464/13920]\n",
      "loss: 0.045918  [ 6528/13920]\n",
      "loss: 0.190101  [ 6592/13920]\n",
      "loss: 0.044881  [ 6656/13920]\n",
      "loss: 0.044406  [ 6720/13920]\n",
      "loss: 0.046070  [ 6784/13920]\n",
      "loss: 0.123676  [ 6848/13920]\n",
      "loss: 0.092492  [ 6912/13920]\n",
      "loss: 0.051617  [ 6976/13920]\n",
      "loss: 0.099166  [ 7040/13920]\n",
      "loss: 0.048152  [ 7104/13920]\n",
      "loss: 0.047536  [ 7168/13920]\n",
      "loss: 0.040954  [ 7232/13920]\n",
      "loss: 0.068467  [ 7296/13920]\n",
      "loss: 0.101321  [ 7360/13920]\n",
      "loss: 0.050648  [ 7424/13920]\n",
      "loss: 0.051508  [ 7488/13920]\n",
      "loss: 0.199270  [ 7552/13920]\n",
      "loss: 0.030280  [ 7616/13920]\n",
      "loss: 0.079281  [ 7680/13920]\n",
      "loss: 0.032963  [ 7744/13920]\n",
      "loss: 0.038978  [ 7808/13920]\n",
      "loss: 0.133759  [ 7872/13920]\n",
      "loss: 0.096824  [ 7936/13920]\n",
      "loss: 0.057409  [ 8000/13920]\n",
      "loss: 0.050127  [ 8064/13920]\n",
      "loss: 0.052703  [ 8128/13920]\n",
      "loss: 0.057999  [ 8192/13920]\n",
      "loss: 0.081322  [ 8256/13920]\n",
      "loss: 0.070703  [ 8320/13920]\n",
      "loss: 0.025509  [ 8384/13920]\n",
      "loss: 0.104102  [ 8448/13920]\n",
      "loss: 0.075172  [ 8512/13920]\n",
      "loss: 0.050753  [ 8576/13920]\n",
      "loss: 0.040027  [ 8640/13920]\n",
      "loss: 0.079060  [ 8704/13920]\n",
      "loss: 0.063576  [ 8768/13920]\n",
      "loss: 0.049772  [ 8832/13920]\n",
      "loss: 0.133422  [ 8896/13920]\n",
      "loss: 0.065570  [ 8960/13920]\n",
      "loss: 0.130208  [ 9024/13920]\n",
      "loss: 0.051885  [ 9088/13920]\n",
      "loss: 0.064473  [ 9152/13920]\n",
      "loss: 0.046054  [ 9216/13920]\n",
      "loss: 0.078035  [ 9280/13920]\n",
      "loss: 0.119658  [ 9344/13920]\n",
      "loss: 0.074232  [ 9408/13920]\n",
      "loss: 0.201725  [ 9472/13920]\n",
      "loss: 0.042547  [ 9536/13920]\n",
      "loss: 0.131163  [ 9600/13920]\n",
      "loss: 0.104158  [ 9664/13920]\n",
      "loss: 0.110206  [ 9728/13920]\n",
      "loss: 0.039956  [ 9792/13920]\n",
      "loss: 0.094184  [ 9856/13920]\n",
      "loss: 0.092726  [ 9920/13920]\n",
      "loss: 0.048816  [ 9984/13920]\n",
      "loss: 0.104749  [10048/13920]\n",
      "loss: 0.034976  [10112/13920]\n",
      "loss: 0.052970  [10176/13920]\n",
      "loss: 0.070646  [10240/13920]\n",
      "loss: 0.049088  [10304/13920]\n",
      "loss: 0.068656  [10368/13920]\n",
      "loss: 0.053890  [10432/13920]\n",
      "loss: 0.127903  [10496/13920]\n",
      "loss: 0.139400  [10560/13920]\n",
      "loss: 0.090525  [10624/13920]\n",
      "loss: 0.080089  [10688/13920]\n",
      "loss: 0.030048  [10752/13920]\n",
      "loss: 0.080318  [10816/13920]\n",
      "loss: 0.068739  [10880/13920]\n",
      "loss: 0.031199  [10944/13920]\n",
      "loss: 0.080148  [11008/13920]\n",
      "loss: 0.125447  [11072/13920]\n",
      "loss: 0.073636  [11136/13920]\n",
      "loss: 0.124244  [11200/13920]\n",
      "loss: 0.088574  [11264/13920]\n",
      "loss: 0.232742  [11328/13920]\n",
      "loss: 0.108949  [11392/13920]\n",
      "loss: 0.132567  [11456/13920]\n",
      "loss: 0.127687  [11520/13920]\n",
      "loss: 0.065646  [11584/13920]\n",
      "loss: 0.071949  [11648/13920]\n",
      "loss: 0.169684  [11712/13920]\n",
      "loss: 0.156041  [11776/13920]\n",
      "loss: 0.056782  [11840/13920]\n",
      "loss: 0.030809  [11904/13920]\n",
      "loss: 0.127160  [11968/13920]\n",
      "loss: 0.078851  [12032/13920]\n",
      "loss: 0.052799  [12096/13920]\n",
      "loss: 0.096167  [12160/13920]\n",
      "loss: 0.064811  [12224/13920]\n",
      "loss: 0.106155  [12288/13920]\n",
      "loss: 0.035108  [12352/13920]\n",
      "loss: 0.069592  [12416/13920]\n",
      "loss: 0.092273  [12480/13920]\n",
      "loss: 0.113214  [12544/13920]\n",
      "loss: 0.035554  [12608/13920]\n",
      "loss: 0.076260  [12672/13920]\n",
      "loss: 0.024134  [12736/13920]\n",
      "loss: 0.085901  [12800/13920]\n",
      "loss: 0.050474  [12864/13920]\n",
      "loss: 0.042348  [12928/13920]\n",
      "loss: 0.083301  [12992/13920]\n",
      "loss: 0.133200  [13056/13920]\n",
      "loss: 0.076453  [13120/13920]\n",
      "loss: 0.061743  [13184/13920]\n",
      "loss: 0.115187  [13248/13920]\n",
      "loss: 0.067495  [13312/13920]\n",
      "loss: 0.087284  [13376/13920]\n",
      "loss: 0.126788  [13440/13920]\n",
      "loss: 0.056551  [13504/13920]\n",
      "loss: 0.056914  [13568/13920]\n",
      "loss: 0.156015  [13632/13920]\n",
      "loss: 0.068065  [13696/13920]\n",
      "loss: 0.083276  [13760/13920]\n",
      "loss: 0.067179  [13824/13920]\n",
      "loss: 0.195866  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.1% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.134982 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.024708  [    0/13920]\n",
      "loss: 0.036813  [   64/13920]\n",
      "loss: 0.049308  [  128/13920]\n",
      "loss: 0.063743  [  192/13920]\n",
      "loss: 0.057605  [  256/13920]\n",
      "loss: 0.171455  [  320/13920]\n",
      "loss: 0.097142  [  384/13920]\n",
      "loss: 0.083095  [  448/13920]\n",
      "loss: 0.058532  [  512/13920]\n",
      "loss: 0.078637  [  576/13920]\n",
      "loss: 0.046251  [  640/13920]\n",
      "loss: 0.102735  [  704/13920]\n",
      "loss: 0.042801  [  768/13920]\n",
      "loss: 0.063907  [  832/13920]\n",
      "loss: 0.083100  [  896/13920]\n",
      "loss: 0.075913  [  960/13920]\n",
      "loss: 0.160828  [ 1024/13920]\n",
      "loss: 0.116851  [ 1088/13920]\n",
      "loss: 0.046545  [ 1152/13920]\n",
      "loss: 0.041363  [ 1216/13920]\n",
      "loss: 0.119964  [ 1280/13920]\n",
      "loss: 0.116087  [ 1344/13920]\n",
      "loss: 0.086484  [ 1408/13920]\n",
      "loss: 0.050206  [ 1472/13920]\n",
      "loss: 0.095468  [ 1536/13920]\n",
      "loss: 0.086041  [ 1600/13920]\n",
      "loss: 0.113427  [ 1664/13920]\n",
      "loss: 0.036298  [ 1728/13920]\n",
      "loss: 0.040057  [ 1792/13920]\n",
      "loss: 0.041270  [ 1856/13920]\n",
      "loss: 0.037305  [ 1920/13920]\n",
      "loss: 0.083968  [ 1984/13920]\n",
      "loss: 0.107860  [ 2048/13920]\n",
      "loss: 0.053459  [ 2112/13920]\n",
      "loss: 0.043175  [ 2176/13920]\n",
      "loss: 0.108059  [ 2240/13920]\n",
      "loss: 0.126485  [ 2304/13920]\n",
      "loss: 0.061460  [ 2368/13920]\n",
      "loss: 0.030920  [ 2432/13920]\n",
      "loss: 0.098130  [ 2496/13920]\n",
      "loss: 0.110310  [ 2560/13920]\n",
      "loss: 0.042103  [ 2624/13920]\n",
      "loss: 0.045914  [ 2688/13920]\n",
      "loss: 0.050917  [ 2752/13920]\n",
      "loss: 0.077451  [ 2816/13920]\n",
      "loss: 0.041259  [ 2880/13920]\n",
      "loss: 0.047267  [ 2944/13920]\n",
      "loss: 0.075840  [ 3008/13920]\n",
      "loss: 0.068132  [ 3072/13920]\n",
      "loss: 0.051351  [ 3136/13920]\n",
      "loss: 0.041598  [ 3200/13920]\n",
      "loss: 0.046754  [ 3264/13920]\n",
      "loss: 0.043813  [ 3328/13920]\n",
      "loss: 0.050479  [ 3392/13920]\n",
      "loss: 0.077080  [ 3456/13920]\n",
      "loss: 0.050410  [ 3520/13920]\n",
      "loss: 0.086510  [ 3584/13920]\n",
      "loss: 0.072559  [ 3648/13920]\n",
      "loss: 0.119474  [ 3712/13920]\n",
      "loss: 0.137703  [ 3776/13920]\n",
      "loss: 0.091862  [ 3840/13920]\n",
      "loss: 0.024471  [ 3904/13920]\n",
      "loss: 0.128651  [ 3968/13920]\n",
      "loss: 0.012750  [ 4032/13920]\n",
      "loss: 0.094622  [ 4096/13920]\n",
      "loss: 0.093557  [ 4160/13920]\n",
      "loss: 0.056390  [ 4224/13920]\n",
      "loss: 0.143139  [ 4288/13920]\n",
      "loss: 0.070844  [ 4352/13920]\n",
      "loss: 0.086785  [ 4416/13920]\n",
      "loss: 0.090285  [ 4480/13920]\n",
      "loss: 0.048813  [ 4544/13920]\n",
      "loss: 0.019511  [ 4608/13920]\n",
      "loss: 0.025063  [ 4672/13920]\n",
      "loss: 0.072401  [ 4736/13920]\n",
      "loss: 0.041105  [ 4800/13920]\n",
      "loss: 0.135388  [ 4864/13920]\n",
      "loss: 0.037267  [ 4928/13920]\n",
      "loss: 0.065810  [ 4992/13920]\n",
      "loss: 0.058886  [ 5056/13920]\n",
      "loss: 0.042551  [ 5120/13920]\n",
      "loss: 0.065129  [ 5184/13920]\n",
      "loss: 0.057072  [ 5248/13920]\n",
      "loss: 0.188612  [ 5312/13920]\n",
      "loss: 0.081703  [ 5376/13920]\n",
      "loss: 0.035984  [ 5440/13920]\n",
      "loss: 0.052898  [ 5504/13920]\n",
      "loss: 0.120956  [ 5568/13920]\n",
      "loss: 0.037246  [ 5632/13920]\n",
      "loss: 0.066304  [ 5696/13920]\n",
      "loss: 0.050293  [ 5760/13920]\n",
      "loss: 0.083008  [ 5824/13920]\n",
      "loss: 0.044732  [ 5888/13920]\n",
      "loss: 0.094090  [ 5952/13920]\n",
      "loss: 0.057631  [ 6016/13920]\n",
      "loss: 0.052507  [ 6080/13920]\n",
      "loss: 0.039218  [ 6144/13920]\n",
      "loss: 0.101995  [ 6208/13920]\n",
      "loss: 0.073617  [ 6272/13920]\n",
      "loss: 0.059860  [ 6336/13920]\n",
      "loss: 0.089770  [ 6400/13920]\n",
      "loss: 0.031204  [ 6464/13920]\n",
      "loss: 0.122678  [ 6528/13920]\n",
      "loss: 0.111270  [ 6592/13920]\n",
      "loss: 0.053030  [ 6656/13920]\n",
      "loss: 0.063126  [ 6720/13920]\n",
      "loss: 0.120787  [ 6784/13920]\n",
      "loss: 0.152095  [ 6848/13920]\n",
      "loss: 0.170942  [ 6912/13920]\n",
      "loss: 0.082873  [ 6976/13920]\n",
      "loss: 0.076192  [ 7040/13920]\n",
      "loss: 0.114416  [ 7104/13920]\n",
      "loss: 0.088026  [ 7168/13920]\n",
      "loss: 0.223240  [ 7232/13920]\n",
      "loss: 0.046138  [ 7296/13920]\n",
      "loss: 0.050895  [ 7360/13920]\n",
      "loss: 0.075532  [ 7424/13920]\n",
      "loss: 0.064217  [ 7488/13920]\n",
      "loss: 0.063169  [ 7552/13920]\n",
      "loss: 0.095969  [ 7616/13920]\n",
      "loss: 0.079407  [ 7680/13920]\n",
      "loss: 0.126039  [ 7744/13920]\n",
      "loss: 0.026844  [ 7808/13920]\n",
      "loss: 0.051440  [ 7872/13920]\n",
      "loss: 0.060465  [ 7936/13920]\n",
      "loss: 0.068135  [ 8000/13920]\n",
      "loss: 0.041454  [ 8064/13920]\n",
      "loss: 0.058912  [ 8128/13920]\n",
      "loss: 0.152059  [ 8192/13920]\n",
      "loss: 0.026245  [ 8256/13920]\n",
      "loss: 0.022070  [ 8320/13920]\n",
      "loss: 0.076192  [ 8384/13920]\n",
      "loss: 0.053455  [ 8448/13920]\n",
      "loss: 0.103070  [ 8512/13920]\n",
      "loss: 0.059662  [ 8576/13920]\n",
      "loss: 0.042850  [ 8640/13920]\n",
      "loss: 0.167753  [ 8704/13920]\n",
      "loss: 0.055056  [ 8768/13920]\n",
      "loss: 0.039302  [ 8832/13920]\n",
      "loss: 0.137451  [ 8896/13920]\n",
      "loss: 0.042785  [ 8960/13920]\n",
      "loss: 0.066586  [ 9024/13920]\n",
      "loss: 0.119868  [ 9088/13920]\n",
      "loss: 0.057495  [ 9152/13920]\n",
      "loss: 0.052157  [ 9216/13920]\n",
      "loss: 0.082278  [ 9280/13920]\n",
      "loss: 0.028522  [ 9344/13920]\n",
      "loss: 0.042278  [ 9408/13920]\n",
      "loss: 0.023987  [ 9472/13920]\n",
      "loss: 0.048820  [ 9536/13920]\n",
      "loss: 0.075140  [ 9600/13920]\n",
      "loss: 0.073724  [ 9664/13920]\n",
      "loss: 0.056146  [ 9728/13920]\n",
      "loss: 0.031118  [ 9792/13920]\n",
      "loss: 0.048097  [ 9856/13920]\n",
      "loss: 0.156405  [ 9920/13920]\n",
      "loss: 0.048936  [ 9984/13920]\n",
      "loss: 0.007987  [10048/13920]\n",
      "loss: 0.087749  [10112/13920]\n",
      "loss: 0.039609  [10176/13920]\n",
      "loss: 0.094991  [10240/13920]\n",
      "loss: 0.087225  [10304/13920]\n",
      "loss: 0.047826  [10368/13920]\n",
      "loss: 0.066358  [10432/13920]\n",
      "loss: 0.118838  [10496/13920]\n",
      "loss: 0.033192  [10560/13920]\n",
      "loss: 0.066115  [10624/13920]\n",
      "loss: 0.024441  [10688/13920]\n",
      "loss: 0.188533  [10752/13920]\n",
      "loss: 0.039154  [10816/13920]\n",
      "loss: 0.110238  [10880/13920]\n",
      "loss: 0.083264  [10944/13920]\n",
      "loss: 0.017208  [11008/13920]\n",
      "loss: 0.052001  [11072/13920]\n",
      "loss: 0.073334  [11136/13920]\n",
      "loss: 0.110642  [11200/13920]\n",
      "loss: 0.033041  [11264/13920]\n",
      "loss: 0.095488  [11328/13920]\n",
      "loss: 0.033950  [11392/13920]\n",
      "loss: 0.212939  [11456/13920]\n",
      "loss: 0.056981  [11520/13920]\n",
      "loss: 0.063120  [11584/13920]\n",
      "loss: 0.121536  [11648/13920]\n",
      "loss: 0.084478  [11712/13920]\n",
      "loss: 0.163725  [11776/13920]\n",
      "loss: 0.022483  [11840/13920]\n",
      "loss: 0.031021  [11904/13920]\n",
      "loss: 0.081856  [11968/13920]\n",
      "loss: 0.019618  [12032/13920]\n",
      "loss: 0.124770  [12096/13920]\n",
      "loss: 0.108554  [12160/13920]\n",
      "loss: 0.177530  [12224/13920]\n",
      "loss: 0.098813  [12288/13920]\n",
      "loss: 0.055072  [12352/13920]\n",
      "loss: 0.038233  [12416/13920]\n",
      "loss: 0.059717  [12480/13920]\n",
      "loss: 0.055403  [12544/13920]\n",
      "loss: 0.034989  [12608/13920]\n",
      "loss: 0.118217  [12672/13920]\n",
      "loss: 0.087907  [12736/13920]\n",
      "loss: 0.097769  [12800/13920]\n",
      "loss: 0.041452  [12864/13920]\n",
      "loss: 0.025724  [12928/13920]\n",
      "loss: 0.068261  [12992/13920]\n",
      "loss: 0.075270  [13056/13920]\n",
      "loss: 0.025385  [13120/13920]\n",
      "loss: 0.028099  [13184/13920]\n",
      "loss: 0.068495  [13248/13920]\n",
      "loss: 0.037245  [13312/13920]\n",
      "loss: 0.128593  [13376/13920]\n",
      "loss: 0.030578  [13440/13920]\n",
      "loss: 0.145666  [13504/13920]\n",
      "loss: 0.081158  [13568/13920]\n",
      "loss: 0.067669  [13632/13920]\n",
      "loss: 0.094213  [13696/13920]\n",
      "loss: 0.132090  [13760/13920]\n",
      "loss: 0.124432  [13824/13920]\n",
      "loss: 0.074985  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.5% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.126978 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.037051  [    0/13920]\n",
      "loss: 0.037594  [   64/13920]\n",
      "loss: 0.044862  [  128/13920]\n",
      "loss: 0.029161  [  192/13920]\n",
      "loss: 0.052150  [  256/13920]\n",
      "loss: 0.068368  [  320/13920]\n",
      "loss: 0.043009  [  384/13920]\n",
      "loss: 0.154503  [  448/13920]\n",
      "loss: 0.042953  [  512/13920]\n",
      "loss: 0.027499  [  576/13920]\n",
      "loss: 0.093127  [  640/13920]\n",
      "loss: 0.163232  [  704/13920]\n",
      "loss: 0.061529  [  768/13920]\n",
      "loss: 0.084051  [  832/13920]\n",
      "loss: 0.036374  [  896/13920]\n",
      "loss: 0.049673  [  960/13920]\n",
      "loss: 0.053014  [ 1024/13920]\n",
      "loss: 0.024037  [ 1088/13920]\n",
      "loss: 0.069464  [ 1152/13920]\n",
      "loss: 0.051477  [ 1216/13920]\n",
      "loss: 0.016435  [ 1280/13920]\n",
      "loss: 0.011061  [ 1344/13920]\n",
      "loss: 0.066253  [ 1408/13920]\n",
      "loss: 0.025898  [ 1472/13920]\n",
      "loss: 0.089402  [ 1536/13920]\n",
      "loss: 0.054478  [ 1600/13920]\n",
      "loss: 0.072978  [ 1664/13920]\n",
      "loss: 0.024962  [ 1728/13920]\n",
      "loss: 0.032165  [ 1792/13920]\n",
      "loss: 0.099609  [ 1856/13920]\n",
      "loss: 0.066598  [ 1920/13920]\n",
      "loss: 0.090359  [ 1984/13920]\n",
      "loss: 0.154369  [ 2048/13920]\n",
      "loss: 0.049060  [ 2112/13920]\n",
      "loss: 0.042875  [ 2176/13920]\n",
      "loss: 0.095942  [ 2240/13920]\n",
      "loss: 0.052682  [ 2304/13920]\n",
      "loss: 0.073285  [ 2368/13920]\n",
      "loss: 0.038975  [ 2432/13920]\n",
      "loss: 0.011169  [ 2496/13920]\n",
      "loss: 0.139074  [ 2560/13920]\n",
      "loss: 0.073400  [ 2624/13920]\n",
      "loss: 0.164845  [ 2688/13920]\n",
      "loss: 0.046273  [ 2752/13920]\n",
      "loss: 0.042050  [ 2816/13920]\n",
      "loss: 0.087306  [ 2880/13920]\n",
      "loss: 0.052236  [ 2944/13920]\n",
      "loss: 0.039059  [ 3008/13920]\n",
      "loss: 0.046640  [ 3072/13920]\n",
      "loss: 0.127917  [ 3136/13920]\n",
      "loss: 0.075617  [ 3200/13920]\n",
      "loss: 0.092200  [ 3264/13920]\n",
      "loss: 0.047655  [ 3328/13920]\n",
      "loss: 0.216850  [ 3392/13920]\n",
      "loss: 0.073874  [ 3456/13920]\n",
      "loss: 0.021991  [ 3520/13920]\n",
      "loss: 0.022149  [ 3584/13920]\n",
      "loss: 0.074466  [ 3648/13920]\n",
      "loss: 0.027623  [ 3712/13920]\n",
      "loss: 0.152389  [ 3776/13920]\n",
      "loss: 0.077674  [ 3840/13920]\n",
      "loss: 0.038306  [ 3904/13920]\n",
      "loss: 0.117060  [ 3968/13920]\n",
      "loss: 0.034573  [ 4032/13920]\n",
      "loss: 0.159583  [ 4096/13920]\n",
      "loss: 0.132931  [ 4160/13920]\n",
      "loss: 0.077716  [ 4224/13920]\n",
      "loss: 0.045874  [ 4288/13920]\n",
      "loss: 0.041713  [ 4352/13920]\n",
      "loss: 0.098307  [ 4416/13920]\n",
      "loss: 0.056940  [ 4480/13920]\n",
      "loss: 0.241395  [ 4544/13920]\n",
      "loss: 0.044316  [ 4608/13920]\n",
      "loss: 0.057525  [ 4672/13920]\n",
      "loss: 0.078179  [ 4736/13920]\n",
      "loss: 0.086805  [ 4800/13920]\n",
      "loss: 0.026717  [ 4864/13920]\n",
      "loss: 0.104123  [ 4928/13920]\n",
      "loss: 0.070396  [ 4992/13920]\n",
      "loss: 0.070995  [ 5056/13920]\n",
      "loss: 0.113171  [ 5120/13920]\n",
      "loss: 0.028005  [ 5184/13920]\n",
      "loss: 0.011876  [ 5248/13920]\n",
      "loss: 0.038492  [ 5312/13920]\n",
      "loss: 0.059270  [ 5376/13920]\n",
      "loss: 0.085672  [ 5440/13920]\n",
      "loss: 0.056139  [ 5504/13920]\n",
      "loss: 0.168527  [ 5568/13920]\n",
      "loss: 0.037923  [ 5632/13920]\n",
      "loss: 0.103439  [ 5696/13920]\n",
      "loss: 0.032800  [ 5760/13920]\n",
      "loss: 0.206491  [ 5824/13920]\n",
      "loss: 0.120168  [ 5888/13920]\n",
      "loss: 0.062765  [ 5952/13920]\n",
      "loss: 0.117485  [ 6016/13920]\n",
      "loss: 0.047855  [ 6080/13920]\n",
      "loss: 0.036275  [ 6144/13920]\n",
      "loss: 0.086819  [ 6208/13920]\n",
      "loss: 0.179345  [ 6272/13920]\n",
      "loss: 0.164127  [ 6336/13920]\n",
      "loss: 0.018178  [ 6400/13920]\n",
      "loss: 0.039493  [ 6464/13920]\n",
      "loss: 0.072188  [ 6528/13920]\n",
      "loss: 0.045549  [ 6592/13920]\n",
      "loss: 0.083831  [ 6656/13920]\n",
      "loss: 0.080651  [ 6720/13920]\n",
      "loss: 0.093894  [ 6784/13920]\n",
      "loss: 0.076738  [ 6848/13920]\n",
      "loss: 0.040823  [ 6912/13920]\n",
      "loss: 0.106446  [ 6976/13920]\n",
      "loss: 0.062594  [ 7040/13920]\n",
      "loss: 0.260096  [ 7104/13920]\n",
      "loss: 0.193072  [ 7168/13920]\n",
      "loss: 0.086895  [ 7232/13920]\n",
      "loss: 0.020641  [ 7296/13920]\n",
      "loss: 0.081065  [ 7360/13920]\n",
      "loss: 0.032676  [ 7424/13920]\n",
      "loss: 0.039577  [ 7488/13920]\n",
      "loss: 0.066635  [ 7552/13920]\n",
      "loss: 0.038713  [ 7616/13920]\n",
      "loss: 0.144128  [ 7680/13920]\n",
      "loss: 0.064742  [ 7744/13920]\n",
      "loss: 0.059625  [ 7808/13920]\n",
      "loss: 0.088546  [ 7872/13920]\n",
      "loss: 0.088922  [ 7936/13920]\n",
      "loss: 0.017037  [ 8000/13920]\n",
      "loss: 0.046719  [ 8064/13920]\n",
      "loss: 0.082815  [ 8128/13920]\n",
      "loss: 0.057377  [ 8192/13920]\n",
      "loss: 0.060924  [ 8256/13920]\n",
      "loss: 0.206141  [ 8320/13920]\n",
      "loss: 0.089152  [ 8384/13920]\n",
      "loss: 0.151535  [ 8448/13920]\n",
      "loss: 0.020843  [ 8512/13920]\n",
      "loss: 0.066907  [ 8576/13920]\n",
      "loss: 0.094426  [ 8640/13920]\n",
      "loss: 0.072172  [ 8704/13920]\n",
      "loss: 0.085203  [ 8768/13920]\n",
      "loss: 0.074416  [ 8832/13920]\n",
      "loss: 0.050249  [ 8896/13920]\n",
      "loss: 0.100630  [ 8960/13920]\n",
      "loss: 0.040125  [ 9024/13920]\n",
      "loss: 0.061260  [ 9088/13920]\n",
      "loss: 0.107059  [ 9152/13920]\n",
      "loss: 0.055837  [ 9216/13920]\n",
      "loss: 0.065542  [ 9280/13920]\n",
      "loss: 0.033782  [ 9344/13920]\n",
      "loss: 0.085574  [ 9408/13920]\n",
      "loss: 0.080049  [ 9472/13920]\n",
      "loss: 0.055956  [ 9536/13920]\n",
      "loss: 0.053930  [ 9600/13920]\n",
      "loss: 0.048053  [ 9664/13920]\n",
      "loss: 0.057805  [ 9728/13920]\n",
      "loss: 0.076201  [ 9792/13920]\n",
      "loss: 0.087536  [ 9856/13920]\n",
      "loss: 0.109620  [ 9920/13920]\n",
      "loss: 0.044332  [ 9984/13920]\n",
      "loss: 0.042154  [10048/13920]\n",
      "loss: 0.061652  [10112/13920]\n",
      "loss: 0.154442  [10176/13920]\n",
      "loss: 0.141198  [10240/13920]\n",
      "loss: 0.200120  [10304/13920]\n",
      "loss: 0.061488  [10368/13920]\n",
      "loss: 0.066431  [10432/13920]\n",
      "loss: 0.024757  [10496/13920]\n",
      "loss: 0.053403  [10560/13920]\n",
      "loss: 0.100462  [10624/13920]\n",
      "loss: 0.029503  [10688/13920]\n",
      "loss: 0.046827  [10752/13920]\n",
      "loss: 0.021574  [10816/13920]\n",
      "loss: 0.046194  [10880/13920]\n",
      "loss: 0.018684  [10944/13920]\n",
      "loss: 0.113428  [11008/13920]\n",
      "loss: 0.036164  [11072/13920]\n",
      "loss: 0.015447  [11136/13920]\n",
      "loss: 0.078655  [11200/13920]\n",
      "loss: 0.061912  [11264/13920]\n",
      "loss: 0.058175  [11328/13920]\n",
      "loss: 0.097705  [11392/13920]\n",
      "loss: 0.065099  [11456/13920]\n",
      "loss: 0.114018  [11520/13920]\n",
      "loss: 0.054509  [11584/13920]\n",
      "loss: 0.041935  [11648/13920]\n",
      "loss: 0.027597  [11712/13920]\n",
      "loss: 0.068209  [11776/13920]\n",
      "loss: 0.032060  [11840/13920]\n",
      "loss: 0.028288  [11904/13920]\n",
      "loss: 0.013482  [11968/13920]\n",
      "loss: 0.106201  [12032/13920]\n",
      "loss: 0.107122  [12096/13920]\n",
      "loss: 0.054238  [12160/13920]\n",
      "loss: 0.041071  [12224/13920]\n",
      "loss: 0.028091  [12288/13920]\n",
      "loss: 0.110189  [12352/13920]\n",
      "loss: 0.027880  [12416/13920]\n",
      "loss: 0.055611  [12480/13920]\n",
      "loss: 0.096105  [12544/13920]\n",
      "loss: 0.090487  [12608/13920]\n",
      "loss: 0.052947  [12672/13920]\n",
      "loss: 0.035826  [12736/13920]\n",
      "loss: 0.079626  [12800/13920]\n",
      "loss: 0.077949  [12864/13920]\n",
      "loss: 0.052367  [12928/13920]\n",
      "loss: 0.031505  [12992/13920]\n",
      "loss: 0.084883  [13056/13920]\n",
      "loss: 0.035969  [13120/13920]\n",
      "loss: 0.062409  [13184/13920]\n",
      "loss: 0.158581  [13248/13920]\n",
      "loss: 0.075970  [13312/13920]\n",
      "loss: 0.060212  [13376/13920]\n",
      "loss: 0.038456  [13440/13920]\n",
      "loss: 0.036092  [13504/13920]\n",
      "loss: 0.113268  [13568/13920]\n",
      "loss: 0.059549  [13632/13920]\n",
      "loss: 0.058475  [13696/13920]\n",
      "loss: 0.077864  [13760/13920]\n",
      "loss: 0.024711  [13824/13920]\n",
      "loss: 0.054590  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.6% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.132979 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.340046  [    0/13920]\n",
      "loss: 1.195500  [   64/13920]\n",
      "loss: 1.028573  [  128/13920]\n",
      "loss: 1.070065  [  192/13920]\n",
      "loss: 0.965844  [  256/13920]\n",
      "loss: 0.955288  [  320/13920]\n",
      "loss: 1.099300  [  384/13920]\n",
      "loss: 1.030276  [  448/13920]\n",
      "loss: 0.972050  [  512/13920]\n",
      "loss: 0.970850  [  576/13920]\n",
      "loss: 0.944693  [  640/13920]\n",
      "loss: 0.855430  [  704/13920]\n",
      "loss: 1.059395  [  768/13920]\n",
      "loss: 0.971825  [  832/13920]\n",
      "loss: 0.924456  [  896/13920]\n",
      "loss: 0.938419  [  960/13920]\n",
      "loss: 0.799213  [ 1024/13920]\n",
      "loss: 0.896955  [ 1088/13920]\n",
      "loss: 0.870259  [ 1152/13920]\n",
      "loss: 0.864949  [ 1216/13920]\n",
      "loss: 0.858010  [ 1280/13920]\n",
      "loss: 0.852096  [ 1344/13920]\n",
      "loss: 0.817193  [ 1408/13920]\n",
      "loss: 0.873509  [ 1472/13920]\n",
      "loss: 0.867116  [ 1536/13920]\n",
      "loss: 0.989116  [ 1600/13920]\n",
      "loss: 0.907217  [ 1664/13920]\n",
      "loss: 0.877613  [ 1728/13920]\n",
      "loss: 0.802226  [ 1792/13920]\n",
      "loss: 0.849668  [ 1856/13920]\n",
      "loss: 0.955992  [ 1920/13920]\n",
      "loss: 0.875415  [ 1984/13920]\n",
      "loss: 0.807832  [ 2048/13920]\n",
      "loss: 0.889090  [ 2112/13920]\n",
      "loss: 1.014243  [ 2176/13920]\n",
      "loss: 0.882695  [ 2240/13920]\n",
      "loss: 0.784729  [ 2304/13920]\n",
      "loss: 0.785737  [ 2368/13920]\n",
      "loss: 0.885869  [ 2432/13920]\n",
      "loss: 0.900185  [ 2496/13920]\n",
      "loss: 0.804426  [ 2560/13920]\n",
      "loss: 0.758234  [ 2624/13920]\n",
      "loss: 0.811421  [ 2688/13920]\n",
      "loss: 0.839393  [ 2752/13920]\n",
      "loss: 0.870975  [ 2816/13920]\n",
      "loss: 0.783854  [ 2880/13920]\n",
      "loss: 0.720284  [ 2944/13920]\n",
      "loss: 0.787042  [ 3008/13920]\n",
      "loss: 0.914255  [ 3072/13920]\n",
      "loss: 0.681182  [ 3136/13920]\n",
      "loss: 0.962572  [ 3200/13920]\n",
      "loss: 0.725085  [ 3264/13920]\n",
      "loss: 0.917033  [ 3328/13920]\n",
      "loss: 0.811301  [ 3392/13920]\n",
      "loss: 0.862861  [ 3456/13920]\n",
      "loss: 0.937073  [ 3520/13920]\n",
      "loss: 0.851020  [ 3584/13920]\n",
      "loss: 0.772028  [ 3648/13920]\n",
      "loss: 0.793591  [ 3712/13920]\n",
      "loss: 0.798260  [ 3776/13920]\n",
      "loss: 0.716196  [ 3840/13920]\n",
      "loss: 0.814216  [ 3904/13920]\n",
      "loss: 0.727205  [ 3968/13920]\n",
      "loss: 0.823605  [ 4032/13920]\n",
      "loss: 0.810291  [ 4096/13920]\n",
      "loss: 0.835291  [ 4160/13920]\n",
      "loss: 0.895189  [ 4224/13920]\n",
      "loss: 0.789395  [ 4288/13920]\n",
      "loss: 0.774160  [ 4352/13920]\n",
      "loss: 0.816061  [ 4416/13920]\n",
      "loss: 0.793247  [ 4480/13920]\n",
      "loss: 0.742887  [ 4544/13920]\n",
      "loss: 0.824471  [ 4608/13920]\n",
      "loss: 0.692537  [ 4672/13920]\n",
      "loss: 0.821779  [ 4736/13920]\n",
      "loss: 0.728634  [ 4800/13920]\n",
      "loss: 0.656288  [ 4864/13920]\n",
      "loss: 0.656723  [ 4928/13920]\n",
      "loss: 0.615109  [ 4992/13920]\n",
      "loss: 0.842561  [ 5056/13920]\n",
      "loss: 0.871598  [ 5120/13920]\n",
      "loss: 0.794241  [ 5184/13920]\n",
      "loss: 0.745124  [ 5248/13920]\n",
      "loss: 0.705593  [ 5312/13920]\n",
      "loss: 0.804898  [ 5376/13920]\n",
      "loss: 0.622539  [ 5440/13920]\n",
      "loss: 0.808967  [ 5504/13920]\n",
      "loss: 0.730882  [ 5568/13920]\n",
      "loss: 0.672472  [ 5632/13920]\n",
      "loss: 0.682113  [ 5696/13920]\n",
      "loss: 0.652552  [ 5760/13920]\n",
      "loss: 0.824273  [ 5824/13920]\n",
      "loss: 0.809204  [ 5888/13920]\n",
      "loss: 0.818989  [ 5952/13920]\n",
      "loss: 0.720446  [ 6016/13920]\n",
      "loss: 0.708515  [ 6080/13920]\n",
      "loss: 0.624961  [ 6144/13920]\n",
      "loss: 0.582463  [ 6208/13920]\n",
      "loss: 0.767609  [ 6272/13920]\n",
      "loss: 0.667034  [ 6336/13920]\n",
      "loss: 0.674947  [ 6400/13920]\n",
      "loss: 0.584714  [ 6464/13920]\n",
      "loss: 0.804344  [ 6528/13920]\n",
      "loss: 0.653919  [ 6592/13920]\n",
      "loss: 0.737963  [ 6656/13920]\n",
      "loss: 0.709541  [ 6720/13920]\n",
      "loss: 0.815889  [ 6784/13920]\n",
      "loss: 0.678578  [ 6848/13920]\n",
      "loss: 0.635829  [ 6912/13920]\n",
      "loss: 0.615531  [ 6976/13920]\n",
      "loss: 0.638753  [ 7040/13920]\n",
      "loss: 0.701386  [ 7104/13920]\n",
      "loss: 0.698673  [ 7168/13920]\n",
      "loss: 0.618202  [ 7232/13920]\n",
      "loss: 0.561032  [ 7296/13920]\n",
      "loss: 0.557994  [ 7360/13920]\n",
      "loss: 0.977193  [ 7424/13920]\n",
      "loss: 0.711712  [ 7488/13920]\n",
      "loss: 0.729214  [ 7552/13920]\n",
      "loss: 0.665538  [ 7616/13920]\n",
      "loss: 0.663816  [ 7680/13920]\n",
      "loss: 0.599105  [ 7744/13920]\n",
      "loss: 0.618781  [ 7808/13920]\n",
      "loss: 0.643150  [ 7872/13920]\n",
      "loss: 0.760561  [ 7936/13920]\n",
      "loss: 0.613854  [ 8000/13920]\n",
      "loss: 0.622828  [ 8064/13920]\n",
      "loss: 0.735289  [ 8128/13920]\n",
      "loss: 0.704988  [ 8192/13920]\n",
      "loss: 0.592097  [ 8256/13920]\n",
      "loss: 0.626692  [ 8320/13920]\n",
      "loss: 0.638856  [ 8384/13920]\n",
      "loss: 0.583058  [ 8448/13920]\n",
      "loss: 0.719097  [ 8512/13920]\n",
      "loss: 0.596065  [ 8576/13920]\n",
      "loss: 0.620380  [ 8640/13920]\n",
      "loss: 0.688726  [ 8704/13920]\n",
      "loss: 0.544011  [ 8768/13920]\n",
      "loss: 0.572174  [ 8832/13920]\n",
      "loss: 0.633946  [ 8896/13920]\n",
      "loss: 0.581362  [ 8960/13920]\n",
      "loss: 0.590220  [ 9024/13920]\n",
      "loss: 0.574937  [ 9088/13920]\n",
      "loss: 0.592718  [ 9152/13920]\n",
      "loss: 0.656541  [ 9216/13920]\n",
      "loss: 0.778156  [ 9280/13920]\n",
      "loss: 0.614889  [ 9344/13920]\n",
      "loss: 0.782146  [ 9408/13920]\n",
      "loss: 0.656156  [ 9472/13920]\n",
      "loss: 0.688216  [ 9536/13920]\n",
      "loss: 0.618161  [ 9600/13920]\n",
      "loss: 0.557117  [ 9664/13920]\n",
      "loss: 0.702366  [ 9728/13920]\n",
      "loss: 0.598438  [ 9792/13920]\n",
      "loss: 0.576841  [ 9856/13920]\n",
      "loss: 0.699250  [ 9920/13920]\n",
      "loss: 0.679556  [ 9984/13920]\n",
      "loss: 0.620425  [10048/13920]\n",
      "loss: 0.745994  [10112/13920]\n",
      "loss: 0.549828  [10176/13920]\n",
      "loss: 0.616437  [10240/13920]\n",
      "loss: 0.551966  [10304/13920]\n",
      "loss: 0.473365  [10368/13920]\n",
      "loss: 0.700906  [10432/13920]\n",
      "loss: 0.667987  [10496/13920]\n",
      "loss: 0.732766  [10560/13920]\n",
      "loss: 0.669872  [10624/13920]\n",
      "loss: 0.619211  [10688/13920]\n",
      "loss: 0.578603  [10752/13920]\n",
      "loss: 0.545591  [10816/13920]\n",
      "loss: 0.703662  [10880/13920]\n",
      "loss: 0.621017  [10944/13920]\n",
      "loss: 0.541052  [11008/13920]\n",
      "loss: 0.571787  [11072/13920]\n",
      "loss: 0.660515  [11136/13920]\n",
      "loss: 0.543191  [11200/13920]\n",
      "loss: 0.654122  [11264/13920]\n",
      "loss: 0.556340  [11328/13920]\n",
      "loss: 0.500424  [11392/13920]\n",
      "loss: 0.610133  [11456/13920]\n",
      "loss: 0.521349  [11520/13920]\n",
      "loss: 0.589334  [11584/13920]\n",
      "loss: 0.669041  [11648/13920]\n",
      "loss: 0.774545  [11712/13920]\n",
      "loss: 0.513699  [11776/13920]\n",
      "loss: 0.476746  [11840/13920]\n",
      "loss: 0.621988  [11904/13920]\n",
      "loss: 0.703691  [11968/13920]\n",
      "loss: 0.588339  [12032/13920]\n",
      "loss: 0.593529  [12096/13920]\n",
      "loss: 0.560322  [12160/13920]\n",
      "loss: 0.591065  [12224/13920]\n",
      "loss: 0.634519  [12288/13920]\n",
      "loss: 0.556759  [12352/13920]\n",
      "loss: 0.727356  [12416/13920]\n",
      "loss: 0.534328  [12480/13920]\n",
      "loss: 0.495642  [12544/13920]\n",
      "loss: 0.563370  [12608/13920]\n",
      "loss: 0.547424  [12672/13920]\n",
      "loss: 0.628023  [12736/13920]\n",
      "loss: 0.522286  [12800/13920]\n",
      "loss: 0.576673  [12864/13920]\n",
      "loss: 0.525919  [12928/13920]\n",
      "loss: 0.426863  [12992/13920]\n",
      "loss: 0.501577  [13056/13920]\n",
      "loss: 0.461079  [13120/13920]\n",
      "loss: 0.603070  [13184/13920]\n",
      "loss: 0.691742  [13248/13920]\n",
      "loss: 0.603664  [13312/13920]\n",
      "loss: 0.502219  [13376/13920]\n",
      "loss: 0.528194  [13440/13920]\n",
      "loss: 0.533496  [13504/13920]\n",
      "loss: 0.424553  [13568/13920]\n",
      "loss: 0.664823  [13632/13920]\n",
      "loss: 0.564641  [13696/13920]\n",
      "loss: 0.687432  [13760/13920]\n",
      "loss: 0.476243  [13824/13920]\n",
      "loss: 0.449224  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 68.3% \n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.550352 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.493521  [    0/13920]\n",
      "loss: 0.436548  [   64/13920]\n",
      "loss: 0.519825  [  128/13920]\n",
      "loss: 0.479698  [  192/13920]\n",
      "loss: 0.438167  [  256/13920]\n",
      "loss: 0.498286  [  320/13920]\n",
      "loss: 0.469801  [  384/13920]\n",
      "loss: 0.551914  [  448/13920]\n",
      "loss: 0.438578  [  512/13920]\n",
      "loss: 0.445882  [  576/13920]\n",
      "loss: 0.535720  [  640/13920]\n",
      "loss: 0.530628  [  704/13920]\n",
      "loss: 0.440695  [  768/13920]\n",
      "loss: 0.518517  [  832/13920]\n",
      "loss: 0.432071  [  896/13920]\n",
      "loss: 0.401844  [  960/13920]\n",
      "loss: 0.446481  [ 1024/13920]\n",
      "loss: 0.519283  [ 1088/13920]\n",
      "loss: 0.608791  [ 1152/13920]\n",
      "loss: 0.428075  [ 1216/13920]\n",
      "loss: 0.396561  [ 1280/13920]\n",
      "loss: 0.457408  [ 1344/13920]\n",
      "loss: 0.699182  [ 1408/13920]\n",
      "loss: 0.402015  [ 1472/13920]\n",
      "loss: 0.419202  [ 1536/13920]\n",
      "loss: 0.517736  [ 1600/13920]\n",
      "loss: 0.440460  [ 1664/13920]\n",
      "loss: 0.498823  [ 1728/13920]\n",
      "loss: 0.683029  [ 1792/13920]\n",
      "loss: 0.473010  [ 1856/13920]\n",
      "loss: 0.518618  [ 1920/13920]\n",
      "loss: 0.474124  [ 1984/13920]\n",
      "loss: 0.453867  [ 2048/13920]\n",
      "loss: 0.411590  [ 2112/13920]\n",
      "loss: 0.418320  [ 2176/13920]\n",
      "loss: 0.476849  [ 2240/13920]\n",
      "loss: 0.569070  [ 2304/13920]\n",
      "loss: 0.499321  [ 2368/13920]\n",
      "loss: 0.466243  [ 2432/13920]\n",
      "loss: 0.376183  [ 2496/13920]\n",
      "loss: 0.495102  [ 2560/13920]\n",
      "loss: 0.488798  [ 2624/13920]\n",
      "loss: 0.539552  [ 2688/13920]\n",
      "loss: 0.557162  [ 2752/13920]\n",
      "loss: 0.543671  [ 2816/13920]\n",
      "loss: 0.600211  [ 2880/13920]\n",
      "loss: 0.540231  [ 2944/13920]\n",
      "loss: 0.514368  [ 3008/13920]\n",
      "loss: 0.536057  [ 3072/13920]\n",
      "loss: 0.418714  [ 3136/13920]\n",
      "loss: 0.446704  [ 3200/13920]\n",
      "loss: 0.445825  [ 3264/13920]\n",
      "loss: 0.462908  [ 3328/13920]\n",
      "loss: 0.485317  [ 3392/13920]\n",
      "loss: 0.461369  [ 3456/13920]\n",
      "loss: 0.461651  [ 3520/13920]\n",
      "loss: 0.692334  [ 3584/13920]\n",
      "loss: 0.359076  [ 3648/13920]\n",
      "loss: 0.386731  [ 3712/13920]\n",
      "loss: 0.472389  [ 3776/13920]\n",
      "loss: 0.348024  [ 3840/13920]\n",
      "loss: 0.440279  [ 3904/13920]\n",
      "loss: 0.367672  [ 3968/13920]\n",
      "loss: 0.583159  [ 4032/13920]\n",
      "loss: 0.355809  [ 4096/13920]\n",
      "loss: 0.568482  [ 4160/13920]\n",
      "loss: 0.461619  [ 4224/13920]\n",
      "loss: 0.605316  [ 4288/13920]\n",
      "loss: 0.456672  [ 4352/13920]\n",
      "loss: 0.466670  [ 4416/13920]\n",
      "loss: 0.478652  [ 4480/13920]\n",
      "loss: 0.463424  [ 4544/13920]\n",
      "loss: 0.371948  [ 4608/13920]\n",
      "loss: 0.504413  [ 4672/13920]\n",
      "loss: 0.456211  [ 4736/13920]\n",
      "loss: 0.545272  [ 4800/13920]\n",
      "loss: 0.429507  [ 4864/13920]\n",
      "loss: 0.390693  [ 4928/13920]\n",
      "loss: 0.416228  [ 4992/13920]\n",
      "loss: 0.391158  [ 5056/13920]\n",
      "loss: 0.462585  [ 5120/13920]\n",
      "loss: 0.497754  [ 5184/13920]\n",
      "loss: 0.463076  [ 5248/13920]\n",
      "loss: 0.492296  [ 5312/13920]\n",
      "loss: 0.335203  [ 5376/13920]\n",
      "loss: 0.353547  [ 5440/13920]\n",
      "loss: 0.439401  [ 5504/13920]\n",
      "loss: 0.535498  [ 5568/13920]\n",
      "loss: 0.547346  [ 5632/13920]\n",
      "loss: 0.335671  [ 5696/13920]\n",
      "loss: 0.399732  [ 5760/13920]\n",
      "loss: 0.373517  [ 5824/13920]\n",
      "loss: 0.469011  [ 5888/13920]\n",
      "loss: 0.435353  [ 5952/13920]\n",
      "loss: 0.426116  [ 6016/13920]\n",
      "loss: 0.356945  [ 6080/13920]\n",
      "loss: 0.307819  [ 6144/13920]\n",
      "loss: 0.472465  [ 6208/13920]\n",
      "loss: 0.369423  [ 6272/13920]\n",
      "loss: 0.445451  [ 6336/13920]\n",
      "loss: 0.501914  [ 6400/13920]\n",
      "loss: 0.305639  [ 6464/13920]\n",
      "loss: 0.463381  [ 6528/13920]\n",
      "loss: 0.534410  [ 6592/13920]\n",
      "loss: 0.395534  [ 6656/13920]\n",
      "loss: 0.333283  [ 6720/13920]\n",
      "loss: 0.397142  [ 6784/13920]\n",
      "loss: 0.359812  [ 6848/13920]\n",
      "loss: 0.444929  [ 6912/13920]\n",
      "loss: 0.471137  [ 6976/13920]\n",
      "loss: 0.442458  [ 7040/13920]\n",
      "loss: 0.312945  [ 7104/13920]\n",
      "loss: 0.306037  [ 7168/13920]\n",
      "loss: 0.430866  [ 7232/13920]\n",
      "loss: 0.597906  [ 7296/13920]\n",
      "loss: 0.420907  [ 7360/13920]\n",
      "loss: 0.550104  [ 7424/13920]\n",
      "loss: 0.440403  [ 7488/13920]\n",
      "loss: 0.461935  [ 7552/13920]\n",
      "loss: 0.396329  [ 7616/13920]\n",
      "loss: 0.353143  [ 7680/13920]\n",
      "loss: 0.490267  [ 7744/13920]\n",
      "loss: 0.383679  [ 7808/13920]\n",
      "loss: 0.396449  [ 7872/13920]\n",
      "loss: 0.434192  [ 7936/13920]\n",
      "loss: 0.488799  [ 8000/13920]\n",
      "loss: 0.484063  [ 8064/13920]\n",
      "loss: 0.313969  [ 8128/13920]\n",
      "loss: 0.498703  [ 8192/13920]\n",
      "loss: 0.375128  [ 8256/13920]\n",
      "loss: 0.328454  [ 8320/13920]\n",
      "loss: 0.454479  [ 8384/13920]\n",
      "loss: 0.401780  [ 8448/13920]\n",
      "loss: 0.426980  [ 8512/13920]\n",
      "loss: 0.314986  [ 8576/13920]\n",
      "loss: 0.399896  [ 8640/13920]\n",
      "loss: 0.404700  [ 8704/13920]\n",
      "loss: 0.429852  [ 8768/13920]\n",
      "loss: 0.383994  [ 8832/13920]\n",
      "loss: 0.568107  [ 8896/13920]\n",
      "loss: 0.358154  [ 8960/13920]\n",
      "loss: 0.355376  [ 9024/13920]\n",
      "loss: 0.356369  [ 9088/13920]\n",
      "loss: 0.359482  [ 9152/13920]\n",
      "loss: 0.356986  [ 9216/13920]\n",
      "loss: 0.438471  [ 9280/13920]\n",
      "loss: 0.448632  [ 9344/13920]\n",
      "loss: 0.390367  [ 9408/13920]\n",
      "loss: 0.359862  [ 9472/13920]\n",
      "loss: 0.373092  [ 9536/13920]\n",
      "loss: 0.370882  [ 9600/13920]\n",
      "loss: 0.327532  [ 9664/13920]\n",
      "loss: 0.404272  [ 9728/13920]\n",
      "loss: 0.433168  [ 9792/13920]\n",
      "loss: 0.525475  [ 9856/13920]\n",
      "loss: 0.306471  [ 9920/13920]\n",
      "loss: 0.353299  [ 9984/13920]\n",
      "loss: 0.347384  [10048/13920]\n",
      "loss: 0.485369  [10112/13920]\n",
      "loss: 0.366532  [10176/13920]\n",
      "loss: 0.445748  [10240/13920]\n",
      "loss: 0.447990  [10304/13920]\n",
      "loss: 0.438726  [10368/13920]\n",
      "loss: 0.394628  [10432/13920]\n",
      "loss: 0.414896  [10496/13920]\n",
      "loss: 0.352942  [10560/13920]\n",
      "loss: 0.403064  [10624/13920]\n",
      "loss: 0.412733  [10688/13920]\n",
      "loss: 0.414803  [10752/13920]\n",
      "loss: 0.394731  [10816/13920]\n",
      "loss: 0.371838  [10880/13920]\n",
      "loss: 0.469459  [10944/13920]\n",
      "loss: 0.341592  [11008/13920]\n",
      "loss: 0.396738  [11072/13920]\n",
      "loss: 0.414546  [11136/13920]\n",
      "loss: 0.396906  [11200/13920]\n",
      "loss: 0.396818  [11264/13920]\n",
      "loss: 0.361544  [11328/13920]\n",
      "loss: 0.383210  [11392/13920]\n",
      "loss: 0.450967  [11456/13920]\n",
      "loss: 0.393287  [11520/13920]\n",
      "loss: 0.357750  [11584/13920]\n",
      "loss: 0.345418  [11648/13920]\n",
      "loss: 0.299536  [11712/13920]\n",
      "loss: 0.473047  [11776/13920]\n",
      "loss: 0.449218  [11840/13920]\n",
      "loss: 0.328454  [11904/13920]\n",
      "loss: 0.426636  [11968/13920]\n",
      "loss: 0.272548  [12032/13920]\n",
      "loss: 0.276816  [12096/13920]\n",
      "loss: 0.306393  [12160/13920]\n",
      "loss: 0.254517  [12224/13920]\n",
      "loss: 0.432558  [12288/13920]\n",
      "loss: 0.265152  [12352/13920]\n",
      "loss: 0.419565  [12416/13920]\n",
      "loss: 0.507056  [12480/13920]\n",
      "loss: 0.286597  [12544/13920]\n",
      "loss: 0.501114  [12608/13920]\n",
      "loss: 0.323738  [12672/13920]\n",
      "loss: 0.244869  [12736/13920]\n",
      "loss: 0.388998  [12800/13920]\n",
      "loss: 0.298020  [12864/13920]\n",
      "loss: 0.314499  [12928/13920]\n",
      "loss: 0.404737  [12992/13920]\n",
      "loss: 0.254932  [13056/13920]\n",
      "loss: 0.349493  [13120/13920]\n",
      "loss: 0.280840  [13184/13920]\n",
      "loss: 0.362241  [13248/13920]\n",
      "loss: 0.338952  [13312/13920]\n",
      "loss: 0.361406  [13376/13920]\n",
      "loss: 0.353352  [13440/13920]\n",
      "loss: 0.332603  [13504/13920]\n",
      "loss: 0.503309  [13568/13920]\n",
      "loss: 0.373635  [13632/13920]\n",
      "loss: 0.451424  [13696/13920]\n",
      "loss: 0.429653  [13760/13920]\n",
      "loss: 0.488713  [13824/13920]\n",
      "loss: 0.386323  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 83.8% \n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.372639 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.362444  [    0/13920]\n",
      "loss: 0.408287  [   64/13920]\n",
      "loss: 0.247298  [  128/13920]\n",
      "loss: 0.331490  [  192/13920]\n",
      "loss: 0.315574  [  256/13920]\n",
      "loss: 0.248212  [  320/13920]\n",
      "loss: 0.327999  [  384/13920]\n",
      "loss: 0.422140  [  448/13920]\n",
      "loss: 0.270719  [  512/13920]\n",
      "loss: 0.298147  [  576/13920]\n",
      "loss: 0.351623  [  640/13920]\n",
      "loss: 0.281946  [  704/13920]\n",
      "loss: 0.256213  [  768/13920]\n",
      "loss: 0.425365  [  832/13920]\n",
      "loss: 0.346695  [  896/13920]\n",
      "loss: 0.253354  [  960/13920]\n",
      "loss: 0.304827  [ 1024/13920]\n",
      "loss: 0.291673  [ 1088/13920]\n",
      "loss: 0.396007  [ 1152/13920]\n",
      "loss: 0.278328  [ 1216/13920]\n",
      "loss: 0.283497  [ 1280/13920]\n",
      "loss: 0.332936  [ 1344/13920]\n",
      "loss: 0.316959  [ 1408/13920]\n",
      "loss: 0.443080  [ 1472/13920]\n",
      "loss: 0.342184  [ 1536/13920]\n",
      "loss: 0.285298  [ 1600/13920]\n",
      "loss: 0.227396  [ 1664/13920]\n",
      "loss: 0.334220  [ 1728/13920]\n",
      "loss: 0.293750  [ 1792/13920]\n",
      "loss: 0.308888  [ 1856/13920]\n",
      "loss: 0.252496  [ 1920/13920]\n",
      "loss: 0.364359  [ 1984/13920]\n",
      "loss: 0.353472  [ 2048/13920]\n",
      "loss: 0.407972  [ 2112/13920]\n",
      "loss: 0.267195  [ 2176/13920]\n",
      "loss: 0.366601  [ 2240/13920]\n",
      "loss: 0.463325  [ 2304/13920]\n",
      "loss: 0.378724  [ 2368/13920]\n",
      "loss: 0.333003  [ 2432/13920]\n",
      "loss: 0.220525  [ 2496/13920]\n",
      "loss: 0.454705  [ 2560/13920]\n",
      "loss: 0.242877  [ 2624/13920]\n",
      "loss: 0.374008  [ 2688/13920]\n",
      "loss: 0.347365  [ 2752/13920]\n",
      "loss: 0.305335  [ 2816/13920]\n",
      "loss: 0.253339  [ 2880/13920]\n",
      "loss: 0.295401  [ 2944/13920]\n",
      "loss: 0.303375  [ 3008/13920]\n",
      "loss: 0.235622  [ 3072/13920]\n",
      "loss: 0.323524  [ 3136/13920]\n",
      "loss: 0.332737  [ 3200/13920]\n",
      "loss: 0.269235  [ 3264/13920]\n",
      "loss: 0.267855  [ 3328/13920]\n",
      "loss: 0.299878  [ 3392/13920]\n",
      "loss: 0.329557  [ 3456/13920]\n",
      "loss: 0.298562  [ 3520/13920]\n",
      "loss: 0.317316  [ 3584/13920]\n",
      "loss: 0.304808  [ 3648/13920]\n",
      "loss: 0.320777  [ 3712/13920]\n",
      "loss: 0.276461  [ 3776/13920]\n",
      "loss: 0.428564  [ 3840/13920]\n",
      "loss: 0.372116  [ 3904/13920]\n",
      "loss: 0.205764  [ 3968/13920]\n",
      "loss: 0.236006  [ 4032/13920]\n",
      "loss: 0.367855  [ 4096/13920]\n",
      "loss: 0.329753  [ 4160/13920]\n",
      "loss: 0.280852  [ 4224/13920]\n",
      "loss: 0.281603  [ 4288/13920]\n",
      "loss: 0.344839  [ 4352/13920]\n",
      "loss: 0.367339  [ 4416/13920]\n",
      "loss: 0.321283  [ 4480/13920]\n",
      "loss: 0.347285  [ 4544/13920]\n",
      "loss: 0.213429  [ 4608/13920]\n",
      "loss: 0.259523  [ 4672/13920]\n",
      "loss: 0.291661  [ 4736/13920]\n",
      "loss: 0.369954  [ 4800/13920]\n",
      "loss: 0.282980  [ 4864/13920]\n",
      "loss: 0.393659  [ 4928/13920]\n",
      "loss: 0.245374  [ 4992/13920]\n",
      "loss: 0.313395  [ 5056/13920]\n",
      "loss: 0.338030  [ 5120/13920]\n",
      "loss: 0.216644  [ 5184/13920]\n",
      "loss: 0.308930  [ 5248/13920]\n",
      "loss: 0.172966  [ 5312/13920]\n",
      "loss: 0.217306  [ 5376/13920]\n",
      "loss: 0.378826  [ 5440/13920]\n",
      "loss: 0.394037  [ 5504/13920]\n",
      "loss: 0.264881  [ 5568/13920]\n",
      "loss: 0.342723  [ 5632/13920]\n",
      "loss: 0.422128  [ 5696/13920]\n",
      "loss: 0.344887  [ 5760/13920]\n",
      "loss: 0.435443  [ 5824/13920]\n",
      "loss: 0.181979  [ 5888/13920]\n",
      "loss: 0.229276  [ 5952/13920]\n",
      "loss: 0.476914  [ 6016/13920]\n",
      "loss: 0.306717  [ 6080/13920]\n",
      "loss: 0.303735  [ 6144/13920]\n",
      "loss: 0.346601  [ 6208/13920]\n",
      "loss: 0.215827  [ 6272/13920]\n",
      "loss: 0.227648  [ 6336/13920]\n",
      "loss: 0.428898  [ 6400/13920]\n",
      "loss: 0.390987  [ 6464/13920]\n",
      "loss: 0.316115  [ 6528/13920]\n",
      "loss: 0.325590  [ 6592/13920]\n",
      "loss: 0.297998  [ 6656/13920]\n",
      "loss: 0.254313  [ 6720/13920]\n",
      "loss: 0.263075  [ 6784/13920]\n",
      "loss: 0.272969  [ 6848/13920]\n",
      "loss: 0.442752  [ 6912/13920]\n",
      "loss: 0.144669  [ 6976/13920]\n",
      "loss: 0.300290  [ 7040/13920]\n",
      "loss: 0.355002  [ 7104/13920]\n",
      "loss: 0.292156  [ 7168/13920]\n",
      "loss: 0.285631  [ 7232/13920]\n",
      "loss: 0.256302  [ 7296/13920]\n",
      "loss: 0.333754  [ 7360/13920]\n",
      "loss: 0.381805  [ 7424/13920]\n",
      "loss: 0.201382  [ 7488/13920]\n",
      "loss: 0.426448  [ 7552/13920]\n",
      "loss: 0.275007  [ 7616/13920]\n",
      "loss: 0.255938  [ 7680/13920]\n",
      "loss: 0.336116  [ 7744/13920]\n",
      "loss: 0.189036  [ 7808/13920]\n",
      "loss: 0.310408  [ 7872/13920]\n",
      "loss: 0.481355  [ 7936/13920]\n",
      "loss: 0.371030  [ 8000/13920]\n",
      "loss: 0.251940  [ 8064/13920]\n",
      "loss: 0.406789  [ 8128/13920]\n",
      "loss: 0.298027  [ 8192/13920]\n",
      "loss: 0.265831  [ 8256/13920]\n",
      "loss: 0.235107  [ 8320/13920]\n",
      "loss: 0.292641  [ 8384/13920]\n",
      "loss: 0.293579  [ 8448/13920]\n",
      "loss: 0.321008  [ 8512/13920]\n",
      "loss: 0.294173  [ 8576/13920]\n",
      "loss: 0.179763  [ 8640/13920]\n",
      "loss: 0.378662  [ 8704/13920]\n",
      "loss: 0.215098  [ 8768/13920]\n",
      "loss: 0.270469  [ 8832/13920]\n",
      "loss: 0.236512  [ 8896/13920]\n",
      "loss: 0.233228  [ 8960/13920]\n",
      "loss: 0.249399  [ 9024/13920]\n",
      "loss: 0.268756  [ 9088/13920]\n",
      "loss: 0.267777  [ 9152/13920]\n",
      "loss: 0.230915  [ 9216/13920]\n",
      "loss: 0.250909  [ 9280/13920]\n",
      "loss: 0.323836  [ 9344/13920]\n",
      "loss: 0.244148  [ 9408/13920]\n",
      "loss: 0.239530  [ 9472/13920]\n",
      "loss: 0.206948  [ 9536/13920]\n",
      "loss: 0.190983  [ 9600/13920]\n",
      "loss: 0.210803  [ 9664/13920]\n",
      "loss: 0.288336  [ 9728/13920]\n",
      "loss: 0.318238  [ 9792/13920]\n",
      "loss: 0.182720  [ 9856/13920]\n",
      "loss: 0.323573  [ 9920/13920]\n",
      "loss: 0.247736  [ 9984/13920]\n",
      "loss: 0.289702  [10048/13920]\n",
      "loss: 0.304552  [10112/13920]\n",
      "loss: 0.356217  [10176/13920]\n",
      "loss: 0.234059  [10240/13920]\n",
      "loss: 0.162096  [10304/13920]\n",
      "loss: 0.208595  [10368/13920]\n",
      "loss: 0.319607  [10432/13920]\n",
      "loss: 0.286097  [10496/13920]\n",
      "loss: 0.371137  [10560/13920]\n",
      "loss: 0.246493  [10624/13920]\n",
      "loss: 0.180676  [10688/13920]\n",
      "loss: 0.185300  [10752/13920]\n",
      "loss: 0.190948  [10816/13920]\n",
      "loss: 0.220589  [10880/13920]\n",
      "loss: 0.258874  [10944/13920]\n",
      "loss: 0.280019  [11008/13920]\n",
      "loss: 0.195725  [11072/13920]\n",
      "loss: 0.222610  [11136/13920]\n",
      "loss: 0.254585  [11200/13920]\n",
      "loss: 0.348180  [11264/13920]\n",
      "loss: 0.192481  [11328/13920]\n",
      "loss: 0.239015  [11392/13920]\n",
      "loss: 0.163116  [11456/13920]\n",
      "loss: 0.255383  [11520/13920]\n",
      "loss: 0.210515  [11584/13920]\n",
      "loss: 0.212242  [11648/13920]\n",
      "loss: 0.249959  [11712/13920]\n",
      "loss: 0.195639  [11776/13920]\n",
      "loss: 0.197362  [11840/13920]\n",
      "loss: 0.163073  [11904/13920]\n",
      "loss: 0.197741  [11968/13920]\n",
      "loss: 0.277468  [12032/13920]\n",
      "loss: 0.260122  [12096/13920]\n",
      "loss: 0.209136  [12160/13920]\n",
      "loss: 0.399906  [12224/13920]\n",
      "loss: 0.274063  [12288/13920]\n",
      "loss: 0.269072  [12352/13920]\n",
      "loss: 0.200753  [12416/13920]\n",
      "loss: 0.278162  [12480/13920]\n",
      "loss: 0.215467  [12544/13920]\n",
      "loss: 0.239478  [12608/13920]\n",
      "loss: 0.175789  [12672/13920]\n",
      "loss: 0.207945  [12736/13920]\n",
      "loss: 0.220710  [12800/13920]\n",
      "loss: 0.156206  [12864/13920]\n",
      "loss: 0.282263  [12928/13920]\n",
      "loss: 0.169012  [12992/13920]\n",
      "loss: 0.290896  [13056/13920]\n",
      "loss: 0.343104  [13120/13920]\n",
      "loss: 0.307000  [13184/13920]\n",
      "loss: 0.336706  [13248/13920]\n",
      "loss: 0.352834  [13312/13920]\n",
      "loss: 0.302069  [13376/13920]\n",
      "loss: 0.211696  [13440/13920]\n",
      "loss: 0.262057  [13504/13920]\n",
      "loss: 0.172838  [13568/13920]\n",
      "loss: 0.304198  [13632/13920]\n",
      "loss: 0.203291  [13696/13920]\n",
      "loss: 0.220448  [13760/13920]\n",
      "loss: 0.234309  [13824/13920]\n",
      "loss: 0.188688  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 89.8% \n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.294659 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.272416  [    0/13920]\n",
      "loss: 0.149402  [   64/13920]\n",
      "loss: 0.211923  [  128/13920]\n",
      "loss: 0.238581  [  192/13920]\n",
      "loss: 0.164293  [  256/13920]\n",
      "loss: 0.331957  [  320/13920]\n",
      "loss: 0.280050  [  384/13920]\n",
      "loss: 0.238115  [  448/13920]\n",
      "loss: 0.228178  [  512/13920]\n",
      "loss: 0.204953  [  576/13920]\n",
      "loss: 0.236410  [  640/13920]\n",
      "loss: 0.300928  [  704/13920]\n",
      "loss: 0.226013  [  768/13920]\n",
      "loss: 0.328518  [  832/13920]\n",
      "loss: 0.177606  [  896/13920]\n",
      "loss: 0.237469  [  960/13920]\n",
      "loss: 0.166614  [ 1024/13920]\n",
      "loss: 0.240392  [ 1088/13920]\n",
      "loss: 0.261137  [ 1152/13920]\n",
      "loss: 0.220187  [ 1216/13920]\n",
      "loss: 0.261552  [ 1280/13920]\n",
      "loss: 0.264265  [ 1344/13920]\n",
      "loss: 0.309119  [ 1408/13920]\n",
      "loss: 0.291911  [ 1472/13920]\n",
      "loss: 0.187501  [ 1536/13920]\n",
      "loss: 0.174688  [ 1600/13920]\n",
      "loss: 0.147217  [ 1664/13920]\n",
      "loss: 0.234219  [ 1728/13920]\n",
      "loss: 0.197911  [ 1792/13920]\n",
      "loss: 0.093384  [ 1856/13920]\n",
      "loss: 0.164764  [ 1920/13920]\n",
      "loss: 0.381515  [ 1984/13920]\n",
      "loss: 0.160063  [ 2048/13920]\n",
      "loss: 0.167277  [ 2112/13920]\n",
      "loss: 0.158598  [ 2176/13920]\n",
      "loss: 0.192860  [ 2240/13920]\n",
      "loss: 0.176339  [ 2304/13920]\n",
      "loss: 0.261882  [ 2368/13920]\n",
      "loss: 0.338611  [ 2432/13920]\n",
      "loss: 0.230149  [ 2496/13920]\n",
      "loss: 0.158293  [ 2560/13920]\n",
      "loss: 0.174443  [ 2624/13920]\n",
      "loss: 0.142397  [ 2688/13920]\n",
      "loss: 0.165169  [ 2752/13920]\n",
      "loss: 0.420028  [ 2816/13920]\n",
      "loss: 0.310208  [ 2880/13920]\n",
      "loss: 0.240537  [ 2944/13920]\n",
      "loss: 0.298741  [ 3008/13920]\n",
      "loss: 0.263464  [ 3072/13920]\n",
      "loss: 0.144262  [ 3136/13920]\n",
      "loss: 0.149999  [ 3200/13920]\n",
      "loss: 0.159007  [ 3264/13920]\n",
      "loss: 0.222153  [ 3328/13920]\n",
      "loss: 0.114958  [ 3392/13920]\n",
      "loss: 0.207430  [ 3456/13920]\n",
      "loss: 0.132160  [ 3520/13920]\n",
      "loss: 0.149528  [ 3584/13920]\n",
      "loss: 0.170428  [ 3648/13920]\n",
      "loss: 0.135271  [ 3712/13920]\n",
      "loss: 0.358903  [ 3776/13920]\n",
      "loss: 0.182057  [ 3840/13920]\n",
      "loss: 0.187098  [ 3904/13920]\n",
      "loss: 0.197192  [ 3968/13920]\n",
      "loss: 0.258054  [ 4032/13920]\n",
      "loss: 0.213227  [ 4096/13920]\n",
      "loss: 0.162425  [ 4160/13920]\n",
      "loss: 0.227433  [ 4224/13920]\n",
      "loss: 0.195935  [ 4288/13920]\n",
      "loss: 0.116657  [ 4352/13920]\n",
      "loss: 0.257902  [ 4416/13920]\n",
      "loss: 0.179733  [ 4480/13920]\n",
      "loss: 0.255779  [ 4544/13920]\n",
      "loss: 0.290417  [ 4608/13920]\n",
      "loss: 0.169160  [ 4672/13920]\n",
      "loss: 0.314781  [ 4736/13920]\n",
      "loss: 0.232692  [ 4800/13920]\n",
      "loss: 0.249358  [ 4864/13920]\n",
      "loss: 0.208413  [ 4928/13920]\n",
      "loss: 0.275958  [ 4992/13920]\n",
      "loss: 0.124157  [ 5056/13920]\n",
      "loss: 0.287343  [ 5120/13920]\n",
      "loss: 0.214892  [ 5184/13920]\n",
      "loss: 0.198296  [ 5248/13920]\n",
      "loss: 0.171192  [ 5312/13920]\n",
      "loss: 0.109081  [ 5376/13920]\n",
      "loss: 0.207369  [ 5440/13920]\n",
      "loss: 0.172079  [ 5504/13920]\n",
      "loss: 0.221675  [ 5568/13920]\n",
      "loss: 0.244541  [ 5632/13920]\n",
      "loss: 0.156404  [ 5696/13920]\n",
      "loss: 0.139922  [ 5760/13920]\n",
      "loss: 0.290476  [ 5824/13920]\n",
      "loss: 0.366295  [ 5888/13920]\n",
      "loss: 0.217738  [ 5952/13920]\n",
      "loss: 0.216291  [ 6016/13920]\n",
      "loss: 0.181933  [ 6080/13920]\n",
      "loss: 0.209153  [ 6144/13920]\n",
      "loss: 0.227821  [ 6208/13920]\n",
      "loss: 0.229303  [ 6272/13920]\n",
      "loss: 0.150460  [ 6336/13920]\n",
      "loss: 0.263955  [ 6400/13920]\n",
      "loss: 0.233295  [ 6464/13920]\n",
      "loss: 0.170737  [ 6528/13920]\n",
      "loss: 0.104770  [ 6592/13920]\n",
      "loss: 0.202378  [ 6656/13920]\n",
      "loss: 0.206221  [ 6720/13920]\n",
      "loss: 0.226149  [ 6784/13920]\n",
      "loss: 0.188725  [ 6848/13920]\n",
      "loss: 0.460963  [ 6912/13920]\n",
      "loss: 0.162291  [ 6976/13920]\n",
      "loss: 0.211419  [ 7040/13920]\n",
      "loss: 0.160742  [ 7104/13920]\n",
      "loss: 0.110179  [ 7168/13920]\n",
      "loss: 0.208399  [ 7232/13920]\n",
      "loss: 0.370665  [ 7296/13920]\n",
      "loss: 0.254428  [ 7360/13920]\n",
      "loss: 0.225916  [ 7424/13920]\n",
      "loss: 0.195831  [ 7488/13920]\n",
      "loss: 0.173230  [ 7552/13920]\n",
      "loss: 0.354815  [ 7616/13920]\n",
      "loss: 0.131906  [ 7680/13920]\n",
      "loss: 0.216297  [ 7744/13920]\n",
      "loss: 0.179267  [ 7808/13920]\n",
      "loss: 0.209320  [ 7872/13920]\n",
      "loss: 0.232822  [ 7936/13920]\n",
      "loss: 0.234202  [ 8000/13920]\n",
      "loss: 0.128280  [ 8064/13920]\n",
      "loss: 0.151772  [ 8128/13920]\n",
      "loss: 0.146889  [ 8192/13920]\n",
      "loss: 0.157210  [ 8256/13920]\n",
      "loss: 0.128023  [ 8320/13920]\n",
      "loss: 0.159378  [ 8384/13920]\n",
      "loss: 0.167624  [ 8448/13920]\n",
      "loss: 0.146130  [ 8512/13920]\n",
      "loss: 0.379714  [ 8576/13920]\n",
      "loss: 0.183151  [ 8640/13920]\n",
      "loss: 0.169291  [ 8704/13920]\n",
      "loss: 0.197885  [ 8768/13920]\n",
      "loss: 0.287120  [ 8832/13920]\n",
      "loss: 0.423969  [ 8896/13920]\n",
      "loss: 0.148108  [ 8960/13920]\n",
      "loss: 0.369288  [ 9024/13920]\n",
      "loss: 0.146351  [ 9088/13920]\n",
      "loss: 0.164352  [ 9152/13920]\n",
      "loss: 0.237135  [ 9216/13920]\n",
      "loss: 0.461034  [ 9280/13920]\n",
      "loss: 0.516018  [ 9344/13920]\n",
      "loss: 0.187837  [ 9408/13920]\n",
      "loss: 0.233747  [ 9472/13920]\n",
      "loss: 0.205344  [ 9536/13920]\n",
      "loss: 0.410913  [ 9600/13920]\n",
      "loss: 0.160880  [ 9664/13920]\n",
      "loss: 0.379445  [ 9728/13920]\n",
      "loss: 0.211282  [ 9792/13920]\n",
      "loss: 0.223141  [ 9856/13920]\n",
      "loss: 0.255489  [ 9920/13920]\n",
      "loss: 0.291697  [ 9984/13920]\n",
      "loss: 0.175585  [10048/13920]\n",
      "loss: 0.175073  [10112/13920]\n",
      "loss: 0.192978  [10176/13920]\n",
      "loss: 0.099742  [10240/13920]\n",
      "loss: 0.207701  [10304/13920]\n",
      "loss: 0.190653  [10368/13920]\n",
      "loss: 0.178091  [10432/13920]\n",
      "loss: 0.174254  [10496/13920]\n",
      "loss: 0.129291  [10560/13920]\n",
      "loss: 0.299891  [10624/13920]\n",
      "loss: 0.242405  [10688/13920]\n",
      "loss: 0.175273  [10752/13920]\n",
      "loss: 0.169421  [10816/13920]\n",
      "loss: 0.177152  [10880/13920]\n",
      "loss: 0.173093  [10944/13920]\n",
      "loss: 0.207089  [11008/13920]\n",
      "loss: 0.166774  [11072/13920]\n",
      "loss: 0.151999  [11136/13920]\n",
      "loss: 0.229323  [11200/13920]\n",
      "loss: 0.155840  [11264/13920]\n",
      "loss: 0.146973  [11328/13920]\n",
      "loss: 0.186186  [11392/13920]\n",
      "loss: 0.217505  [11456/13920]\n",
      "loss: 0.205727  [11520/13920]\n",
      "loss: 0.311886  [11584/13920]\n",
      "loss: 0.156481  [11648/13920]\n",
      "loss: 0.242490  [11712/13920]\n",
      "loss: 0.194767  [11776/13920]\n",
      "loss: 0.276183  [11840/13920]\n",
      "loss: 0.084070  [11904/13920]\n",
      "loss: 0.260185  [11968/13920]\n",
      "loss: 0.210129  [12032/13920]\n",
      "loss: 0.240316  [12096/13920]\n",
      "loss: 0.211390  [12160/13920]\n",
      "loss: 0.175048  [12224/13920]\n",
      "loss: 0.170233  [12288/13920]\n",
      "loss: 0.262952  [12352/13920]\n",
      "loss: 0.251532  [12416/13920]\n",
      "loss: 0.207020  [12480/13920]\n",
      "loss: 0.180643  [12544/13920]\n",
      "loss: 0.220737  [12608/13920]\n",
      "loss: 0.182635  [12672/13920]\n",
      "loss: 0.166505  [12736/13920]\n",
      "loss: 0.220642  [12800/13920]\n",
      "loss: 0.216321  [12864/13920]\n",
      "loss: 0.137046  [12928/13920]\n",
      "loss: 0.166108  [12992/13920]\n",
      "loss: 0.147327  [13056/13920]\n",
      "loss: 0.120937  [13120/13920]\n",
      "loss: 0.158091  [13184/13920]\n",
      "loss: 0.175009  [13248/13920]\n",
      "loss: 0.148468  [13312/13920]\n",
      "loss: 0.141803  [13376/13920]\n",
      "loss: 0.238000  [13440/13920]\n",
      "loss: 0.293808  [13504/13920]\n",
      "loss: 0.186994  [13568/13920]\n",
      "loss: 0.116837  [13632/13920]\n",
      "loss: 0.256419  [13696/13920]\n",
      "loss: 0.196128  [13760/13920]\n",
      "loss: 0.165181  [13824/13920]\n",
      "loss: 0.113436  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 92.8% \n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.213970 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.239881  [    0/13920]\n",
      "loss: 0.116984  [   64/13920]\n",
      "loss: 0.182622  [  128/13920]\n",
      "loss: 0.243151  [  192/13920]\n",
      "loss: 0.175149  [  256/13920]\n",
      "loss: 0.089495  [  320/13920]\n",
      "loss: 0.113293  [  384/13920]\n",
      "loss: 0.201692  [  448/13920]\n",
      "loss: 0.126154  [  512/13920]\n",
      "loss: 0.161881  [  576/13920]\n",
      "loss: 0.211126  [  640/13920]\n",
      "loss: 0.158302  [  704/13920]\n",
      "loss: 0.146641  [  768/13920]\n",
      "loss: 0.185736  [  832/13920]\n",
      "loss: 0.334410  [  896/13920]\n",
      "loss: 0.105500  [  960/13920]\n",
      "loss: 0.081301  [ 1024/13920]\n",
      "loss: 0.086133  [ 1088/13920]\n",
      "loss: 0.179312  [ 1152/13920]\n",
      "loss: 0.191240  [ 1216/13920]\n",
      "loss: 0.168588  [ 1280/13920]\n",
      "loss: 0.090821  [ 1344/13920]\n",
      "loss: 0.220019  [ 1408/13920]\n",
      "loss: 0.154688  [ 1472/13920]\n",
      "loss: 0.242931  [ 1536/13920]\n",
      "loss: 0.120373  [ 1600/13920]\n",
      "loss: 0.192521  [ 1664/13920]\n",
      "loss: 0.214377  [ 1728/13920]\n",
      "loss: 0.225445  [ 1792/13920]\n",
      "loss: 0.126333  [ 1856/13920]\n",
      "loss: 0.140973  [ 1920/13920]\n",
      "loss: 0.106135  [ 1984/13920]\n",
      "loss: 0.141688  [ 2048/13920]\n",
      "loss: 0.154349  [ 2112/13920]\n",
      "loss: 0.227505  [ 2176/13920]\n",
      "loss: 0.196849  [ 2240/13920]\n",
      "loss: 0.152078  [ 2304/13920]\n",
      "loss: 0.163762  [ 2368/13920]\n",
      "loss: 0.155100  [ 2432/13920]\n",
      "loss: 0.340032  [ 2496/13920]\n",
      "loss: 0.203588  [ 2560/13920]\n",
      "loss: 0.154751  [ 2624/13920]\n",
      "loss: 0.213948  [ 2688/13920]\n",
      "loss: 0.101974  [ 2752/13920]\n",
      "loss: 0.124691  [ 2816/13920]\n",
      "loss: 0.213721  [ 2880/13920]\n",
      "loss: 0.131049  [ 2944/13920]\n",
      "loss: 0.057734  [ 3008/13920]\n",
      "loss: 0.122750  [ 3072/13920]\n",
      "loss: 0.226529  [ 3136/13920]\n",
      "loss: 0.157456  [ 3200/13920]\n",
      "loss: 0.243057  [ 3264/13920]\n",
      "loss: 0.276113  [ 3328/13920]\n",
      "loss: 0.151287  [ 3392/13920]\n",
      "loss: 0.101860  [ 3456/13920]\n",
      "loss: 0.169119  [ 3520/13920]\n",
      "loss: 0.128366  [ 3584/13920]\n",
      "loss: 0.170320  [ 3648/13920]\n",
      "loss: 0.132045  [ 3712/13920]\n",
      "loss: 0.256645  [ 3776/13920]\n",
      "loss: 0.159457  [ 3840/13920]\n",
      "loss: 0.120840  [ 3904/13920]\n",
      "loss: 0.076256  [ 3968/13920]\n",
      "loss: 0.083172  [ 4032/13920]\n",
      "loss: 0.136467  [ 4096/13920]\n",
      "loss: 0.168355  [ 4160/13920]\n",
      "loss: 0.275247  [ 4224/13920]\n",
      "loss: 0.108197  [ 4288/13920]\n",
      "loss: 0.118608  [ 4352/13920]\n",
      "loss: 0.139860  [ 4416/13920]\n",
      "loss: 0.208695  [ 4480/13920]\n",
      "loss: 0.238897  [ 4544/13920]\n",
      "loss: 0.230729  [ 4608/13920]\n",
      "loss: 0.236423  [ 4672/13920]\n",
      "loss: 0.273994  [ 4736/13920]\n",
      "loss: 0.082677  [ 4800/13920]\n",
      "loss: 0.150970  [ 4864/13920]\n",
      "loss: 0.283176  [ 4928/13920]\n",
      "loss: 0.121908  [ 4992/13920]\n",
      "loss: 0.194654  [ 5056/13920]\n",
      "loss: 0.132087  [ 5120/13920]\n",
      "loss: 0.186368  [ 5184/13920]\n",
      "loss: 0.145366  [ 5248/13920]\n",
      "loss: 0.180196  [ 5312/13920]\n",
      "loss: 0.080339  [ 5376/13920]\n",
      "loss: 0.116747  [ 5440/13920]\n",
      "loss: 0.298849  [ 5504/13920]\n",
      "loss: 0.122218  [ 5568/13920]\n",
      "loss: 0.213758  [ 5632/13920]\n",
      "loss: 0.138441  [ 5696/13920]\n",
      "loss: 0.215373  [ 5760/13920]\n",
      "loss: 0.127777  [ 5824/13920]\n",
      "loss: 0.188698  [ 5888/13920]\n",
      "loss: 0.085012  [ 5952/13920]\n",
      "loss: 0.148416  [ 6016/13920]\n",
      "loss: 0.186596  [ 6080/13920]\n",
      "loss: 0.240405  [ 6144/13920]\n",
      "loss: 0.088262  [ 6208/13920]\n",
      "loss: 0.127377  [ 6272/13920]\n",
      "loss: 0.128652  [ 6336/13920]\n",
      "loss: 0.147761  [ 6400/13920]\n",
      "loss: 0.118265  [ 6464/13920]\n",
      "loss: 0.138284  [ 6528/13920]\n",
      "loss: 0.186585  [ 6592/13920]\n",
      "loss: 0.155100  [ 6656/13920]\n",
      "loss: 0.286194  [ 6720/13920]\n",
      "loss: 0.177508  [ 6784/13920]\n",
      "loss: 0.161739  [ 6848/13920]\n",
      "loss: 0.121258  [ 6912/13920]\n",
      "loss: 0.205894  [ 6976/13920]\n",
      "loss: 0.210776  [ 7040/13920]\n",
      "loss: 0.178322  [ 7104/13920]\n",
      "loss: 0.257410  [ 7168/13920]\n",
      "loss: 0.280121  [ 7232/13920]\n",
      "loss: 0.240956  [ 7296/13920]\n",
      "loss: 0.151902  [ 7360/13920]\n",
      "loss: 0.073095  [ 7424/13920]\n",
      "loss: 0.085234  [ 7488/13920]\n",
      "loss: 0.209363  [ 7552/13920]\n",
      "loss: 0.166467  [ 7616/13920]\n",
      "loss: 0.152544  [ 7680/13920]\n",
      "loss: 0.186236  [ 7744/13920]\n",
      "loss: 0.135811  [ 7808/13920]\n",
      "loss: 0.171244  [ 7872/13920]\n",
      "loss: 0.169855  [ 7936/13920]\n",
      "loss: 0.104136  [ 8000/13920]\n",
      "loss: 0.123873  [ 8064/13920]\n",
      "loss: 0.181549  [ 8128/13920]\n",
      "loss: 0.141912  [ 8192/13920]\n",
      "loss: 0.134032  [ 8256/13920]\n",
      "loss: 0.283468  [ 8320/13920]\n",
      "loss: 0.137680  [ 8384/13920]\n",
      "loss: 0.096911  [ 8448/13920]\n",
      "loss: 0.093754  [ 8512/13920]\n",
      "loss: 0.217548  [ 8576/13920]\n",
      "loss: 0.132790  [ 8640/13920]\n",
      "loss: 0.181896  [ 8704/13920]\n",
      "loss: 0.106627  [ 8768/13920]\n",
      "loss: 0.090382  [ 8832/13920]\n",
      "loss: 0.224788  [ 8896/13920]\n",
      "loss: 0.131740  [ 8960/13920]\n",
      "loss: 0.123445  [ 9024/13920]\n",
      "loss: 0.140824  [ 9088/13920]\n",
      "loss: 0.161430  [ 9152/13920]\n",
      "loss: 0.153817  [ 9216/13920]\n",
      "loss: 0.167450  [ 9280/13920]\n",
      "loss: 0.069390  [ 9344/13920]\n",
      "loss: 0.080806  [ 9408/13920]\n",
      "loss: 0.184697  [ 9472/13920]\n",
      "loss: 0.261826  [ 9536/13920]\n",
      "loss: 0.146124  [ 9600/13920]\n",
      "loss: 0.180942  [ 9664/13920]\n",
      "loss: 0.096695  [ 9728/13920]\n",
      "loss: 0.179492  [ 9792/13920]\n",
      "loss: 0.287098  [ 9856/13920]\n",
      "loss: 0.182010  [ 9920/13920]\n",
      "loss: 0.098377  [ 9984/13920]\n",
      "loss: 0.110835  [10048/13920]\n",
      "loss: 0.077892  [10112/13920]\n",
      "loss: 0.099449  [10176/13920]\n",
      "loss: 0.088569  [10240/13920]\n",
      "loss: 0.160289  [10304/13920]\n",
      "loss: 0.133559  [10368/13920]\n",
      "loss: 0.100465  [10432/13920]\n",
      "loss: 0.168990  [10496/13920]\n",
      "loss: 0.184180  [10560/13920]\n",
      "loss: 0.258555  [10624/13920]\n",
      "loss: 0.150203  [10688/13920]\n",
      "loss: 0.104412  [10752/13920]\n",
      "loss: 0.116795  [10816/13920]\n",
      "loss: 0.230038  [10880/13920]\n",
      "loss: 0.352715  [10944/13920]\n",
      "loss: 0.145788  [11008/13920]\n",
      "loss: 0.098365  [11072/13920]\n",
      "loss: 0.142467  [11136/13920]\n",
      "loss: 0.079980  [11200/13920]\n",
      "loss: 0.213271  [11264/13920]\n",
      "loss: 0.118639  [11328/13920]\n",
      "loss: 0.194866  [11392/13920]\n",
      "loss: 0.169773  [11456/13920]\n",
      "loss: 0.219767  [11520/13920]\n",
      "loss: 0.131548  [11584/13920]\n",
      "loss: 0.086394  [11648/13920]\n",
      "loss: 0.227814  [11712/13920]\n",
      "loss: 0.192951  [11776/13920]\n",
      "loss: 0.101904  [11840/13920]\n",
      "loss: 0.129326  [11904/13920]\n",
      "loss: 0.202223  [11968/13920]\n",
      "loss: 0.146308  [12032/13920]\n",
      "loss: 0.107357  [12096/13920]\n",
      "loss: 0.178482  [12160/13920]\n",
      "loss: 0.141974  [12224/13920]\n",
      "loss: 0.072067  [12288/13920]\n",
      "loss: 0.188991  [12352/13920]\n",
      "loss: 0.086524  [12416/13920]\n",
      "loss: 0.138351  [12480/13920]\n",
      "loss: 0.194169  [12544/13920]\n",
      "loss: 0.115614  [12608/13920]\n",
      "loss: 0.122753  [12672/13920]\n",
      "loss: 0.176335  [12736/13920]\n",
      "loss: 0.175022  [12800/13920]\n",
      "loss: 0.087326  [12864/13920]\n",
      "loss: 0.142681  [12928/13920]\n",
      "loss: 0.137984  [12992/13920]\n",
      "loss: 0.143709  [13056/13920]\n",
      "loss: 0.244555  [13120/13920]\n",
      "loss: 0.236497  [13184/13920]\n",
      "loss: 0.147941  [13248/13920]\n",
      "loss: 0.178001  [13312/13920]\n",
      "loss: 0.167662  [13376/13920]\n",
      "loss: 0.165082  [13440/13920]\n",
      "loss: 0.189939  [13504/13920]\n",
      "loss: 0.237323  [13568/13920]\n",
      "loss: 0.142805  [13632/13920]\n",
      "loss: 0.115816  [13696/13920]\n",
      "loss: 0.088748  [13760/13920]\n",
      "loss: 0.219336  [13824/13920]\n",
      "loss: 0.126895  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 94.3% \n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.199734 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.106648  [    0/13920]\n",
      "loss: 0.100066  [   64/13920]\n",
      "loss: 0.118321  [  128/13920]\n",
      "loss: 0.137080  [  192/13920]\n",
      "loss: 0.161075  [  256/13920]\n",
      "loss: 0.134516  [  320/13920]\n",
      "loss: 0.112307  [  384/13920]\n",
      "loss: 0.069830  [  448/13920]\n",
      "loss: 0.072395  [  512/13920]\n",
      "loss: 0.114640  [  576/13920]\n",
      "loss: 0.096010  [  640/13920]\n",
      "loss: 0.108900  [  704/13920]\n",
      "loss: 0.078799  [  768/13920]\n",
      "loss: 0.105241  [  832/13920]\n",
      "loss: 0.073706  [  896/13920]\n",
      "loss: 0.143490  [  960/13920]\n",
      "loss: 0.202818  [ 1024/13920]\n",
      "loss: 0.106550  [ 1088/13920]\n",
      "loss: 0.088351  [ 1152/13920]\n",
      "loss: 0.123716  [ 1216/13920]\n",
      "loss: 0.080188  [ 1280/13920]\n",
      "loss: 0.106230  [ 1344/13920]\n",
      "loss: 0.094494  [ 1408/13920]\n",
      "loss: 0.048482  [ 1472/13920]\n",
      "loss: 0.148898  [ 1536/13920]\n",
      "loss: 0.147649  [ 1600/13920]\n",
      "loss: 0.160812  [ 1664/13920]\n",
      "loss: 0.093726  [ 1728/13920]\n",
      "loss: 0.140395  [ 1792/13920]\n",
      "loss: 0.134817  [ 1856/13920]\n",
      "loss: 0.152229  [ 1920/13920]\n",
      "loss: 0.078142  [ 1984/13920]\n",
      "loss: 0.125828  [ 2048/13920]\n",
      "loss: 0.203855  [ 2112/13920]\n",
      "loss: 0.085536  [ 2176/13920]\n",
      "loss: 0.084685  [ 2240/13920]\n",
      "loss: 0.110298  [ 2304/13920]\n",
      "loss: 0.142574  [ 2368/13920]\n",
      "loss: 0.116729  [ 2432/13920]\n",
      "loss: 0.068629  [ 2496/13920]\n",
      "loss: 0.090566  [ 2560/13920]\n",
      "loss: 0.145817  [ 2624/13920]\n",
      "loss: 0.128153  [ 2688/13920]\n",
      "loss: 0.084313  [ 2752/13920]\n",
      "loss: 0.098701  [ 2816/13920]\n",
      "loss: 0.065217  [ 2880/13920]\n",
      "loss: 0.129523  [ 2944/13920]\n",
      "loss: 0.110802  [ 3008/13920]\n",
      "loss: 0.127807  [ 3072/13920]\n",
      "loss: 0.096668  [ 3136/13920]\n",
      "loss: 0.108105  [ 3200/13920]\n",
      "loss: 0.132408  [ 3264/13920]\n",
      "loss: 0.193881  [ 3328/13920]\n",
      "loss: 0.085283  [ 3392/13920]\n",
      "loss: 0.135660  [ 3456/13920]\n",
      "loss: 0.125041  [ 3520/13920]\n",
      "loss: 0.315497  [ 3584/13920]\n",
      "loss: 0.060674  [ 3648/13920]\n",
      "loss: 0.209145  [ 3712/13920]\n",
      "loss: 0.065899  [ 3776/13920]\n",
      "loss: 0.119982  [ 3840/13920]\n",
      "loss: 0.197255  [ 3904/13920]\n",
      "loss: 0.096561  [ 3968/13920]\n",
      "loss: 0.301137  [ 4032/13920]\n",
      "loss: 0.210676  [ 4096/13920]\n",
      "loss: 0.184404  [ 4160/13920]\n",
      "loss: 0.067852  [ 4224/13920]\n",
      "loss: 0.142567  [ 4288/13920]\n",
      "loss: 0.078552  [ 4352/13920]\n",
      "loss: 0.143544  [ 4416/13920]\n",
      "loss: 0.138159  [ 4480/13920]\n",
      "loss: 0.189455  [ 4544/13920]\n",
      "loss: 0.078887  [ 4608/13920]\n",
      "loss: 0.103264  [ 4672/13920]\n",
      "loss: 0.202542  [ 4736/13920]\n",
      "loss: 0.080814  [ 4800/13920]\n",
      "loss: 0.084885  [ 4864/13920]\n",
      "loss: 0.250576  [ 4928/13920]\n",
      "loss: 0.114328  [ 4992/13920]\n",
      "loss: 0.127916  [ 5056/13920]\n",
      "loss: 0.069500  [ 5120/13920]\n",
      "loss: 0.191836  [ 5184/13920]\n",
      "loss: 0.080749  [ 5248/13920]\n",
      "loss: 0.075659  [ 5312/13920]\n",
      "loss: 0.184803  [ 5376/13920]\n",
      "loss: 0.184257  [ 5440/13920]\n",
      "loss: 0.228414  [ 5504/13920]\n",
      "loss: 0.163513  [ 5568/13920]\n",
      "loss: 0.157726  [ 5632/13920]\n",
      "loss: 0.122242  [ 5696/13920]\n",
      "loss: 0.142704  [ 5760/13920]\n",
      "loss: 0.158894  [ 5824/13920]\n",
      "loss: 0.108983  [ 5888/13920]\n",
      "loss: 0.138500  [ 5952/13920]\n",
      "loss: 0.136700  [ 6016/13920]\n",
      "loss: 0.151422  [ 6080/13920]\n",
      "loss: 0.155494  [ 6144/13920]\n",
      "loss: 0.109056  [ 6208/13920]\n",
      "loss: 0.103745  [ 6272/13920]\n",
      "loss: 0.126382  [ 6336/13920]\n",
      "loss: 0.136579  [ 6400/13920]\n",
      "loss: 0.150743  [ 6464/13920]\n",
      "loss: 0.161594  [ 6528/13920]\n",
      "loss: 0.107745  [ 6592/13920]\n",
      "loss: 0.145601  [ 6656/13920]\n",
      "loss: 0.182211  [ 6720/13920]\n",
      "loss: 0.110265  [ 6784/13920]\n",
      "loss: 0.100943  [ 6848/13920]\n",
      "loss: 0.147020  [ 6912/13920]\n",
      "loss: 0.190435  [ 6976/13920]\n",
      "loss: 0.051862  [ 7040/13920]\n",
      "loss: 0.056791  [ 7104/13920]\n",
      "loss: 0.090004  [ 7168/13920]\n",
      "loss: 0.149497  [ 7232/13920]\n",
      "loss: 0.093517  [ 7296/13920]\n",
      "loss: 0.102956  [ 7360/13920]\n",
      "loss: 0.057203  [ 7424/13920]\n",
      "loss: 0.099733  [ 7488/13920]\n",
      "loss: 0.181677  [ 7552/13920]\n",
      "loss: 0.121445  [ 7616/13920]\n",
      "loss: 0.077851  [ 7680/13920]\n",
      "loss: 0.129845  [ 7744/13920]\n",
      "loss: 0.106514  [ 7808/13920]\n",
      "loss: 0.239185  [ 7872/13920]\n",
      "loss: 0.156152  [ 7936/13920]\n",
      "loss: 0.181434  [ 8000/13920]\n",
      "loss: 0.127073  [ 8064/13920]\n",
      "loss: 0.101480  [ 8128/13920]\n",
      "loss: 0.136358  [ 8192/13920]\n",
      "loss: 0.034675  [ 8256/13920]\n",
      "loss: 0.072172  [ 8320/13920]\n",
      "loss: 0.080778  [ 8384/13920]\n",
      "loss: 0.063264  [ 8448/13920]\n",
      "loss: 0.119426  [ 8512/13920]\n",
      "loss: 0.130661  [ 8576/13920]\n",
      "loss: 0.154034  [ 8640/13920]\n",
      "loss: 0.101250  [ 8704/13920]\n",
      "loss: 0.070034  [ 8768/13920]\n",
      "loss: 0.098537  [ 8832/13920]\n",
      "loss: 0.159065  [ 8896/13920]\n",
      "loss: 0.238429  [ 8960/13920]\n",
      "loss: 0.174274  [ 9024/13920]\n",
      "loss: 0.098956  [ 9088/13920]\n",
      "loss: 0.069823  [ 9152/13920]\n",
      "loss: 0.073073  [ 9216/13920]\n",
      "loss: 0.109063  [ 9280/13920]\n",
      "loss: 0.061420  [ 9344/13920]\n",
      "loss: 0.077628  [ 9408/13920]\n",
      "loss: 0.078092  [ 9472/13920]\n",
      "loss: 0.062034  [ 9536/13920]\n",
      "loss: 0.096689  [ 9600/13920]\n",
      "loss: 0.160955  [ 9664/13920]\n",
      "loss: 0.082192  [ 9728/13920]\n",
      "loss: 0.099341  [ 9792/13920]\n",
      "loss: 0.078818  [ 9856/13920]\n",
      "loss: 0.064605  [ 9920/13920]\n",
      "loss: 0.101209  [ 9984/13920]\n",
      "loss: 0.241088  [10048/13920]\n",
      "loss: 0.160524  [10112/13920]\n",
      "loss: 0.055942  [10176/13920]\n",
      "loss: 0.115371  [10240/13920]\n",
      "loss: 0.124591  [10304/13920]\n",
      "loss: 0.057484  [10368/13920]\n",
      "loss: 0.131818  [10432/13920]\n",
      "loss: 0.093367  [10496/13920]\n",
      "loss: 0.120798  [10560/13920]\n",
      "loss: 0.186578  [10624/13920]\n",
      "loss: 0.159633  [10688/13920]\n",
      "loss: 0.179214  [10752/13920]\n",
      "loss: 0.135223  [10816/13920]\n",
      "loss: 0.088911  [10880/13920]\n",
      "loss: 0.175632  [10944/13920]\n",
      "loss: 0.111365  [11008/13920]\n",
      "loss: 0.222773  [11072/13920]\n",
      "loss: 0.250389  [11136/13920]\n",
      "loss: 0.141036  [11200/13920]\n",
      "loss: 0.184606  [11264/13920]\n",
      "loss: 0.064403  [11328/13920]\n",
      "loss: 0.239528  [11392/13920]\n",
      "loss: 0.064769  [11456/13920]\n",
      "loss: 0.248483  [11520/13920]\n",
      "loss: 0.048039  [11584/13920]\n",
      "loss: 0.113041  [11648/13920]\n",
      "loss: 0.114453  [11712/13920]\n",
      "loss: 0.186088  [11776/13920]\n",
      "loss: 0.104318  [11840/13920]\n",
      "loss: 0.037212  [11904/13920]\n",
      "loss: 0.129533  [11968/13920]\n",
      "loss: 0.151720  [12032/13920]\n",
      "loss: 0.109395  [12096/13920]\n",
      "loss: 0.197495  [12160/13920]\n",
      "loss: 0.136736  [12224/13920]\n",
      "loss: 0.031772  [12288/13920]\n",
      "loss: 0.178151  [12352/13920]\n",
      "loss: 0.151052  [12416/13920]\n",
      "loss: 0.050078  [12480/13920]\n",
      "loss: 0.091826  [12544/13920]\n",
      "loss: 0.221971  [12608/13920]\n",
      "loss: 0.160059  [12672/13920]\n",
      "loss: 0.102497  [12736/13920]\n",
      "loss: 0.123800  [12800/13920]\n",
      "loss: 0.153396  [12864/13920]\n",
      "loss: 0.071129  [12928/13920]\n",
      "loss: 0.206347  [12992/13920]\n",
      "loss: 0.118982  [13056/13920]\n",
      "loss: 0.183792  [13120/13920]\n",
      "loss: 0.093244  [13184/13920]\n",
      "loss: 0.140467  [13248/13920]\n",
      "loss: 0.178102  [13312/13920]\n",
      "loss: 0.136067  [13376/13920]\n",
      "loss: 0.163143  [13440/13920]\n",
      "loss: 0.175176  [13504/13920]\n",
      "loss: 0.197198  [13568/13920]\n",
      "loss: 0.100674  [13632/13920]\n",
      "loss: 0.132010  [13696/13920]\n",
      "loss: 0.084958  [13760/13920]\n",
      "loss: 0.191066  [13824/13920]\n",
      "loss: 0.096088  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 95.8% \n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.158587 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.050566  [    0/13920]\n",
      "loss: 0.079790  [   64/13920]\n",
      "loss: 0.075119  [  128/13920]\n",
      "loss: 0.155737  [  192/13920]\n",
      "loss: 0.074453  [  256/13920]\n",
      "loss: 0.119345  [  320/13920]\n",
      "loss: 0.087655  [  384/13920]\n",
      "loss: 0.247692  [  448/13920]\n",
      "loss: 0.184625  [  512/13920]\n",
      "loss: 0.060160  [  576/13920]\n",
      "loss: 0.049056  [  640/13920]\n",
      "loss: 0.129902  [  704/13920]\n",
      "loss: 0.059545  [  768/13920]\n",
      "loss: 0.106010  [  832/13920]\n",
      "loss: 0.139793  [  896/13920]\n",
      "loss: 0.105737  [  960/13920]\n",
      "loss: 0.073476  [ 1024/13920]\n",
      "loss: 0.105362  [ 1088/13920]\n",
      "loss: 0.058128  [ 1152/13920]\n",
      "loss: 0.037085  [ 1216/13920]\n",
      "loss: 0.088847  [ 1280/13920]\n",
      "loss: 0.178168  [ 1344/13920]\n",
      "loss: 0.058596  [ 1408/13920]\n",
      "loss: 0.113943  [ 1472/13920]\n",
      "loss: 0.098867  [ 1536/13920]\n",
      "loss: 0.129952  [ 1600/13920]\n",
      "loss: 0.053305  [ 1664/13920]\n",
      "loss: 0.109478  [ 1728/13920]\n",
      "loss: 0.150375  [ 1792/13920]\n",
      "loss: 0.141405  [ 1856/13920]\n",
      "loss: 0.131291  [ 1920/13920]\n",
      "loss: 0.113734  [ 1984/13920]\n",
      "loss: 0.068068  [ 2048/13920]\n",
      "loss: 0.102066  [ 2112/13920]\n",
      "loss: 0.073474  [ 2176/13920]\n",
      "loss: 0.153310  [ 2240/13920]\n",
      "loss: 0.070836  [ 2304/13920]\n",
      "loss: 0.073599  [ 2368/13920]\n",
      "loss: 0.049595  [ 2432/13920]\n",
      "loss: 0.109097  [ 2496/13920]\n",
      "loss: 0.093761  [ 2560/13920]\n",
      "loss: 0.120379  [ 2624/13920]\n",
      "loss: 0.100496  [ 2688/13920]\n",
      "loss: 0.171762  [ 2752/13920]\n",
      "loss: 0.168476  [ 2816/13920]\n",
      "loss: 0.055611  [ 2880/13920]\n",
      "loss: 0.110928  [ 2944/13920]\n",
      "loss: 0.162075  [ 3008/13920]\n",
      "loss: 0.054191  [ 3072/13920]\n",
      "loss: 0.053031  [ 3136/13920]\n",
      "loss: 0.077908  [ 3200/13920]\n",
      "loss: 0.062571  [ 3264/13920]\n",
      "loss: 0.037735  [ 3328/13920]\n",
      "loss: 0.159553  [ 3392/13920]\n",
      "loss: 0.057482  [ 3456/13920]\n",
      "loss: 0.070908  [ 3520/13920]\n",
      "loss: 0.147200  [ 3584/13920]\n",
      "loss: 0.039605  [ 3648/13920]\n",
      "loss: 0.112545  [ 3712/13920]\n",
      "loss: 0.105648  [ 3776/13920]\n",
      "loss: 0.043286  [ 3840/13920]\n",
      "loss: 0.077530  [ 3904/13920]\n",
      "loss: 0.092695  [ 3968/13920]\n",
      "loss: 0.160508  [ 4032/13920]\n",
      "loss: 0.063146  [ 4096/13920]\n",
      "loss: 0.092561  [ 4160/13920]\n",
      "loss: 0.061694  [ 4224/13920]\n",
      "loss: 0.082305  [ 4288/13920]\n",
      "loss: 0.104138  [ 4352/13920]\n",
      "loss: 0.178913  [ 4416/13920]\n",
      "loss: 0.112224  [ 4480/13920]\n",
      "loss: 0.112861  [ 4544/13920]\n",
      "loss: 0.117772  [ 4608/13920]\n",
      "loss: 0.122954  [ 4672/13920]\n",
      "loss: 0.117939  [ 4736/13920]\n",
      "loss: 0.139208  [ 4800/13920]\n",
      "loss: 0.155296  [ 4864/13920]\n",
      "loss: 0.177702  [ 4928/13920]\n",
      "loss: 0.095074  [ 4992/13920]\n",
      "loss: 0.095698  [ 5056/13920]\n",
      "loss: 0.053307  [ 5120/13920]\n",
      "loss: 0.115016  [ 5184/13920]\n",
      "loss: 0.081691  [ 5248/13920]\n",
      "loss: 0.203635  [ 5312/13920]\n",
      "loss: 0.205893  [ 5376/13920]\n",
      "loss: 0.167626  [ 5440/13920]\n",
      "loss: 0.090436  [ 5504/13920]\n",
      "loss: 0.144424  [ 5568/13920]\n",
      "loss: 0.096750  [ 5632/13920]\n",
      "loss: 0.091667  [ 5696/13920]\n",
      "loss: 0.088237  [ 5760/13920]\n",
      "loss: 0.269143  [ 5824/13920]\n",
      "loss: 0.127051  [ 5888/13920]\n",
      "loss: 0.130460  [ 5952/13920]\n",
      "loss: 0.161485  [ 6016/13920]\n",
      "loss: 0.116263  [ 6080/13920]\n",
      "loss: 0.051047  [ 6144/13920]\n",
      "loss: 0.146100  [ 6208/13920]\n",
      "loss: 0.073212  [ 6272/13920]\n",
      "loss: 0.223211  [ 6336/13920]\n",
      "loss: 0.088815  [ 6400/13920]\n",
      "loss: 0.067919  [ 6464/13920]\n",
      "loss: 0.062793  [ 6528/13920]\n",
      "loss: 0.099813  [ 6592/13920]\n",
      "loss: 0.057102  [ 6656/13920]\n",
      "loss: 0.131914  [ 6720/13920]\n",
      "loss: 0.052197  [ 6784/13920]\n",
      "loss: 0.082245  [ 6848/13920]\n",
      "loss: 0.110634  [ 6912/13920]\n",
      "loss: 0.132004  [ 6976/13920]\n",
      "loss: 0.052868  [ 7040/13920]\n",
      "loss: 0.152370  [ 7104/13920]\n",
      "loss: 0.100597  [ 7168/13920]\n",
      "loss: 0.135082  [ 7232/13920]\n",
      "loss: 0.045455  [ 7296/13920]\n",
      "loss: 0.106833  [ 7360/13920]\n",
      "loss: 0.213756  [ 7424/13920]\n",
      "loss: 0.051393  [ 7488/13920]\n",
      "loss: 0.090861  [ 7552/13920]\n",
      "loss: 0.097561  [ 7616/13920]\n",
      "loss: 0.164957  [ 7680/13920]\n",
      "loss: 0.103538  [ 7744/13920]\n",
      "loss: 0.191540  [ 7808/13920]\n",
      "loss: 0.106580  [ 7872/13920]\n",
      "loss: 0.094948  [ 7936/13920]\n",
      "loss: 0.236986  [ 8000/13920]\n",
      "loss: 0.065908  [ 8064/13920]\n",
      "loss: 0.205590  [ 8128/13920]\n",
      "loss: 0.078666  [ 8192/13920]\n",
      "loss: 0.074590  [ 8256/13920]\n",
      "loss: 0.186644  [ 8320/13920]\n",
      "loss: 0.067418  [ 8384/13920]\n",
      "loss: 0.044998  [ 8448/13920]\n",
      "loss: 0.167622  [ 8512/13920]\n",
      "loss: 0.107182  [ 8576/13920]\n",
      "loss: 0.063029  [ 8640/13920]\n",
      "loss: 0.097827  [ 8704/13920]\n",
      "loss: 0.168672  [ 8768/13920]\n",
      "loss: 0.082282  [ 8832/13920]\n",
      "loss: 0.126783  [ 8896/13920]\n",
      "loss: 0.067149  [ 8960/13920]\n",
      "loss: 0.048073  [ 9024/13920]\n",
      "loss: 0.137112  [ 9088/13920]\n",
      "loss: 0.145722  [ 9152/13920]\n",
      "loss: 0.120299  [ 9216/13920]\n",
      "loss: 0.133553  [ 9280/13920]\n",
      "loss: 0.141470  [ 9344/13920]\n",
      "loss: 0.214259  [ 9408/13920]\n",
      "loss: 0.073845  [ 9472/13920]\n",
      "loss: 0.192874  [ 9536/13920]\n",
      "loss: 0.109110  [ 9600/13920]\n",
      "loss: 0.091147  [ 9664/13920]\n",
      "loss: 0.127918  [ 9728/13920]\n",
      "loss: 0.339035  [ 9792/13920]\n",
      "loss: 0.114623  [ 9856/13920]\n",
      "loss: 0.120236  [ 9920/13920]\n",
      "loss: 0.128428  [ 9984/13920]\n",
      "loss: 0.085922  [10048/13920]\n",
      "loss: 0.117418  [10112/13920]\n",
      "loss: 0.117672  [10176/13920]\n",
      "loss: 0.062603  [10240/13920]\n",
      "loss: 0.151235  [10304/13920]\n",
      "loss: 0.077668  [10368/13920]\n",
      "loss: 0.095927  [10432/13920]\n",
      "loss: 0.193455  [10496/13920]\n",
      "loss: 0.145154  [10560/13920]\n",
      "loss: 0.068387  [10624/13920]\n",
      "loss: 0.182404  [10688/13920]\n",
      "loss: 0.093931  [10752/13920]\n",
      "loss: 0.120056  [10816/13920]\n",
      "loss: 0.075432  [10880/13920]\n",
      "loss: 0.082946  [10944/13920]\n",
      "loss: 0.051666  [11008/13920]\n",
      "loss: 0.121766  [11072/13920]\n",
      "loss: 0.181493  [11136/13920]\n",
      "loss: 0.056010  [11200/13920]\n",
      "loss: 0.084170  [11264/13920]\n",
      "loss: 0.046576  [11328/13920]\n",
      "loss: 0.078059  [11392/13920]\n",
      "loss: 0.026729  [11456/13920]\n",
      "loss: 0.069615  [11520/13920]\n",
      "loss: 0.100511  [11584/13920]\n",
      "loss: 0.114874  [11648/13920]\n",
      "loss: 0.150395  [11712/13920]\n",
      "loss: 0.172144  [11776/13920]\n",
      "loss: 0.109981  [11840/13920]\n",
      "loss: 0.127497  [11904/13920]\n",
      "loss: 0.046869  [11968/13920]\n",
      "loss: 0.092182  [12032/13920]\n",
      "loss: 0.178647  [12096/13920]\n",
      "loss: 0.054746  [12160/13920]\n",
      "loss: 0.250059  [12224/13920]\n",
      "loss: 0.126960  [12288/13920]\n",
      "loss: 0.054327  [12352/13920]\n",
      "loss: 0.070937  [12416/13920]\n",
      "loss: 0.071089  [12480/13920]\n",
      "loss: 0.098778  [12544/13920]\n",
      "loss: 0.045684  [12608/13920]\n",
      "loss: 0.114501  [12672/13920]\n",
      "loss: 0.127728  [12736/13920]\n",
      "loss: 0.075117  [12800/13920]\n",
      "loss: 0.049871  [12864/13920]\n",
      "loss: 0.064990  [12928/13920]\n",
      "loss: 0.118718  [12992/13920]\n",
      "loss: 0.085942  [13056/13920]\n",
      "loss: 0.080481  [13120/13920]\n",
      "loss: 0.125779  [13184/13920]\n",
      "loss: 0.094645  [13248/13920]\n",
      "loss: 0.089115  [13312/13920]\n",
      "loss: 0.072429  [13376/13920]\n",
      "loss: 0.184433  [13440/13920]\n",
      "loss: 0.137603  [13504/13920]\n",
      "loss: 0.092782  [13568/13920]\n",
      "loss: 0.146343  [13632/13920]\n",
      "loss: 0.078244  [13696/13920]\n",
      "loss: 0.093715  [13760/13920]\n",
      "loss: 0.124242  [13824/13920]\n",
      "loss: 0.231190  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 96.3% \n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.170987 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.102196  [    0/13920]\n",
      "loss: 0.057023  [   64/13920]\n",
      "loss: 0.106838  [  128/13920]\n",
      "loss: 0.045733  [  192/13920]\n",
      "loss: 0.112942  [  256/13920]\n",
      "loss: 0.126475  [  320/13920]\n",
      "loss: 0.071968  [  384/13920]\n",
      "loss: 0.066963  [  448/13920]\n",
      "loss: 0.046524  [  512/13920]\n",
      "loss: 0.098345  [  576/13920]\n",
      "loss: 0.065040  [  640/13920]\n",
      "loss: 0.063680  [  704/13920]\n",
      "loss: 0.121802  [  768/13920]\n",
      "loss: 0.115042  [  832/13920]\n",
      "loss: 0.136716  [  896/13920]\n",
      "loss: 0.094836  [  960/13920]\n",
      "loss: 0.131896  [ 1024/13920]\n",
      "loss: 0.091564  [ 1088/13920]\n",
      "loss: 0.125063  [ 1152/13920]\n",
      "loss: 0.186951  [ 1216/13920]\n",
      "loss: 0.063630  [ 1280/13920]\n",
      "loss: 0.107877  [ 1344/13920]\n",
      "loss: 0.046133  [ 1408/13920]\n",
      "loss: 0.080016  [ 1472/13920]\n",
      "loss: 0.045017  [ 1536/13920]\n",
      "loss: 0.090609  [ 1600/13920]\n",
      "loss: 0.041341  [ 1664/13920]\n",
      "loss: 0.088926  [ 1728/13920]\n",
      "loss: 0.135743  [ 1792/13920]\n",
      "loss: 0.076931  [ 1856/13920]\n",
      "loss: 0.165466  [ 1920/13920]\n",
      "loss: 0.075698  [ 1984/13920]\n",
      "loss: 0.131703  [ 2048/13920]\n",
      "loss: 0.084756  [ 2112/13920]\n",
      "loss: 0.042362  [ 2176/13920]\n",
      "loss: 0.076994  [ 2240/13920]\n",
      "loss: 0.024599  [ 2304/13920]\n",
      "loss: 0.079007  [ 2368/13920]\n",
      "loss: 0.086424  [ 2432/13920]\n",
      "loss: 0.156342  [ 2496/13920]\n",
      "loss: 0.081639  [ 2560/13920]\n",
      "loss: 0.067600  [ 2624/13920]\n",
      "loss: 0.072043  [ 2688/13920]\n",
      "loss: 0.072166  [ 2752/13920]\n",
      "loss: 0.097718  [ 2816/13920]\n",
      "loss: 0.169308  [ 2880/13920]\n",
      "loss: 0.114258  [ 2944/13920]\n",
      "loss: 0.072446  [ 3008/13920]\n",
      "loss: 0.212515  [ 3072/13920]\n",
      "loss: 0.134151  [ 3136/13920]\n",
      "loss: 0.076741  [ 3200/13920]\n",
      "loss: 0.056007  [ 3264/13920]\n",
      "loss: 0.019199  [ 3328/13920]\n",
      "loss: 0.035362  [ 3392/13920]\n",
      "loss: 0.188486  [ 3456/13920]\n",
      "loss: 0.032147  [ 3520/13920]\n",
      "loss: 0.172900  [ 3584/13920]\n",
      "loss: 0.080181  [ 3648/13920]\n",
      "loss: 0.038746  [ 3712/13920]\n",
      "loss: 0.052090  [ 3776/13920]\n",
      "loss: 0.045420  [ 3840/13920]\n",
      "loss: 0.070056  [ 3904/13920]\n",
      "loss: 0.048598  [ 3968/13920]\n",
      "loss: 0.122105  [ 4032/13920]\n",
      "loss: 0.045473  [ 4096/13920]\n",
      "loss: 0.080018  [ 4160/13920]\n",
      "loss: 0.138079  [ 4224/13920]\n",
      "loss: 0.110255  [ 4288/13920]\n",
      "loss: 0.163241  [ 4352/13920]\n",
      "loss: 0.054123  [ 4416/13920]\n",
      "loss: 0.132004  [ 4480/13920]\n",
      "loss: 0.082968  [ 4544/13920]\n",
      "loss: 0.089523  [ 4608/13920]\n",
      "loss: 0.118117  [ 4672/13920]\n",
      "loss: 0.057976  [ 4736/13920]\n",
      "loss: 0.136345  [ 4800/13920]\n",
      "loss: 0.090832  [ 4864/13920]\n",
      "loss: 0.055553  [ 4928/13920]\n",
      "loss: 0.171753  [ 4992/13920]\n",
      "loss: 0.104959  [ 5056/13920]\n",
      "loss: 0.105828  [ 5120/13920]\n",
      "loss: 0.111862  [ 5184/13920]\n",
      "loss: 0.142753  [ 5248/13920]\n",
      "loss: 0.149146  [ 5312/13920]\n",
      "loss: 0.104353  [ 5376/13920]\n",
      "loss: 0.122069  [ 5440/13920]\n",
      "loss: 0.079318  [ 5504/13920]\n",
      "loss: 0.044121  [ 5568/13920]\n",
      "loss: 0.079576  [ 5632/13920]\n",
      "loss: 0.084652  [ 5696/13920]\n",
      "loss: 0.039741  [ 5760/13920]\n",
      "loss: 0.123752  [ 5824/13920]\n",
      "loss: 0.075689  [ 5888/13920]\n",
      "loss: 0.032708  [ 5952/13920]\n",
      "loss: 0.053423  [ 6016/13920]\n",
      "loss: 0.035807  [ 6080/13920]\n",
      "loss: 0.117671  [ 6144/13920]\n",
      "loss: 0.170183  [ 6208/13920]\n",
      "loss: 0.041186  [ 6272/13920]\n",
      "loss: 0.072552  [ 6336/13920]\n",
      "loss: 0.062682  [ 6400/13920]\n",
      "loss: 0.028245  [ 6464/13920]\n",
      "loss: 0.121120  [ 6528/13920]\n",
      "loss: 0.063114  [ 6592/13920]\n",
      "loss: 0.124426  [ 6656/13920]\n",
      "loss: 0.143948  [ 6720/13920]\n",
      "loss: 0.066550  [ 6784/13920]\n",
      "loss: 0.127088  [ 6848/13920]\n",
      "loss: 0.057921  [ 6912/13920]\n",
      "loss: 0.063505  [ 6976/13920]\n",
      "loss: 0.130877  [ 7040/13920]\n",
      "loss: 0.058614  [ 7104/13920]\n",
      "loss: 0.053490  [ 7168/13920]\n",
      "loss: 0.105870  [ 7232/13920]\n",
      "loss: 0.060821  [ 7296/13920]\n",
      "loss: 0.037219  [ 7360/13920]\n",
      "loss: 0.139271  [ 7424/13920]\n",
      "loss: 0.080574  [ 7488/13920]\n",
      "loss: 0.044264  [ 7552/13920]\n",
      "loss: 0.063071  [ 7616/13920]\n",
      "loss: 0.047316  [ 7680/13920]\n",
      "loss: 0.130464  [ 7744/13920]\n",
      "loss: 0.049007  [ 7808/13920]\n",
      "loss: 0.074342  [ 7872/13920]\n",
      "loss: 0.072992  [ 7936/13920]\n",
      "loss: 0.055568  [ 8000/13920]\n",
      "loss: 0.096420  [ 8064/13920]\n",
      "loss: 0.067882  [ 8128/13920]\n",
      "loss: 0.142831  [ 8192/13920]\n",
      "loss: 0.087124  [ 8256/13920]\n",
      "loss: 0.142853  [ 8320/13920]\n",
      "loss: 0.133317  [ 8384/13920]\n",
      "loss: 0.066743  [ 8448/13920]\n",
      "loss: 0.137688  [ 8512/13920]\n",
      "loss: 0.081657  [ 8576/13920]\n",
      "loss: 0.039564  [ 8640/13920]\n",
      "loss: 0.153118  [ 8704/13920]\n",
      "loss: 0.021906  [ 8768/13920]\n",
      "loss: 0.043182  [ 8832/13920]\n",
      "loss: 0.034293  [ 8896/13920]\n",
      "loss: 0.096073  [ 8960/13920]\n",
      "loss: 0.063077  [ 9024/13920]\n",
      "loss: 0.051037  [ 9088/13920]\n",
      "loss: 0.105816  [ 9152/13920]\n",
      "loss: 0.037240  [ 9216/13920]\n",
      "loss: 0.086169  [ 9280/13920]\n",
      "loss: 0.075583  [ 9344/13920]\n",
      "loss: 0.059903  [ 9408/13920]\n",
      "loss: 0.062489  [ 9472/13920]\n",
      "loss: 0.035689  [ 9536/13920]\n",
      "loss: 0.052641  [ 9600/13920]\n",
      "loss: 0.101684  [ 9664/13920]\n",
      "loss: 0.154373  [ 9728/13920]\n",
      "loss: 0.058666  [ 9792/13920]\n",
      "loss: 0.187130  [ 9856/13920]\n",
      "loss: 0.041755  [ 9920/13920]\n",
      "loss: 0.058822  [ 9984/13920]\n",
      "loss: 0.035891  [10048/13920]\n",
      "loss: 0.260302  [10112/13920]\n",
      "loss: 0.064151  [10176/13920]\n",
      "loss: 0.110457  [10240/13920]\n",
      "loss: 0.049688  [10304/13920]\n",
      "loss: 0.062266  [10368/13920]\n",
      "loss: 0.042623  [10432/13920]\n",
      "loss: 0.079937  [10496/13920]\n",
      "loss: 0.132219  [10560/13920]\n",
      "loss: 0.063249  [10624/13920]\n",
      "loss: 0.100467  [10688/13920]\n",
      "loss: 0.028412  [10752/13920]\n",
      "loss: 0.143435  [10816/13920]\n",
      "loss: 0.075201  [10880/13920]\n",
      "loss: 0.098926  [10944/13920]\n",
      "loss: 0.061027  [11008/13920]\n",
      "loss: 0.074274  [11072/13920]\n",
      "loss: 0.048065  [11136/13920]\n",
      "loss: 0.086479  [11200/13920]\n",
      "loss: 0.093371  [11264/13920]\n",
      "loss: 0.121748  [11328/13920]\n",
      "loss: 0.082438  [11392/13920]\n",
      "loss: 0.046450  [11456/13920]\n",
      "loss: 0.057975  [11520/13920]\n",
      "loss: 0.037053  [11584/13920]\n",
      "loss: 0.059036  [11648/13920]\n",
      "loss: 0.067099  [11712/13920]\n",
      "loss: 0.068587  [11776/13920]\n",
      "loss: 0.039562  [11840/13920]\n",
      "loss: 0.060183  [11904/13920]\n",
      "loss: 0.093716  [11968/13920]\n",
      "loss: 0.081767  [12032/13920]\n",
      "loss: 0.104655  [12096/13920]\n",
      "loss: 0.057831  [12160/13920]\n",
      "loss: 0.053522  [12224/13920]\n",
      "loss: 0.069330  [12288/13920]\n",
      "loss: 0.162361  [12352/13920]\n",
      "loss: 0.111269  [12416/13920]\n",
      "loss: 0.045166  [12480/13920]\n",
      "loss: 0.076813  [12544/13920]\n",
      "loss: 0.077034  [12608/13920]\n",
      "loss: 0.057352  [12672/13920]\n",
      "loss: 0.162509  [12736/13920]\n",
      "loss: 0.084047  [12800/13920]\n",
      "loss: 0.067477  [12864/13920]\n",
      "loss: 0.180633  [12928/13920]\n",
      "loss: 0.085471  [12992/13920]\n",
      "loss: 0.059612  [13056/13920]\n",
      "loss: 0.087894  [13120/13920]\n",
      "loss: 0.189482  [13184/13920]\n",
      "loss: 0.136388  [13248/13920]\n",
      "loss: 0.071945  [13312/13920]\n",
      "loss: 0.160139  [13376/13920]\n",
      "loss: 0.101315  [13440/13920]\n",
      "loss: 0.055311  [13504/13920]\n",
      "loss: 0.111745  [13568/13920]\n",
      "loss: 0.094578  [13632/13920]\n",
      "loss: 0.285722  [13696/13920]\n",
      "loss: 0.057058  [13760/13920]\n",
      "loss: 0.052474  [13824/13920]\n",
      "loss: 0.039446  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.1% \n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.154545 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.045632  [    0/13920]\n",
      "loss: 0.053065  [   64/13920]\n",
      "loss: 0.062692  [  128/13920]\n",
      "loss: 0.108356  [  192/13920]\n",
      "loss: 0.136387  [  256/13920]\n",
      "loss: 0.102381  [  320/13920]\n",
      "loss: 0.044546  [  384/13920]\n",
      "loss: 0.036132  [  448/13920]\n",
      "loss: 0.120221  [  512/13920]\n",
      "loss: 0.072029  [  576/13920]\n",
      "loss: 0.098878  [  640/13920]\n",
      "loss: 0.136355  [  704/13920]\n",
      "loss: 0.056815  [  768/13920]\n",
      "loss: 0.016852  [  832/13920]\n",
      "loss: 0.093202  [  896/13920]\n",
      "loss: 0.067544  [  960/13920]\n",
      "loss: 0.102090  [ 1024/13920]\n",
      "loss: 0.052332  [ 1088/13920]\n",
      "loss: 0.096009  [ 1152/13920]\n",
      "loss: 0.093100  [ 1216/13920]\n",
      "loss: 0.033486  [ 1280/13920]\n",
      "loss: 0.094568  [ 1344/13920]\n",
      "loss: 0.078384  [ 1408/13920]\n",
      "loss: 0.037021  [ 1472/13920]\n",
      "loss: 0.050042  [ 1536/13920]\n",
      "loss: 0.063142  [ 1600/13920]\n",
      "loss: 0.082072  [ 1664/13920]\n",
      "loss: 0.024644  [ 1728/13920]\n",
      "loss: 0.071466  [ 1792/13920]\n",
      "loss: 0.022057  [ 1856/13920]\n",
      "loss: 0.068870  [ 1920/13920]\n",
      "loss: 0.027568  [ 1984/13920]\n",
      "loss: 0.050091  [ 2048/13920]\n",
      "loss: 0.051653  [ 2112/13920]\n",
      "loss: 0.119239  [ 2176/13920]\n",
      "loss: 0.084639  [ 2240/13920]\n",
      "loss: 0.048444  [ 2304/13920]\n",
      "loss: 0.060009  [ 2368/13920]\n",
      "loss: 0.074181  [ 2432/13920]\n",
      "loss: 0.068126  [ 2496/13920]\n",
      "loss: 0.062411  [ 2560/13920]\n",
      "loss: 0.045531  [ 2624/13920]\n",
      "loss: 0.064886  [ 2688/13920]\n",
      "loss: 0.052042  [ 2752/13920]\n",
      "loss: 0.048143  [ 2816/13920]\n",
      "loss: 0.020445  [ 2880/13920]\n",
      "loss: 0.088751  [ 2944/13920]\n",
      "loss: 0.032454  [ 3008/13920]\n",
      "loss: 0.043272  [ 3072/13920]\n",
      "loss: 0.056959  [ 3136/13920]\n",
      "loss: 0.172408  [ 3200/13920]\n",
      "loss: 0.074902  [ 3264/13920]\n",
      "loss: 0.104156  [ 3328/13920]\n",
      "loss: 0.033529  [ 3392/13920]\n",
      "loss: 0.069568  [ 3456/13920]\n",
      "loss: 0.041515  [ 3520/13920]\n",
      "loss: 0.067572  [ 3584/13920]\n",
      "loss: 0.077517  [ 3648/13920]\n",
      "loss: 0.046684  [ 3712/13920]\n",
      "loss: 0.205244  [ 3776/13920]\n",
      "loss: 0.072557  [ 3840/13920]\n",
      "loss: 0.140951  [ 3904/13920]\n",
      "loss: 0.054777  [ 3968/13920]\n",
      "loss: 0.057228  [ 4032/13920]\n",
      "loss: 0.050475  [ 4096/13920]\n",
      "loss: 0.027851  [ 4160/13920]\n",
      "loss: 0.052951  [ 4224/13920]\n",
      "loss: 0.115275  [ 4288/13920]\n",
      "loss: 0.086833  [ 4352/13920]\n",
      "loss: 0.078037  [ 4416/13920]\n",
      "loss: 0.081070  [ 4480/13920]\n",
      "loss: 0.163076  [ 4544/13920]\n",
      "loss: 0.055608  [ 4608/13920]\n",
      "loss: 0.046084  [ 4672/13920]\n",
      "loss: 0.052203  [ 4736/13920]\n",
      "loss: 0.146707  [ 4800/13920]\n",
      "loss: 0.035274  [ 4864/13920]\n",
      "loss: 0.146955  [ 4928/13920]\n",
      "loss: 0.046204  [ 4992/13920]\n",
      "loss: 0.044226  [ 5056/13920]\n",
      "loss: 0.182676  [ 5120/13920]\n",
      "loss: 0.048352  [ 5184/13920]\n",
      "loss: 0.063914  [ 5248/13920]\n",
      "loss: 0.123370  [ 5312/13920]\n",
      "loss: 0.143157  [ 5376/13920]\n",
      "loss: 0.060228  [ 5440/13920]\n",
      "loss: 0.108927  [ 5504/13920]\n",
      "loss: 0.055819  [ 5568/13920]\n",
      "loss: 0.078542  [ 5632/13920]\n",
      "loss: 0.067633  [ 5696/13920]\n",
      "loss: 0.060770  [ 5760/13920]\n",
      "loss: 0.031961  [ 5824/13920]\n",
      "loss: 0.061951  [ 5888/13920]\n",
      "loss: 0.074189  [ 5952/13920]\n",
      "loss: 0.051566  [ 6016/13920]\n",
      "loss: 0.067870  [ 6080/13920]\n",
      "loss: 0.275816  [ 6144/13920]\n",
      "loss: 0.117100  [ 6208/13920]\n",
      "loss: 0.076879  [ 6272/13920]\n",
      "loss: 0.075175  [ 6336/13920]\n",
      "loss: 0.042505  [ 6400/13920]\n",
      "loss: 0.062594  [ 6464/13920]\n",
      "loss: 0.013322  [ 6528/13920]\n",
      "loss: 0.044057  [ 6592/13920]\n",
      "loss: 0.031673  [ 6656/13920]\n",
      "loss: 0.091372  [ 6720/13920]\n",
      "loss: 0.079751  [ 6784/13920]\n",
      "loss: 0.116036  [ 6848/13920]\n",
      "loss: 0.098387  [ 6912/13920]\n",
      "loss: 0.062950  [ 6976/13920]\n",
      "loss: 0.034505  [ 7040/13920]\n",
      "loss: 0.233107  [ 7104/13920]\n",
      "loss: 0.065556  [ 7168/13920]\n",
      "loss: 0.043957  [ 7232/13920]\n",
      "loss: 0.080984  [ 7296/13920]\n",
      "loss: 0.117416  [ 7360/13920]\n",
      "loss: 0.048733  [ 7424/13920]\n",
      "loss: 0.117471  [ 7488/13920]\n",
      "loss: 0.046561  [ 7552/13920]\n",
      "loss: 0.071313  [ 7616/13920]\n",
      "loss: 0.134043  [ 7680/13920]\n",
      "loss: 0.081371  [ 7744/13920]\n",
      "loss: 0.172000  [ 7808/13920]\n",
      "loss: 0.096818  [ 7872/13920]\n",
      "loss: 0.180181  [ 7936/13920]\n",
      "loss: 0.060196  [ 8000/13920]\n",
      "loss: 0.054510  [ 8064/13920]\n",
      "loss: 0.060270  [ 8128/13920]\n",
      "loss: 0.086735  [ 8192/13920]\n",
      "loss: 0.076073  [ 8256/13920]\n",
      "loss: 0.109056  [ 8320/13920]\n",
      "loss: 0.070500  [ 8384/13920]\n",
      "loss: 0.043376  [ 8448/13920]\n",
      "loss: 0.087268  [ 8512/13920]\n",
      "loss: 0.044456  [ 8576/13920]\n",
      "loss: 0.048574  [ 8640/13920]\n",
      "loss: 0.041950  [ 8704/13920]\n",
      "loss: 0.050454  [ 8768/13920]\n",
      "loss: 0.025703  [ 8832/13920]\n",
      "loss: 0.067230  [ 8896/13920]\n",
      "loss: 0.156045  [ 8960/13920]\n",
      "loss: 0.079287  [ 9024/13920]\n",
      "loss: 0.102370  [ 9088/13920]\n",
      "loss: 0.050361  [ 9152/13920]\n",
      "loss: 0.027574  [ 9216/13920]\n",
      "loss: 0.193619  [ 9280/13920]\n",
      "loss: 0.073701  [ 9344/13920]\n",
      "loss: 0.066476  [ 9408/13920]\n",
      "loss: 0.083974  [ 9472/13920]\n",
      "loss: 0.065427  [ 9536/13920]\n",
      "loss: 0.044957  [ 9600/13920]\n",
      "loss: 0.034516  [ 9664/13920]\n",
      "loss: 0.033289  [ 9728/13920]\n",
      "loss: 0.036901  [ 9792/13920]\n",
      "loss: 0.088455  [ 9856/13920]\n",
      "loss: 0.044034  [ 9920/13920]\n",
      "loss: 0.177737  [ 9984/13920]\n",
      "loss: 0.025486  [10048/13920]\n",
      "loss: 0.044748  [10112/13920]\n",
      "loss: 0.018339  [10176/13920]\n",
      "loss: 0.103041  [10240/13920]\n",
      "loss: 0.184947  [10304/13920]\n",
      "loss: 0.145790  [10368/13920]\n",
      "loss: 0.044236  [10432/13920]\n",
      "loss: 0.028535  [10496/13920]\n",
      "loss: 0.175015  [10560/13920]\n",
      "loss: 0.110676  [10624/13920]\n",
      "loss: 0.055475  [10688/13920]\n",
      "loss: 0.021375  [10752/13920]\n",
      "loss: 0.048754  [10816/13920]\n",
      "loss: 0.054399  [10880/13920]\n",
      "loss: 0.093100  [10944/13920]\n",
      "loss: 0.164427  [11008/13920]\n",
      "loss: 0.032440  [11072/13920]\n",
      "loss: 0.112374  [11136/13920]\n",
      "loss: 0.031113  [11200/13920]\n",
      "loss: 0.064338  [11264/13920]\n",
      "loss: 0.104359  [11328/13920]\n",
      "loss: 0.166180  [11392/13920]\n",
      "loss: 0.047516  [11456/13920]\n",
      "loss: 0.043523  [11520/13920]\n",
      "loss: 0.031581  [11584/13920]\n",
      "loss: 0.054959  [11648/13920]\n",
      "loss: 0.031948  [11712/13920]\n",
      "loss: 0.039576  [11776/13920]\n",
      "loss: 0.060948  [11840/13920]\n",
      "loss: 0.095569  [11904/13920]\n",
      "loss: 0.031535  [11968/13920]\n",
      "loss: 0.120485  [12032/13920]\n",
      "loss: 0.069612  [12096/13920]\n",
      "loss: 0.026830  [12160/13920]\n",
      "loss: 0.134069  [12224/13920]\n",
      "loss: 0.083255  [12288/13920]\n",
      "loss: 0.034994  [12352/13920]\n",
      "loss: 0.035922  [12416/13920]\n",
      "loss: 0.035455  [12480/13920]\n",
      "loss: 0.110932  [12544/13920]\n",
      "loss: 0.049696  [12608/13920]\n",
      "loss: 0.084567  [12672/13920]\n",
      "loss: 0.038642  [12736/13920]\n",
      "loss: 0.026688  [12800/13920]\n",
      "loss: 0.101776  [12864/13920]\n",
      "loss: 0.032463  [12928/13920]\n",
      "loss: 0.087835  [12992/13920]\n",
      "loss: 0.038674  [13056/13920]\n",
      "loss: 0.060301  [13120/13920]\n",
      "loss: 0.102709  [13184/13920]\n",
      "loss: 0.100251  [13248/13920]\n",
      "loss: 0.039572  [13312/13920]\n",
      "loss: 0.071846  [13376/13920]\n",
      "loss: 0.108067  [13440/13920]\n",
      "loss: 0.068951  [13504/13920]\n",
      "loss: 0.017304  [13568/13920]\n",
      "loss: 0.054092  [13632/13920]\n",
      "loss: 0.138743  [13696/13920]\n",
      "loss: 0.015233  [13760/13920]\n",
      "loss: 0.014097  [13824/13920]\n",
      "loss: 0.017880  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 97.5% \n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.140107 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.059502  [    0/13920]\n",
      "loss: 0.058784  [   64/13920]\n",
      "loss: 0.023918  [  128/13920]\n",
      "loss: 0.027106  [  192/13920]\n",
      "loss: 0.035719  [  256/13920]\n",
      "loss: 0.046155  [  320/13920]\n",
      "loss: 0.037506  [  384/13920]\n",
      "loss: 0.030633  [  448/13920]\n",
      "loss: 0.069151  [  512/13920]\n",
      "loss: 0.018251  [  576/13920]\n",
      "loss: 0.078641  [  640/13920]\n",
      "loss: 0.043440  [  704/13920]\n",
      "loss: 0.082340  [  768/13920]\n",
      "loss: 0.018503  [  832/13920]\n",
      "loss: 0.014478  [  896/13920]\n",
      "loss: 0.114214  [  960/13920]\n",
      "loss: 0.059185  [ 1024/13920]\n",
      "loss: 0.046667  [ 1088/13920]\n",
      "loss: 0.097288  [ 1152/13920]\n",
      "loss: 0.040864  [ 1216/13920]\n",
      "loss: 0.109716  [ 1280/13920]\n",
      "loss: 0.021720  [ 1344/13920]\n",
      "loss: 0.051189  [ 1408/13920]\n",
      "loss: 0.040495  [ 1472/13920]\n",
      "loss: 0.047204  [ 1536/13920]\n",
      "loss: 0.032030  [ 1600/13920]\n",
      "loss: 0.046323  [ 1664/13920]\n",
      "loss: 0.035533  [ 1728/13920]\n",
      "loss: 0.031508  [ 1792/13920]\n",
      "loss: 0.048097  [ 1856/13920]\n",
      "loss: 0.053950  [ 1920/13920]\n",
      "loss: 0.092787  [ 1984/13920]\n",
      "loss: 0.070868  [ 2048/13920]\n",
      "loss: 0.057486  [ 2112/13920]\n",
      "loss: 0.084571  [ 2176/13920]\n",
      "loss: 0.040687  [ 2240/13920]\n",
      "loss: 0.035099  [ 2304/13920]\n",
      "loss: 0.072590  [ 2368/13920]\n",
      "loss: 0.047259  [ 2432/13920]\n",
      "loss: 0.026092  [ 2496/13920]\n",
      "loss: 0.047572  [ 2560/13920]\n",
      "loss: 0.129444  [ 2624/13920]\n",
      "loss: 0.038153  [ 2688/13920]\n",
      "loss: 0.072805  [ 2752/13920]\n",
      "loss: 0.074154  [ 2816/13920]\n",
      "loss: 0.062867  [ 2880/13920]\n",
      "loss: 0.035892  [ 2944/13920]\n",
      "loss: 0.019533  [ 3008/13920]\n",
      "loss: 0.051067  [ 3072/13920]\n",
      "loss: 0.075182  [ 3136/13920]\n",
      "loss: 0.049672  [ 3200/13920]\n",
      "loss: 0.069807  [ 3264/13920]\n",
      "loss: 0.064240  [ 3328/13920]\n",
      "loss: 0.025780  [ 3392/13920]\n",
      "loss: 0.088282  [ 3456/13920]\n",
      "loss: 0.085390  [ 3520/13920]\n",
      "loss: 0.031749  [ 3584/13920]\n",
      "loss: 0.037382  [ 3648/13920]\n",
      "loss: 0.105229  [ 3712/13920]\n",
      "loss: 0.080984  [ 3776/13920]\n",
      "loss: 0.036200  [ 3840/13920]\n",
      "loss: 0.095311  [ 3904/13920]\n",
      "loss: 0.052546  [ 3968/13920]\n",
      "loss: 0.057178  [ 4032/13920]\n",
      "loss: 0.071981  [ 4096/13920]\n",
      "loss: 0.051611  [ 4160/13920]\n",
      "loss: 0.034787  [ 4224/13920]\n",
      "loss: 0.071444  [ 4288/13920]\n",
      "loss: 0.195990  [ 4352/13920]\n",
      "loss: 0.044065  [ 4416/13920]\n",
      "loss: 0.044377  [ 4480/13920]\n",
      "loss: 0.025300  [ 4544/13920]\n",
      "loss: 0.118536  [ 4608/13920]\n",
      "loss: 0.060516  [ 4672/13920]\n",
      "loss: 0.045393  [ 4736/13920]\n",
      "loss: 0.069945  [ 4800/13920]\n",
      "loss: 0.070595  [ 4864/13920]\n",
      "loss: 0.040803  [ 4928/13920]\n",
      "loss: 0.032151  [ 4992/13920]\n",
      "loss: 0.094395  [ 5056/13920]\n",
      "loss: 0.053867  [ 5120/13920]\n",
      "loss: 0.164293  [ 5184/13920]\n",
      "loss: 0.052207  [ 5248/13920]\n",
      "loss: 0.088581  [ 5312/13920]\n",
      "loss: 0.081668  [ 5376/13920]\n",
      "loss: 0.035938  [ 5440/13920]\n",
      "loss: 0.090360  [ 5504/13920]\n",
      "loss: 0.034284  [ 5568/13920]\n",
      "loss: 0.107278  [ 5632/13920]\n",
      "loss: 0.024290  [ 5696/13920]\n",
      "loss: 0.072648  [ 5760/13920]\n",
      "loss: 0.164298  [ 5824/13920]\n",
      "loss: 0.057175  [ 5888/13920]\n",
      "loss: 0.041439  [ 5952/13920]\n",
      "loss: 0.086646  [ 6016/13920]\n",
      "loss: 0.044893  [ 6080/13920]\n",
      "loss: 0.077915  [ 6144/13920]\n",
      "loss: 0.055615  [ 6208/13920]\n",
      "loss: 0.088313  [ 6272/13920]\n",
      "loss: 0.055723  [ 6336/13920]\n",
      "loss: 0.119526  [ 6400/13920]\n",
      "loss: 0.052588  [ 6464/13920]\n",
      "loss: 0.030980  [ 6528/13920]\n",
      "loss: 0.100460  [ 6592/13920]\n",
      "loss: 0.081565  [ 6656/13920]\n",
      "loss: 0.053611  [ 6720/13920]\n",
      "loss: 0.051258  [ 6784/13920]\n",
      "loss: 0.025030  [ 6848/13920]\n",
      "loss: 0.033037  [ 6912/13920]\n",
      "loss: 0.042180  [ 6976/13920]\n",
      "loss: 0.068560  [ 7040/13920]\n",
      "loss: 0.077601  [ 7104/13920]\n",
      "loss: 0.036878  [ 7168/13920]\n",
      "loss: 0.020006  [ 7232/13920]\n",
      "loss: 0.090569  [ 7296/13920]\n",
      "loss: 0.203838  [ 7360/13920]\n",
      "loss: 0.103556  [ 7424/13920]\n",
      "loss: 0.028808  [ 7488/13920]\n",
      "loss: 0.030759  [ 7552/13920]\n",
      "loss: 0.012257  [ 7616/13920]\n",
      "loss: 0.048911  [ 7680/13920]\n",
      "loss: 0.048896  [ 7744/13920]\n",
      "loss: 0.042922  [ 7808/13920]\n",
      "loss: 0.064397  [ 7872/13920]\n",
      "loss: 0.108714  [ 7936/13920]\n",
      "loss: 0.048958  [ 8000/13920]\n",
      "loss: 0.109529  [ 8064/13920]\n",
      "loss: 0.076117  [ 8128/13920]\n",
      "loss: 0.084957  [ 8192/13920]\n",
      "loss: 0.060277  [ 8256/13920]\n",
      "loss: 0.071202  [ 8320/13920]\n",
      "loss: 0.086222  [ 8384/13920]\n",
      "loss: 0.073665  [ 8448/13920]\n",
      "loss: 0.059794  [ 8512/13920]\n",
      "loss: 0.081771  [ 8576/13920]\n",
      "loss: 0.068658  [ 8640/13920]\n",
      "loss: 0.047185  [ 8704/13920]\n",
      "loss: 0.034602  [ 8768/13920]\n",
      "loss: 0.042900  [ 8832/13920]\n",
      "loss: 0.084766  [ 8896/13920]\n",
      "loss: 0.196517  [ 8960/13920]\n",
      "loss: 0.082122  [ 9024/13920]\n",
      "loss: 0.022437  [ 9088/13920]\n",
      "loss: 0.095435  [ 9152/13920]\n",
      "loss: 0.057318  [ 9216/13920]\n",
      "loss: 0.013740  [ 9280/13920]\n",
      "loss: 0.054040  [ 9344/13920]\n",
      "loss: 0.065018  [ 9408/13920]\n",
      "loss: 0.077085  [ 9472/13920]\n",
      "loss: 0.086229  [ 9536/13920]\n",
      "loss: 0.075312  [ 9600/13920]\n",
      "loss: 0.078530  [ 9664/13920]\n",
      "loss: 0.031216  [ 9728/13920]\n",
      "loss: 0.087583  [ 9792/13920]\n",
      "loss: 0.040771  [ 9856/13920]\n",
      "loss: 0.068855  [ 9920/13920]\n",
      "loss: 0.018234  [ 9984/13920]\n",
      "loss: 0.020063  [10048/13920]\n",
      "loss: 0.055742  [10112/13920]\n",
      "loss: 0.068740  [10176/13920]\n",
      "loss: 0.060168  [10240/13920]\n",
      "loss: 0.088962  [10304/13920]\n",
      "loss: 0.129648  [10368/13920]\n",
      "loss: 0.154843  [10432/13920]\n",
      "loss: 0.064682  [10496/13920]\n",
      "loss: 0.047600  [10560/13920]\n",
      "loss: 0.048642  [10624/13920]\n",
      "loss: 0.037114  [10688/13920]\n",
      "loss: 0.015831  [10752/13920]\n",
      "loss: 0.020268  [10816/13920]\n",
      "loss: 0.077509  [10880/13920]\n",
      "loss: 0.095176  [10944/13920]\n",
      "loss: 0.035222  [11008/13920]\n",
      "loss: 0.040131  [11072/13920]\n",
      "loss: 0.142393  [11136/13920]\n",
      "loss: 0.112706  [11200/13920]\n",
      "loss: 0.057477  [11264/13920]\n",
      "loss: 0.052692  [11328/13920]\n",
      "loss: 0.168258  [11392/13920]\n",
      "loss: 0.039358  [11456/13920]\n",
      "loss: 0.052767  [11520/13920]\n",
      "loss: 0.026175  [11584/13920]\n",
      "loss: 0.013111  [11648/13920]\n",
      "loss: 0.088275  [11712/13920]\n",
      "loss: 0.045515  [11776/13920]\n",
      "loss: 0.032692  [11840/13920]\n",
      "loss: 0.028894  [11904/13920]\n",
      "loss: 0.050228  [11968/13920]\n",
      "loss: 0.019542  [12032/13920]\n",
      "loss: 0.034793  [12096/13920]\n",
      "loss: 0.075126  [12160/13920]\n",
      "loss: 0.214604  [12224/13920]\n",
      "loss: 0.059032  [12288/13920]\n",
      "loss: 0.016521  [12352/13920]\n",
      "loss: 0.039178  [12416/13920]\n",
      "loss: 0.146076  [12480/13920]\n",
      "loss: 0.067572  [12544/13920]\n",
      "loss: 0.099702  [12608/13920]\n",
      "loss: 0.097610  [12672/13920]\n",
      "loss: 0.053975  [12736/13920]\n",
      "loss: 0.075555  [12800/13920]\n",
      "loss: 0.066467  [12864/13920]\n",
      "loss: 0.035045  [12928/13920]\n",
      "loss: 0.070247  [12992/13920]\n",
      "loss: 0.073871  [13056/13920]\n",
      "loss: 0.041242  [13120/13920]\n",
      "loss: 0.039039  [13184/13920]\n",
      "loss: 0.019083  [13248/13920]\n",
      "loss: 0.036020  [13312/13920]\n",
      "loss: 0.069137  [13376/13920]\n",
      "loss: 0.053606  [13440/13920]\n",
      "loss: 0.043545  [13504/13920]\n",
      "loss: 0.016181  [13568/13920]\n",
      "loss: 0.107628  [13632/13920]\n",
      "loss: 0.040256  [13696/13920]\n",
      "loss: 0.018679  [13760/13920]\n",
      "loss: 0.053075  [13824/13920]\n",
      "loss: 0.022446  [ 6944/13920]\n",
      "Train Error: \n",
      " Accuracy: 98.1% \n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.124890 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torcheeg.models import DGCNN\n",
    "\n",
    "writer = SummaryWriter(r\".\\log\\log_Avg_de5_DGCNN32_2_5k_shuffle111_batch64_epoch10_lr1e-3\")\n",
    "total_train_step = 0\n",
    "total_val_step = 0\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    model = DGCNN(in_channels=5, num_electrodes=16, hid_channels=32, num_layers=2, num_classes=3).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs = 10\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_loader, model, loss_fn, optimizer)\n",
    "        valid(val_loader, model, loss_fn)\n",
    "        torch.save(model, './models/DE/DGCNN_{}.pth'.format(t))\n",
    "    print(\"Done!\")\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T05:48:33.922959700Z",
     "start_time": "2023-08-04T05:39:52.591165300Z"
    }
   },
   "id": "4838748dd8f91179"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7a367391b1409ff0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
